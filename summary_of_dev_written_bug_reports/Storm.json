[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "bug_report": {
            "BugID": "STORM-2443",
            "Title": "Nimbus throws error when changing log level on UI topology page",
            "Description": "A NullPointerException occurs in Nimbus when attempting to set log configuration for a topology.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The log configuration should be updated without errors.",
            "ObservedBehavior": "A NullPointerException is thrown, preventing the log configuration from being set.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "bug_report": {
            "BugID": "STORM-3213",
            "Title": "500 Server Error on __acker component page on Storm UI",
            "Description": "An internal error occurs when processing the getComponentPageInfo request, resulting in a 500 Server Error on the Storm UI.",
            "StackTrace": [
                "org.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)",
                "at org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)",
                "at org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)",
                "at org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The component page should load without errors.",
            "ObservedBehavior": "A 500 Server Error is displayed when attempting to access the __acker component page.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "bug_report": {
            "BugID": "STORM-2496",
            "Title": "Dependency artifacts should be uploaded to blobstore with READ permission for all",
            "Description": "When submitting a topology with dependency artifacts, the supervisor fails to access the uploaded artifacts due to insufficient permissions, leading to a crash.",
            "StackTrace": [
                "org.apache.storm.generated.AuthorizationException: null",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]",
                "at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "Caused by: org.apache.storm.generated.AuthorizationException"
            ],
            "StepsToReproduce": [
                "Submit a topology with dependency artifacts as a specific user.",
                "Ensure the artifacts are uploaded to the blobstore.",
                "Attempt to access the artifacts from a different user without READ permission."
            ],
            "ExpectedBehavior": "The supervisor should be able to access the uploaded artifacts without crashing.",
            "ObservedBehavior": "The supervisor fails to get the artifact due to authorization issues and crashes.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "bug_report": {
            "BugID": "STORM-2879",
            "Title": "Supervisor collapse continuously when there is a expired assignment for overdue storm",
            "Description": "The supervisor fails to recover when an exception occurs during the deletion of storm files, leading to continuous collapses until manual cleanup is performed.",
            "StackTrace": [
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]"
            ],
            "StepsToReproduce": [
                "Reassign or kill a topology for a cluster.",
                "Ensure that the storm files (storm-code, storm-ser, storm-jar, LocalAssignment) are overdue.",
                "Restart the supervisor after the exception occurs."
            ],
            "ExpectedBehavior": "The supervisor should recover without manual intervention after an exception during file deletion.",
            "ObservedBehavior": "The supervisor collapses continuously due to uncleaned local assignments, requiring manual cleanup.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3012",
            "Title": "Nimbus will crash if pacemaker is restarted",
            "Description": "Nimbus crashed due to a NullPointerException (NPE) when the pacemaker was restarted.",
            "StackTrace": [
                "org.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.",
                "at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Nimbus should handle pacemaker restarts without crashing.",
            "ObservedBehavior": "Nimbus crashes with a NullPointerException when pacemaker is restarted.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "bug_report": {
            "BugID": "STORM-3073",
            "Title": "In some cases workers may crash because pendingEmits is full",
            "Description": "The executor's pendingEmits queue is full, leading to a crash when trying to add another tuple. This can occur due to various reasons, including the reemission of failed tuples and excessive tuple emissions in a single call.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.IllegalStateException: Queue full",
                "at org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: java.lang.IllegalStateException: Queue full",
                "at java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]"
            ],
            "StepsToReproduce": [
                "Run the ThroughputVsLatency topology from the Apache Storm examples.",
                "Trigger conditions that lead to the executor's pendingEmits queue filling up."
            ],
            "ExpectedBehavior": "The executor should handle tuple emissions without crashing, even when the pendingEmits queue is full.",
            "ObservedBehavior": "The executor crashes with a RuntimeException indicating that the queue is full.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "bug_report": {
            "BugID": "STORM-1672",
            "Title": "Stats not get class cast exception",
            "Description": "A ClassCastException occurs when invoking the component page in the UI.",
            "StackTrace": [
                "java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map",
                "at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)",
                "at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)",
                "at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)",
                "at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The component page should display statistics without throwing exceptions.",
            "ObservedBehavior": "A ClassCastException is thrown when attempting to access the component page.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "bug_report": {
            "BugID": "STORM-1520",
            "Title": "Nimbus Clojure/Zookeeper issue (\"stateChanged\" method not found)",
            "Description": "Nimbus becomes unresponsive and needs to be manually restarted after deploying/undeploying topologies. An error is logged indicating that no matching method was found for 'stateChanged'.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "at org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)",
                "at org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Nimbus should handle topology deployments without becoming unresponsive.",
            "ObservedBehavior": "Nimbus becomes unresponsive and requires a manual restart.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1977",
            "Title": "Leader Nimbus crashes with getClusterInfo when it doesn't have one or more replicated topology codes",
            "Description": "Nimbus instances can crash when they gain leadership without having all required topology codes, particularly when getClusterInfo is requested.",
            "StackTrace": [
                "KeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)",
                "at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)",
                "at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)",
                "java.lang.RuntimeException: (\"Error when processing an event\")",
                "at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)"
            ],
            "StepsToReproduce": [
                "Comment cleanup-corrupt-topologies! from nimbus.clj",
                "Patch Storm cluster",
                "Launch Nimbus 1 (leader)",
                "Run topology",
                "Kill Nimbus 1",
                "Launch Nimbus 2 from different node",
                "Nimbus 2 gains leadership",
                "Request getClusterInfo from Nimbus 2"
            ],
            "ExpectedBehavior": "Nimbus should handle requests for getClusterInfo without crashing, even if it lacks some topology codes.",
            "ObservedBehavior": "Nimbus crashes with a KeyNotFoundException when getClusterInfo is requested without all topology codes.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "bug_report": {
            "BugID": "STORM-2988",
            "Title": "\"Error on initialization of server mk-worker\" when using org.apache.storm.metrics2.reporters.JmxStormReporter on worker",
            "Description": "Workers cannot initialize and report an error when using JmxStormReporter for metrics reporting.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String",
                "at org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]"
            ],
            "StepsToReproduce": [
                "Configure metrics v2 in storm.yaml with JmxStormReporter.",
                "Start nimbus and supervisors.",
                "Submit a topology."
            ],
            "ExpectedBehavior": "Workers should initialize successfully and report metrics to JMX.",
            "ObservedBehavior": "Workers fail to initialize and log an error related to JmxStormReporter configuration.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "bug_report": {
            "BugID": "STORM-2321",
            "Title": "Nimbus did not come up after restart",
            "Description": "The nimbus was restarted during HA testing. After the restart, the nimbus failed to come up.",
            "StackTrace": [
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:206)",
                "at org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)",
                "at org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)",
                "Caused by: org.apache.storm.thrift.transport.TTransportException"
            ],
            "StepsToReproduce": [
                "Restart the nimbus during HA testing."
            ],
            "ExpectedBehavior": "Nimbus should come up successfully after a restart.",
            "ObservedBehavior": "Nimbus fails to come up after the restart.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "bug_report": {
            "BugID": "STORM-3013",
            "Title": "Deactivated topology restarts if data flows into Kafka",
            "Description": "When the storm topology is deactivated and records are produced into Kafka, an exception is thrown.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]",
                "Caused by: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]"
            ],
            "StepsToReproduce": [
                "Deactivate the storm topology.",
                "Produce records into Kafka."
            ],
            "ExpectedBehavior": "The system should handle the deactivation gracefully without throwing exceptions.",
            "ObservedBehavior": "An exception is thrown indicating that the consumer has already been closed.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "bug_report": {
            "BugID": "STORM-3117",
            "Title": "Deleting blobs for running topologies hoses Nimbus",
            "Description": "The deletion of blobs for running topologies causes Nimbus to get stuck and restart.",
            "StackTrace": [
                "org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]",
                "java.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms."
            ],
            "StepsToReproduce": [
                "Submit a topology using cluster.submitTopology()",
                "Wait for the topology to be up using cluster.waitTopologyUp()",
                "Delete all blobs using cluster.deleteAllBlobs()"
            ],
            "ExpectedBehavior": "Nimbus should handle blob deletions without getting stuck or restarting.",
            "ObservedBehavior": "Nimbus gets stuck and continuously restarts after blob deletion.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "bug_report": {
            "BugID": "STORM-2993",
            "Title": "Storm HDFS bolt throws ClosedChannelException when Time rotation policy is used",
            "Description": "The Storm connector throws a ClosedChannelException in the worker logs when the timed rotation policy is used, indicating a potential synchronization issue.",
            "StackTrace": [
                "java.nio.channels.ClosedChannelException: null",
                "at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73)",
                "at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153)",
                "at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105)",
                "at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57)",
                "at java.io.DataOutputStream.write(DataOutputStream.java:107)",
                "at java.io.FilterOutputStream.write(FilterOutputStream.java:97)",
                "at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48)",
                "at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40)",
                "at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The HDFS bolt should successfully write data without encountering a ClosedChannelException.",
            "ObservedBehavior": "The HDFS bolt fails to write data and throws a ClosedChannelException when the timed rotation policy is used.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "bug_report": {
            "BugID": "STORM-1540",
            "Title": "Topology Debug/Sampling Breaks Trident Topologies",
            "Description": "When deploying a Trident topology with debug/sampling enabled, workers crash due to a serialization issue.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448)",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414)",
                "at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73)",
                "at org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83)",
                "at org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484)",
                "at clojure.lang.AFn.run(AFn.java:22)",
                "at java.lang.Thread.run(Thread.java:745)",
                "Caused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "at org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41)",
                "at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568)",
                "at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75)",
                "at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44)",
                "at org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186)",
                "at org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309)",
                "at org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40)",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435)"
            ],
            "StepsToReproduce": [
                "Deploy a Trident topology.",
                "Turn on debug/sampling."
            ],
            "ExpectedBehavior": "The Trident topology should run without crashing.",
            "ObservedBehavior": "Workers crash with a NotSerializableException when debug/sampling is enabled.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "bug_report": {
            "BugID": "STORM-2275",
            "Title": "Nimbus crashed during state transition of topology",
            "Description": "Nimbus crashes due to a NullPointerException during the state transition of a topology.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)",
                "... 1 more"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Nimbus should handle state transitions without crashing.",
            "ObservedBehavior": "Nimbus crashes with a NullPointerException during state transition.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "bug_report": {
            "BugID": "STORM-2873",
            "Title": "Backpressure implementation deletes ephemeral too frequently",
            "Description": "The backpressure implementation deletes the znode when not relevant, leading to a Zookeeper issue of too frequent deletion and creation of the same path for ephemeral znodes.",
            "StackTrace": [
                "java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721",
                "at backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should not delete ephemeral znodes too frequently to avoid Zookeeper errors.",
            "ObservedBehavior": "Frequent deletion and creation of the same ephemeral znode leads to NoAuthException errors in Zookeeper.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "bug_report": {
            "BugID": "STORM-2279",
            "Title": "Unable to open bolt page of storm ui",
            "Description": "With the latest storm code, the UI fails to open and display bolt information, resulting in an Internal Server Error.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:3606)",
                "java.lang.ArrayIndexOutOfBoundsException: -2",
                "at java.util.ArrayList.elementData(ArrayList.java:418)"
            ],
            "StepsToReproduce": [
                "Set up the vagrant environment with the latest storm code.",
                "Attempt to access the bolt page via the UI."
            ],
            "ExpectedBehavior": "The bolt page should load successfully and display the relevant information.",
            "ObservedBehavior": "An Internal Server Error occurs, preventing the UI from displaying bolt information.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "bug_report": {
            "BugID": "STORM-3079",
            "Title": "improve getMessage support for ThriftExceptions",
            "Description": "The generated thrift code does not support getMessage(), leading to confusion with null messages in error callstacks. The log messages should be improved.",
            "StackTrace": [
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should provide meaningful error messages instead of null messages.",
            "ObservedBehavior": "Error callstacks show null messages, causing confusion.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "bug_report": {
            "BugID": "STORM-3096",
            "Title": "blobstores deleted before topologies can be submitted",
            "Description": "After an attempted fix for a race condition in topology submission, the error persists due to premature deletion of blobs.",
            "StackTrace": [
                "org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Blobs should remain available until all topologies are fully submitted.",
            "ObservedBehavior": "Blobs are deleted prematurely, leading to submission errors.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1642",
            "Title": "NullPointerException when deserialize",
            "Description": "Encountered a NullPointerException when Storm tries to deserialize. The issue arises despite not using OutputCollector concurrently, and only passing a thrift object between bolts.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]",
                "at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]",
                "at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]",
                "at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]",
                "Caused by: java.lang.NullPointerException",
                "at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]",
                "at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should successfully deserialize the thrift object without throwing a NullPointerException.",
            "ObservedBehavior": "A NullPointerException is thrown during the deserialization process.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "bug_report": {
            "BugID": "STORM-2700",
            "Title": "Blobstore shouldn't check ACL when Blobstore Acl validation disabled",
            "Description": "When the configuration 'storm.blobstore.acl.validation.enabled' is set to false, the blobstore still checks ACL, leading to authorization errors.",
            "StackTrace": [
                "java.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)",
                "at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]",
                "at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]",
                "at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: org.apache.storm.generated.AuthorizationException",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Create a blobstore with permission set to one user (e.g mapredqa).",
                "Submit a topology with topology.blobstore.map config as someone else (e.g. ethan)."
            ],
            "ExpectedBehavior": "The blobstore should not check ACL when ACL validation is disabled.",
            "ObservedBehavior": "The blobstore checks ACL and throws an AuthorizationException.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "bug_report": {
            "BugID": "STORM-1663",
            "Title": "Clicking on an active topology from storm ui home page and then refreshing the page throws exception",
            "Description": "An exception is thrown when refreshing the page after clicking on an active topology in the Storm UI.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)",
                "at org.apache.storm.ui.core$topology_page.invoke(core.clj:638)"
            ],
            "StepsToReproduce": [
                "Click on an active topology from the Storm UI home page.",
                "Refresh the page."
            ],
            "ExpectedBehavior": "The topology page should refresh without throwing an exception.",
            "ObservedBehavior": "An exception is thrown, preventing the page from refreshing properly.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "bug_report": {
            "BugID": "STORM-2518",
            "Title": "NPE during uploading dependency artifacts with secured cluster",
            "Description": "A NullPointerException occurs when adding ACL to USER while uploading artifacts, due to Nimbus reading a null value for the optional 'name' field without checking.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382)",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357)",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:498)",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047)",
                "at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)",
                "at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should handle the optional 'name' field correctly without throwing a NullPointerException.",
            "ObservedBehavior": "Uploading artifacts fails and topology submission also fails due to a NullPointerException.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "bug_report": {
            "BugID": "STORM-3124",
            "Title": "Failures talking to Pacemaker",
            "Description": "Sporadic failures when attempting to communicate with the Pacemaker service, leading to issues in launching topologies.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:470) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should successfully connect to the Pacemaker service and launch topologies without errors.",
            "ObservedBehavior": "The system fails to connect to the Pacemaker service, resulting in errors and inability to launch topologies.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2095",
            "Title": "Nimbus dies and never recovers due to java.nio.file.DirectoryNotEmptyException",
            "Description": "Nimbus fails to restart after a blobstore key creation is interrupted, leading to a DirectoryNotEmptyException.",
            "StackTrace": [
                "java.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file",
                "at org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "at java.lang.reflect.Method.invoke(Method.java:497)",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "at org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)",
                "at org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)",
                "at clojure.lang.AFn.applyToHelper(AFn.java:156)",
                "at clojure.lang.AFn.applyTo(AFn.java:144)",
                "at clojure.core$apply.invoke(core.clj:630)",
                "at org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)",
                "at clojure.lang.RestFn.invoke(RestFn.java:421)",
                "at org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)",
                "at org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)",
                "at org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)",
                "at clojure.lang.AFn.applyToHelper(AFn.java:152)",
                "at clojure.lang.AFn.applyTo(AFn.java:144)",
                "at org.apache.storm.daemon.nimbus.main(Unknown Source)"
            ],
            "StepsToReproduce": [
                "1) Create a blobstore key for a large file (1 or 2 GB).",
                "2) While the blob is being created, restart nimbus.",
                "3) Observe that nimbus fails to start due to DirectoryNotEmptyException."
            ],
            "ExpectedBehavior": "Partial blobstore key is deleted cleanly and doesn\u2019t affect nimbus.",
            "ObservedBehavior": "Nimbus keeps dying due to DirectoryNotEmptyException and never comes up.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2847",
            "Title": "Exception thrown after rebalance IllegalArgumentException",
            "Description": "After rebalance, the storm-kafka-client spout attempts to check the current position of partitions that are no longer assigned to the current spout, leading to an IllegalArgumentException.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262)",
                "at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The spout should only check the position for partitions that are assigned to it.",
            "ObservedBehavior": "An IllegalArgumentException is thrown when checking the position of unassigned partitions.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "bug_report": {
            "BugID": "STORM-1114",
            "Title": "Racing condition in trident zookeeper zk-node create/delete",
            "Description": "In production for some trident topology, workers are trying to create a zk-node that already exists or delete a zk-node that has already been deleted, causing the worker process to die due to a racing condition in the zk-node operations.",
            "StackTrace": [
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The worker should successfully create or delete zk-nodes without causing the process to die.",
            "ObservedBehavior": "The worker process dies when attempting to create or delete zk-nodes that already exist or do not exist.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "bug_report": {
            "BugID": "STORM-2811",
            "Title": "Nimbus may throw NPE if the same topology is killed multiple times",
            "Description": "Nimbus throws a NullPointerException when attempting to kill the same topology multiple times during integration tests.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[libthrift-0.10.0.jar:0.10.0]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should handle multiple requests to kill the same topology without throwing exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown when attempting to kill the same topology multiple times.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2903",
            "Title": "Fix possible NullPointerException in AbstractAutoCreds",
            "Description": "Observed a NullPointerException while testing the Hive token mechanism.",
            "StackTrace": [
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]",
                "at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]",
                "at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should handle token initialization without throwing exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown during the initialization process.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "bug_report": {
            "BugID": "STORM-3168",
            "Title": "AsyncLocalizer cleanup appears to crash",
            "Description": "The AsyncLocalizer fails to log cleanup messages and appears to crash, requiring a restart of the supervisor to resume logging.",
            "StackTrace": [
                "java.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...",
                "at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]",
                "at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "Caused by: org.apache.storm.generated.KeyNotFoundException",
                "at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "Enable debug logging for AsyncLocalizer.",
                "Observe the logs for cleanup messages.",
                "Restart the supervisor to see if logging resumes."
            ],
            "ExpectedBehavior": "The cleanup process should run continuously and log any failures.",
            "ObservedBehavior": "The cleanup messages do not log, and the process appears to crash.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "bug_report": {
            "BugID": "STORM-2986",
            "Title": "NPE from LogCleaner",
            "Description": "A NullPointerException occurs in the LogCleaner when attempting to clean up old logs due to the absence of the workers-artifacts directory before any topologies are submitted.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Set logviewer.cleanup.interval.secs to 10 to start LogCleaner thread.",
                "Ensure that the workers-artifacts directory does not exist.",
                "Check logviewer.log for errors."
            ],
            "ExpectedBehavior": "LogCleaner should operate without throwing exceptions, even if the workers-artifacts directory is not present.",
            "ObservedBehavior": "LogCleaner throws a NullPointerException when attempting to clean up logs due to the missing directory.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2197",
            "Title": "NimbusClient connections leak due to leakage in ThriftClient.",
            "Description": "Nimbus client connections are not closed when there are errors while connecting to Nimbus. The TSocket in ThriftClient should have been closed in case of errors.",
            "StackTrace": [
                "org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed",
                "at org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199)",
                "at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277)",
                "at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37)",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145)",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140)",
                "at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103)",
                "at backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The TSocket in ThriftClient should close properly in case of connection errors.",
            "ObservedBehavior": "Connections to Nimbus are not closed, leading to resource leaks.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "bug_report": {
            "BugID": "STORM-1596",
            "Title": "Multiple Subject sharing Kerberos TGT - causes services to fail",
            "Description": "With multiple threads accessing the same Subject, it can cause a ServiceTicket in use by one thread to be destroyed by another thread. This issue can be reproduced by running BasicDRPCTopology with high parallelism in a secure cluster.",
            "StackTrace": [
                "javax.security.sasl.SaslException: GSS initiate failed",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]",
                "at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)",
                "Caused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME"
            ],
            "StepsToReproduce": [
                "Run BasicDRPCTopology with high parallelism in a secure cluster."
            ],
            "ExpectedBehavior": "The system should handle multiple threads accessing the same Subject without causing service failures.",
            "ObservedBehavior": "Service failures occur due to the destruction of ServiceTickets by concurrent threads.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2142",
            "Title": "ReportErrorAndDie runs suicide function only when InterruptedException or InterruptedIOException is thrown",
            "Description": "When EvaluationFilter / EvaluationFunction throws Exception, the async loop for the executor dies while others continue to work.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]",
                "at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]",
                "Caused by: java.lang.RuntimeException: Cannot convert null to int",
                "at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The system should log the error and not terminate the async loop for the executor.",
            "ObservedBehavior": "The async loop for the executor dies when an exception is thrown, while others continue to work.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "bug_report": {
            "BugID": "STORM-2400",
            "Title": "Intermittent failure in nimbus because of errors from LeaderLatch#getLeader()",
            "Description": "The method LeaderLatch#getLeader() intermittently throws KeeperException with Code#NONODE, likely due to a participant's ephemeral ZK node being removed when its session is closed.",
            "StackTrace": [
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The LeaderLatch#getLeader() method should not throw KeeperException with NoNode and should handle such cases gracefully.",
            "ObservedBehavior": "The method intermittently throws KeeperException with NoNode, causing failures in the nimbus.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3084",
            "Title": "2.x NPE on Nimbus startup",
            "Description": "A NullPointerException occurs during the startup of the Nimbus server in Apache Storm version 2.0.0.y.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Nimbus server should start without any exceptions.",
            "ObservedBehavior": "Nimbus server fails to start due to a NullPointerException.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "bug_report": {
            "BugID": "STORM-3118",
            "Title": "Netty incompatibilities with Pacemaker",
            "Description": "Nimbus has issues with Pacemaker, leading to exceptions that prevent topology submission.",
            "StackTrace": [
                "org.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106)",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738)",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801)",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814)",
                "at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65)",
                "Caused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "java.lang.IllegalStateException: instance must be started before calling this method",
                "at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444)"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Topology should be submitted successfully without exceptions.",
            "ObservedBehavior": "Exceptions occur during topology submission, preventing it from completing.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "bug_report": {
            "BugID": "STORM-2158",
            "Title": "OutOfMemoryError in Nimbus' SimpleTransportPlugin",
            "Description": "An OutOfMemoryError is thrown by Nimbus' SimpleTransportPlugin when a malformed Thrift request is posted.",
            "StackTrace": [
                "java.lang.OutOfMemoryError: Java heap space",
                "at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]",
                "at java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Post a malformed Thrift request using the command: echo 'Hello' | nc localhost 6627"
            ],
            "ExpectedBehavior": "The system should handle malformed requests without throwing an OutOfMemoryError.",
            "ObservedBehavior": "The system throws an OutOfMemoryError and shuts down.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "bug_report": {
            "BugID": "STORM-2682",
            "Title": "Supervisor crashes with NullPointerException",
            "Description": "When the supervisor is started, it crashes after about 30 seconds due to a NullPointerException.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]",
                "at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "The supervisor should start and run without crashing.",
            "ObservedBehavior": "The supervisor crashes with a NullPointerException after approximately 30 seconds.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "bug_report": {
            "BugID": "STORM-3103",
            "Title": "nimbus stuck shutting down causing leadership issues on startup",
            "Description": "When debugging a Nimbus NPE that caused restarts, a forced halt occurred, leading to leadership confusion.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": null,
            "ExpectedBehavior": "Nimbus should shut down cleanly without causing leadership confusion.",
            "ObservedBehavior": "Nimbus experiences a NullPointerException during shutdown, leading to leadership issues.",
            "Resolution": "Fixed"
        }
    }
]