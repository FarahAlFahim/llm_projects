[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "bug_report": {
            "BugID": "STORM-2443",
            "Title": "NullPointerException in Nimbus when setting log configuration for topology",
            "Description": "A NullPointerException occurs in the Nimbus service when attempting to set the log configuration for a topology via the UI. This issue arises specifically when the topology ID provided is invalid or when the topology configuration cannot be read, leading to a failure in the log configuration process.",
            "StackTrace": [
                "2017-03-30 16:53:26.954 o.a.s.d.n.Nimbus pool-14-thread-56 [WARN] set log config topology exception. (topology id='rolling-1-1490860365')",
                "java.lang.NullPointerException: null",
                "at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]"
            ],
            "StepsToReproduce": [
                "1. Access the Apache Storm UI.",
                "2. Navigate to the topology management section.",
                "3. Attempt to change the log level for a topology with an invalid ID (e.g., 'rolling-1-1490860365').",
                "4. Observe the error message in the Nimbus logs."
            ],
            "ExpectedBehavior": "The log configuration should be updated successfully without any exceptions, or a clear error message should be displayed indicating that the topology ID is invalid.",
            "ObservedBehavior": "A NullPointerException is thrown, and a warning is logged in the Nimbus logs indicating a failure to set the log configuration for the specified topology ID.",
            "Resolution": "A fix has been implemented to handle cases where the topology ID is invalid or the configuration cannot be read, preventing the NullPointerException from occurring."
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "bug_report": {
            "BugID": "STORM-3213",
            "Title": "500 Server Error on Acker Component Page in Storm UI",
            "Description": "A 500 Internal Server Error occurs when attempting to access the Acker component page in the Storm UI. The error is caused by a NullPointerException in the Nimbus service when processing the request for component page information.",
            "StackTrace": [
                "org.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)",
                "at org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)",
                "at org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)",
                "at org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)",
                "2018-09-05 16:15:24.927 o.a.s.t.ProcessFunction pool-21-thread-55 [ERROR] Internal error processing getComponentPageInfo",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38)",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169)",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:748)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37)",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192)"
            ],
            "StepsToReproduce": [
                "1. Start the Storm cluster and ensure the Acker component is running.",
                "2. Access the Storm UI and navigate to the Acker component page.",
                "3. Observe the server response."
            ],
            "ExpectedBehavior": "The Acker component page should load successfully without any errors.",
            "ObservedBehavior": "A 500 Internal Server Error is displayed, indicating an internal error processing the request.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "bug_report": {
            "BugID": "STORM-2496",
            "Title": "Supervisor Fails to Download Artifacts Due to Insufficient Permissions",
            "Description": "When submitting a topology with dependency artifacts, the supervisor fails to download the required artifacts from the blobstore if the artifacts do not have READ permissions for the user. This results in an AuthorizationException and causes the supervisor to crash.",
            "StackTrace": [
                "2017-04-28 04:56:46.594 o.a.s.l.AsyncLocalizer Async Localizer [WARN] Caught Exception While Downloading (rethrowing)...",
                "org.apache.storm.generated.AuthorizationException: null",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]",
                "2017-04-28 04:56:46.597 o.a.s.d.s.Slot SLOT_6701 [ERROR] Error when processing event",
                "java.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)",
                "at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]",
                "at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]",
                "at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "Caused by: org.apache.storm.generated.AuthorizationException",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]",
                "2017-04-28 04:56:46.597 o.a.s.u.Utils SLOT_6701 [ERROR] Halting process: Error when processing an event",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]"
            ],
            "StepsToReproduce": [
                "1. Submit a topology with dependency artifacts using a user that does not have READ permissions for those artifacts.",
                "2. Monitor the logs for the supervisor process."
            ],
            "ExpectedBehavior": "The supervisor should successfully download the required artifacts from the blobstore without crashing.",
            "ObservedBehavior": "The supervisor fails to download the artifacts due to an AuthorizationException, resulting in a crash.",
            "Resolution": "Ensure that all uploaded artifacts have READ permissions for all users, or modify the supervisor to handle missing permissions gracefully."
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "bug_report": {
            "BugID": "STORM-2879",
            "Title": "Supervisor Fails to Recover Due to KeyNotFoundException on Overdue Local Assignments",
            "Description": "When a topology is reassigned or killed in a cluster, the supervisor attempts to delete files associated with an overdue storm. However, if an exception occurs during the deletion of these files, the local assignment remains on disk. Upon supervisor restart, it tries to recover from these local assignments, leading to a KeyNotFoundException when the blob store cannot find the required files. This results in a continuous failure loop where the supervisor cannot recover until all local assignments are manually cleaned up.",
            "StackTrace": [
                "2017-12-27 14:15:04.434 o.a.s.l.AsyncLocalizer [INFO] Cleaning up unused topologies in /opt/meituan/storm/data/supervisor/stormdist",
                "2017-12-27 14:15:04.434 o.a.s.d.s.AdvancedFSOps [INFO] Deleting path /opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785",
                "2017-12-27 14:15:04.502 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.",
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]",
                "at java.lang.Thread.run(Thread.java:745) ~[?:1.7.0_76]"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology in the cluster.",
                "2. Reassign or kill the topology while it is still overdue.",
                "3. Observe the supervisor's attempt to delete the associated files.",
                "4. Trigger an exception during the deletion process (e.g., simulate a file system error).",
                "5. Restart the supervisor and observe the continuous failure due to KeyNotFoundException."
            ],
            "ExpectedBehavior": "The supervisor should successfully delete the files associated with the overdue storm and recover without errors.",
            "ObservedBehavior": "The supervisor fails to recover due to a KeyNotFoundException when it attempts to access files that were not deleted due to an earlier exception.",
            "Resolution": "A fix has been implemented to ensure that file deletions are handled in a transactional manner, preventing leftover local assignments from causing recovery failures."
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3012",
            "Title": "Nimbus Crashes with NullPointerException When Pacemaker is Restarted",
            "Description": "The Nimbus service crashes due to a NullPointerException (NPE) when the Pacemaker is restarted. This occurs because the Nimbus attempts to process a heartbeat message that is null, leading to an unhandled exception in the cleanup process.",
            "StackTrace": [
                "2018-03-26 21:39:26.596 timer o.a.s.d.n.Nimbus [ERROR] Error while processing event",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2508) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus service.",
                "2. Restart the Pacemaker service.",
                "3. Observe the Nimbus logs for any errors."
            ],
            "ExpectedBehavior": "Nimbus should handle the Pacemaker restart gracefully without crashing.",
            "ObservedBehavior": "Nimbus crashes with a NullPointerException when attempting to process heartbeat messages after the Pacemaker is restarted.",
            "Resolution": "A fix has been implemented to handle null responses from the Pacemaker client, ensuring that Nimbus does not crash during cleanup operations."
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "bug_report": {
            "BugID": "STORM-3073",
            "Title": "Worker Crashes Due to Full Pending Emits Queue in Storm Topology",
            "Description": "While running the `ThroughputVsLatency` topology from the Apache Storm examples, an error occurs indicating that the executor's pending emits queue is full, leading to a crash of the worker. This issue arises when the topology attempts to emit too many tuples in a single call or when tick tuples trigger re-emission of failed tuples, causing the queue to overflow.",
            "StackTrace": [
                "2018-05-15 11:35:28.365 o.a.s.u.Utils Thread-16-spout-executor[8, 8] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.IllegalStateException: Queue full",
                "at org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: java.lang.IllegalStateException: Queue full",
                "at java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]",
                "at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "1. Clone the Apache Storm repository from GitHub.",
                "2. Navigate to the examples directory: `cd examples/storm-loadgen/src/main/java/org/apache/storm/loadgen`.",
                "3. Compile the project using Maven: `mvn clean install`.",
                "4. Run the `ThroughputVsLatency` topology.",
                "5. Monitor the logs for errors related to the pending emits queue."
            ],
            "ExpectedBehavior": "The topology should run without errors, and the worker should process tuples without crashing due to a full pending emits queue.",
            "ObservedBehavior": "The worker crashes with a `java.lang.RuntimeException: java.lang.IllegalStateException: Queue full` error when the pending emits queue reaches its limit.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "bug_report": {
            "BugID": "STORM-1672",
            "Title": "ClassCastException in StatsUtil.filterSysStreams due to Long to Map cast",
            "Description": "A ClassCastException occurs when invoking the StatsUtil.filterSysStreams method, indicating that a Long value is being incorrectly cast to a Map. This issue arises during the aggregation of component statistics in the Apache Storm UI.",
            "StackTrace": [
                "2016-03-31 14:21:44.576 o.a.s.t.s.AbstractNonblockingServer$FrameBuffer [ERROR] Unexpected throwable while invoking!",
                "java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map",
                "at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)",
                "at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)",
                "at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)",
                "at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "StepsToReproduce": [
                "1. Start the Apache Storm cluster.",
                "2. Deploy a topology that generates component statistics.",
                "3. Access the component page in the UI.",
                "4. Observe the logs for any ClassCastException errors."
            ],
            "ExpectedBehavior": "The component page should display the aggregated statistics without any errors.",
            "ObservedBehavior": "A ClassCastException is thrown, preventing the display of component statistics.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "bug_report": {
            "BugID": "STORM-1520",
            "Title": "Nimbus Unresponsive Due to Missing 'stateChanged' Method in Clojure/Zookeeper Integration",
            "Description": "After deploying or undeploying topologies, Nimbus becomes unresponsive, requiring a manual restart. The following error appears in the nimbus.log:\n\n```\n2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception\njava.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n```\n\nThis issue appears to stem from the Clojure implementation of the Zookeeper state factory, where the expected method `stateChanged` is not found, leading to an unresponsive Nimbus instance.",
            "StackTrace": [
                "2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception",
                "java.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "at org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)",
                "at org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "Deploy a topology using Nimbus.",
                "Undeploy the same topology.",
                "Monitor the nimbus.log for errors."
            ],
            "ExpectedBehavior": "Nimbus should handle topology deployment and undeployment without becoming unresponsive.",
            "ObservedBehavior": "Nimbus becomes unresponsive and requires a manual restart after deploying or undeploying topologies, with an error logged regarding a missing 'stateChanged' method.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1977",
            "Title": "Nimbus Crashes on getClusterInfo When Missing Replicated Topology Codes",
            "Description": "When a Nimbus instance that lacks one or more replicated topology codes attempts to process a getClusterInfo request, it crashes due to a KeyNotFoundException. This issue arises after Nimbus gains leadership without having all necessary topology codes, which is a change in behavior introduced with the BlobStore feature.",
            "StackTrace": [
                "KeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)",
                "at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)",
                "at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)",
                "at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)",
                "at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "1. Comment out the cleanup-corrupt-topologies! function in nimbus.clj to bypass the cleanup logic.",
                "2. Patch the Storm cluster with the modified nimbus.clj.",
                "3. Launch Nimbus 1 as the leader.",
                "4. Run a topology on Nimbus 1.",
                "5. Kill Nimbus 1 to simulate a failure.",
                "6. Launch Nimbus 2 from a different node.",
                "7. Nimbus 2 gains leadership without having all necessary topology codes.",
                "8. Request getClusterInfo from Nimbus 2."
            ],
            "ExpectedBehavior": "Nimbus should handle the getClusterInfo request gracefully, even if it does not have all replicated topology codes, without crashing.",
            "ObservedBehavior": "Nimbus crashes with a KeyNotFoundException when attempting to process the getClusterInfo request due to missing topology codes.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "bug_report": {
            "BugID": "STORM-2988",
            "Title": "Initialization Error in Worker with JmxStormReporter Configuration",
            "Description": "When configuring the JmxStormReporter in the storm.yaml file, workers fail to initialize and throw an IllegalArgumentException. The error indicates that the reporter configuration is not being converted to a string properly, leading to a failure in the metrics reporting setup.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String",
                "at org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.RestFn.invoke(RestFn.java:512) [storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]",
                "at clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]"
            ],
            "StepsToReproduce": [
                "1. Configure the storm.yaml file with the following JmxStormReporter settings:",
                "   storm.metrics.reporters:",
                "     - class: \"org.apache.storm.metrics2.reporters.JmxStormReporter\"",
                "       daemons:",
                "         - \"supervisor\"",
                "         - \"nimbus\"",
                "         - \"worker\"",
                "       report.period: 10",
                "       report.period.units: \"SECONDS\"",
                "2. Start the Nimbus and Supervisor processes.",
                "3. Submit a topology to the cluster.",
                "4. Observe the worker initialization logs for errors."
            ],
            "ExpectedBehavior": "Workers should initialize successfully and report metrics to JMX without any errors.",
            "ObservedBehavior": "Workers fail to initialize and log an IllegalArgumentException related to the reporter configuration.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "bug_report": {
            "BugID": "STORM-2321",
            "Title": "Nimbus Fails to Start After Restart During HA Testing",
            "Description": "During high availability (HA) testing, the Nimbus service was restarted, but it failed to come back online. The logs indicate multiple errors related to the blobstore and ZooKeeper, specifically a `NoNodeException` when attempting to access a blob that should have been present. This issue appears to stem from the Nimbus not being able to retrieve the necessary state from ZooKeeper after the restart.",
            "StackTrace": [
                "2017-01-18 04:57:58.247 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with key KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar",
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)",
                "at org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)",
                "at org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)",
                "at org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)",
                "at org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:252)",
                "at org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:349)"
            ],
            "StepsToReproduce": [
                "1. Set up a Nimbus instance with high availability (HA) enabled.",
                "2. Start the Nimbus service.",
                "3. Restart the Nimbus service during HA testing.",
                "4. Observe the logs for any errors related to blobstore and ZooKeeper."
            ],
            "ExpectedBehavior": "The Nimbus service should restart successfully and be able to retrieve its state from ZooKeeper, allowing it to function normally.",
            "ObservedBehavior": "The Nimbus service fails to start after the restart, with errors indicating that it cannot find the necessary blob in ZooKeeper, resulting in a `NoNodeException`.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "bug_report": {
            "BugID": "STORM-3013",
            "Title": "Exception Thrown When Producing Records to Kafka After Deactivating Storm Topology",
            "Description": "When a Storm topology is deactivated and records are produced into Kafka, an exception is thrown indicating that the Kafka consumer has already been closed. This issue occurs during the metrics tick process, leading to a failure in processing incoming records.",
            "StackTrace": [
                "2018-03-28 09:51:01.289 o.a.s.util Thread-17-kafkaLogs-executor[139 139] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]",
                "Caused by: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]",
                "at org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]",
                "at clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6478$G__6447__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]"
            ],
            "StepsToReproduce": [
                "1. Deactivate the Storm topology.",
                "2. Produce records into the Kafka topic associated with the deactivated topology.",
                "3. Observe the logs for any exceptions thrown."
            ],
            "ExpectedBehavior": "The system should handle the deactivation of the topology gracefully without throwing exceptions when records are produced into Kafka.",
            "ObservedBehavior": "An exception is thrown indicating that the Kafka consumer has already been closed, leading to a failure in processing incoming records.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "bug_report": {
            "BugID": "STORM-3117",
            "Title": "Nimbus Fails to Handle Blob Deletion for Running Topologies, Leading to Continuous Restarts",
            "Description": "When attempting to delete blobs associated with running topologies, Nimbus encounters a WrappedKeyNotFoundException, which causes it to restart continuously. This issue arises specifically when the following pseudo-code is executed:\n\n```java\ncluster.submitTopology(cluster.getTopologiesJarFile(), topoName, config, topology);\ncluster.waitTopologyUp(topoName);\ncluster.deleteAllBlobs();\n```\n\nThe deletion of blobs for the topology `wc-topology-test-1-1529509694` results in Nimbus being unable to find the necessary blob metadata, leading to a failure in processing events and ultimately causing a server shutdown.",
            "StackTrace": [
                "2018-06-20 15:48:37.947 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event",
                "java.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormcode.ser",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:420) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1517) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getClusterInfoImpl(Nimbus.java:2675) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.sendClusterMetricsToExecutors(Nimbus.java:2686) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Submit a topology using the following code:\n   ```java\n   cluster.submitTopology(cluster.getTopologiesJarFile(), topoName, config, topology);\n   ```",
                "2. Wait for the topology to be fully operational:\n   ```java\n   cluster.waitTopologyUp(topoName);\n   ```",
                "3. Attempt to delete all blobs associated with the topology:\n   ```java\n   cluster.deleteAllBlobs();\n   ```"
            ],
            "ExpectedBehavior": "Nimbus should successfully delete the blobs associated with the running topology without encountering any exceptions, allowing the topology to continue running smoothly.",
            "ObservedBehavior": "Nimbus encounters a WrappedKeyNotFoundException when trying to access the metadata for the deleted blobs, leading to continuous restarts and failure to process events.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "bug_report": {
            "BugID": "STORM-2993",
            "Title": "ClosedChannelException in HDFS Bolt due to unsynchronized timed rotation policy",
            "Description": "The Storm HDFS bolt encounters a ClosedChannelException when the timed rotation policy is used. This issue arises because the rotation policy does not synchronize properly, leading to attempts to write to a closed writer.",
            "StackTrace": [
                "java.nio.channels.ClosedChannelException: null",
                "at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?]",
                "at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?]",
                "at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?]",
                "at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?]",
                "at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161]",
                "at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161]",
                "at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?]",
                "at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?]",
                "at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) ~[stormjar.jar:?]",
                "at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161]"
            ],
            "StepsToReproduce": [
                "1. Configure the Storm HDFS bolt with a timed rotation policy.",
                "2. Start the Storm topology that utilizes the HDFS bolt.",
                "3. Monitor the worker logs for any errors related to file writing."
            ],
            "ExpectedBehavior": "The HDFS bolt should successfully write data to HDFS without encountering any exceptions.",
            "ObservedBehavior": "The HDFS bolt throws a ClosedChannelException, indicating that it attempted to write to a closed writer due to unsynchronized access during the timed rotation.",
            "Resolution": "A fix for this issue has been implemented and tested, ensuring proper synchronization in the timed rotation policy."
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "bug_report": {
            "BugID": "STORM-1540",
            "Title": "Trident Topologies Crash with NotSerializableException During Debug/Sampling",
            "Description": "When deploying a Trident topology with debug/sampling enabled, workers crash due to a NotSerializableException related to the ConsList class. This issue occurs during the serialization process when attempting to transfer data between components.",
            "StackTrace": [
                "2016-02-11 14:13:23.617 o.a.s.util [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]",
                "Caused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "at org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]",
                "at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]",
                "at com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]",
                "at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]",
                "at org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "... 6 more"
            ],
            "StepsToReproduce": [
                "1. Deploy a Trident topology.",
                "2. Enable debug/sampling in the configuration.",
                "3. Observe the worker logs for errors."
            ],
            "ExpectedBehavior": "The Trident topology should run without crashing, and debug/sampling should provide the necessary insights without serialization issues.",
            "ObservedBehavior": "Workers crash with a NotSerializableException for the ConsList class, leading to a failure in processing.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "bug_report": {
            "BugID": "STORM-2275",
            "Title": "NullPointerException in Nimbus during topology state transition",
            "Description": "A NullPointerException occurs in the Nimbus component of Apache Storm when processing an event related to topology state transitions. This issue arises due to an assumption that the StormBase object will be non-null, which is incorrect in certain scenarios, leading to a crash of the Nimbus process.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)",
                "... 1 more",
                "java.lang.RuntimeException: Halting process: Error while processing event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology in Apache Storm.",
                "2. Trigger an event that causes a state transition in the topology.",
                "3. Monitor the Nimbus logs for errors."
            ],
            "ExpectedBehavior": "The Nimbus should handle the state transition without throwing a NullPointerException and should log the transition details appropriately.",
            "ObservedBehavior": "The Nimbus crashes with a NullPointerException when attempting to process the event related to the topology state transition, leading to a halt in the process.",
            "Resolution": "The issue has been identified and fixed by ensuring that the StormBase object is checked for null before proceeding with the state transition logic."
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "bug_report": {
            "BugID": "STORM-2873",
            "Title": "Frequent Deletion of Ephemeral Znodes in Backpressure Implementation Causes NoAuthException",
            "Description": "The backpressure implementation in Apache Storm is deleting ephemeral znodes too frequently, leading to a Zookeeper issue where the system encounters a NoAuthException due to rapid deletion and creation of the same path. This behavior is problematic as it violates Zookeeper's constraints on ephemeral nodes.",
            "StackTrace": [
                "java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721",
                "at backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]",
                "at backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]",
                "at backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology that utilizes the backpressure feature.",
                "2. Monitor the Zookeeper logs for any deletion of ephemeral znodes.",
                "3. Observe the frequency of deletions and check for NoAuthException errors."
            ],
            "ExpectedBehavior": "The backpressure implementation should manage ephemeral znodes without exceeding Zookeeper's constraints, avoiding frequent deletions and ensuring proper authorization.",
            "ObservedBehavior": "The backpressure implementation deletes ephemeral znodes too frequently, resulting in NoAuthException errors from Zookeeper.",
            "Resolution": "A fix for this issue has been implemented and tested, ensuring that the backpressure mechanism adheres to Zookeeper's constraints."
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "bug_report": {
            "BugID": "STORM-2279",
            "Title": "Internal Server Error when accessing Bolt page in Storm UI",
            "Description": "When attempting to access the bolt information page in the Storm UI, an Internal Server Error is encountered. This issue arises specifically when using the latest Storm code with a Vagrant setup. The error is linked to an ArrayIndexOutOfBoundsException occurring in the Nimbus service.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:101)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1369)",
                "at org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1353)",
                "at org.apache.storm.ui.core$component_page.invoke(core.clj:1026)",
                "at org.apache.storm.ui.core$fn__4308.invoke(core.clj:1214)",
                "at org.apache.storm.shade.compojure.core$make_route$fn__789.invoke(core.clj:100)",
                "at org.apache.storm.shade.compojure.core$if_route$fn__777.invoke(core.clj:46)",
                "at org.apache.storm.shade.compojure.core$if_method$fn__770.invoke(core.clj:31)",
                "at org.apache.storm.shade.compojure.core$routing$fn__795.invoke(core.clj:113)",
                "at clojure.core$some.invoke(core.clj:2570)",
                "at org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:113)",
                "at clojure.lang.RestFn.applyTo(RestFn.java:139)",
                "at clojure.core$apply.invoke(core.clj:632)",
                "at org.apache.storm.shade.compojure.core$routes$fn__799.invoke(core.clj:118)",
                "at org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__3573.invoke(json.clj:56)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)",
                "at org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__3102.invoke(reload.clj:22)",
                "at org.apache.storm.ui.helpers$requests_middleware$fn__2152.invoke(helpers.clj:54)",
                "at org.apache.storm.ui.core$catch_errors$fn__4474.invoke(core.clj:1460)",
                "at org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__1844.invoke(keyword_params.clj:35)",
                "at org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__1887.invoke(nested_params.clj:84)",
                "at org.apache.storm.shade.ring.middleware.params$wrap_params$fn__1816.invoke(params.clj:64)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)",
                "at org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__2139.invoke(flash.clj:35)",
                "at org.apache.storm.shade.ring.middleware.session$wrap_session$fn__2125.invoke(session.clj:98)",
                "at org.apache.storm.shade.ring.util.servlet$make_service_method$fn__1674.invoke(servlet.clj:127)",
                "at org.apache.storm.shade.ring.util.servlet$servlet$fn__1678.invoke(servlet.clj:136)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "1. Set up the Vagrant environment with the latest Storm code.",
                "2. Start the Storm UI.",
                "3. Navigate to the bolt information page using the URL: http://node1:8080/component.html?id=SlidingTimeCorrectness-winSec1slideSec1VerificationBolt&topology_id=SlidingWindowTestw1s1-2-1483646178.",
                "4. Observe the error message displayed."
            ],
            "ExpectedBehavior": "The bolt information page should load successfully, displaying the relevant details without any errors.",
            "ObservedBehavior": "An Internal Server Error is displayed, indicating a failure to retrieve the component page information due to an ArrayIndexOutOfBoundsException.",
            "Resolution": "The issue is caused by a negative index being used to access an ArrayList. A fix should ensure that the index is always non-negative before accessing the list."
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "bug_report": {
            "BugID": "STORM-3079",
            "Title": "Enhance Logging for KeyNotFoundException in Nimbus",
            "Description": "The current logging for KeyNotFoundException in the Nimbus component of Apache Storm does not provide sufficient information, as it logs a null message. This can lead to confusion when debugging issues related to missing blobs. The generated Thrift code does not support the getMessage() method, which results in the lack of a meaningful error message. Improving the log messages will aid in better understanding and troubleshooting of the issue.",
            "StackTrace": [
                "2018-05-16 21:15:04.596 o.a.s.d.n.Nimbus timer [INFO] Exception {}",
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology that references a blob that does not exist.",
                "2. Monitor the Nimbus logs for any exceptions thrown.",
                "3. Observe the logged exception message for KeyNotFoundException."
            ],
            "ExpectedBehavior": "When a KeyNotFoundException occurs, the log should provide a meaningful message indicating the missing key and context about the operation that failed.",
            "ObservedBehavior": "The log shows a null message for KeyNotFoundException, making it difficult to identify the cause of the error.",
            "Resolution": "A fix has been implemented to enhance the logging for KeyNotFoundException, providing more context in the log messages."
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "bug_report": {
            "BugID": "STORM-3096",
            "Title": "Race Condition in Nimbus Cleanup Causes Missing Blobstore Entries During Topology Submission",
            "Description": "After the fix for STORM-3053, which aimed to address a race condition in Nimbus where a timer could prematurely delete blobs during topology submission, the issue persists. The method `idsOfTopologiesWithPrivateWorkerKeys()` is identified as a potential source of the problem, as it may not be adequately handling the timing of blob deletions relative to topology submissions.",
            "StackTrace": [
                "org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Submit a topology with the name 'topology-testHardCoreFaultTolerance-4'.",
                "2. Monitor the Nimbus logs for cleanup operations.",
                "3. Observe the timing of blob deletions in relation to topology submissions."
            ],
            "ExpectedBehavior": "The Nimbus should successfully retain all necessary blobs during topology submission, ensuring that no WrappedKeyNotFoundException is thrown.",
            "ObservedBehavior": "The Nimbus throws a WrappedKeyNotFoundException indicating that the blob for the submitted topology is missing, suggesting that the cleanup process is deleting blobs prematurely.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1642",
            "Title": "NullPointerException During Deserialization in Apache Storm",
            "Description": "A NullPointerException (NPE) occurs when Apache Storm attempts to deserialize a Thrift object. The issue arises in the KryoTupleDeserializer when the buffer is not set correctly, leading to a failure in processing tuples. The user has confirmed that OutputCollector is not used concurrently in their code, and they have provided a custom serializer for the Thrift object being passed between bolts.",
            "StackTrace": [
                "2016-03-04 17:17:43.583 b.s.util [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]",
                "Caused by: java.lang.NullPointerException",
                "    at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]",
                "    at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]",
                "    ... 6 more",
                "2016-03-04 17:17:43.648 b.s.util [ERROR] Halting process: (\"Worker died\")",
                "java.lang.RuntimeException: (\"Worker died\")",
                "    at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.6.0.jar:?]",
                "    at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]"
            ],
            "StepsToReproduce": [
                "1. Set up an Apache Storm environment with a Thrift object being passed between bolts.",
                "2. Implement a custom serializer for the Thrift object.",
                "3. Ensure that OutputCollector is not used concurrently in the code.",
                "4. Trigger the deserialization process in the Storm topology."
            ],
            "ExpectedBehavior": "The Thrift object should be deserialized without any exceptions, allowing the Storm topology to process tuples successfully.",
            "ObservedBehavior": "A NullPointerException is thrown during the deserialization process, causing the worker to die and halt the processing.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "bug_report": {
            "BugID": "STORM-2700",
            "Title": "Blobstore ACL Check Occurs Even When Disabled",
            "Description": "When the configuration parameter `storm.blobstore.acl.validation.enabled` is set to `false`, the blobstore still performs ACL checks, leading to authorization errors when accessing blobs. This behavior contradicts the expected functionality of disabling ACL checks.",
            "StackTrace": [
                "2017-08-21 13:56:19.800 o.a.s.d.s.Slot SLOT_6702 [ERROR] Error when processing event",
                "java.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)",
                "at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]",
                "at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]",
                "at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: org.apache.storm.generated.AuthorizationException",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]"
            ],
            "StepsToReproduce": [
                "1. Create a blobstore with permission set to one user (e.g., mapredqa).",
                "   Command: sudo -u mapredqa storm blobstore create --file test-blobstore.txt --acl u:mapredqa:rwa key1",
                "2. Set the configuration parameter to disable ACL validation.",
                "   Configuration: storm.blobstore.acl.validation.enabled: false",
                "3. Submit a topology with the blobstore configuration as a different user (e.g., ethan).",
                "   Command: sudo -u ethan storm jar /tmp/storm-starter-2.0.0-SNAPSHOT.jar org.apache.storm.starter.WordCountTopology wc -c topology.blobstore.map='{\"key1\":{\"localname\":\"test-blobstore.txt\", \"uncompress\":false}}'"
            ],
            "ExpectedBehavior": "The blobstore should not perform any ACL checks when `storm.blobstore.acl.validation.enabled` is set to `false`, allowing any user to access the blob without authorization errors.",
            "ObservedBehavior": "The blobstore still checks ACLs and throws an `AuthorizationException` indicating that the user does not have READ access to the specified blob, despite the ACL validation being disabled.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "bug_report": {
            "BugID": "STORM-1663",
            "Title": "Exception Thrown When Refreshing Active Topology Page in Storm UI",
            "Description": "When clicking on an active topology from the Storm UI home page and subsequently refreshing the page, an exception is thrown, preventing the user from viewing the topology details.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:101)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)",
                "at org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)",
                "at org.apache.storm.ui.core$topology_page.invoke(core.clj:638)",
                "at org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)",
                "at org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)",
                "at org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)",
                "at org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)",
                "at org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)",
                "at clojure.core$some.invoke(core.clj:2570)",
                "at org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)",
                "at clojure.lang.RestFn.applyTo(RestFn.java:139)",
                "at clojure.core$apply.invoke(core.clj:632)",
                "at org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)",
                "at org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)",
                "at org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)",
                "at org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)",
                "at org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)",
                "at org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)",
                "at org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)",
                "at org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)",
                "at org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)",
                "at org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)",
                "at org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)",
                "at org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)",
                "at org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)",
                "at org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "1. Navigate to the Storm UI home page.",
                "2. Click on an active topology.",
                "3. Refresh the page."
            ],
            "ExpectedBehavior": "The active topology page should refresh without any errors, displaying the current state of the topology.",
            "ObservedBehavior": "An exception is thrown, preventing the page from displaying the topology details.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "bug_report": {
            "BugID": "STORM-2518",
            "Title": "NullPointerException when adding ACL for user during artifact upload",
            "Description": "A NullPointerException occurs when attempting to add an Access Control List (ACL) for a user while uploading artifacts. The 'name' field in the ACL is optional according to the Thrift specification, but the Nimbus component does not check for null values before processing, leading to this error.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]",
                "at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]"
            ],
            "StepsToReproduce": [
                "1. Attempt to upload an artifact to a secured cluster.",
                "2. Ensure that the ACL for the user being added does not include a 'name' field.",
                "3. Observe the error that occurs during the upload process."
            ],
            "ExpectedBehavior": "The artifact should upload successfully without any errors, even if the 'name' field in the ACL is not provided.",
            "ObservedBehavior": "A NullPointerException is thrown, causing the upload to fail.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "bug_report": {
            "BugID": "STORM-3124",
            "Title": "Pacemaker Connection Failure Causes Topology Launch Issues",
            "Description": "The system experiences sporadic failures when attempting to communicate with the Pacemaker service, resulting in the inability to launch topologies. The error logs indicate repeated connection timeouts and failures to retrieve heartbeat information from the Pacemaker server.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:199) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Apache Storm cluster with the Pacemaker service configured.",
                "2. Attempt to launch a topology using the Nimbus server.",
                "3. Monitor the logs for connection attempts to the Pacemaker service."
            ],
            "ExpectedBehavior": "The topology should launch successfully without any connection errors to the Pacemaker service.",
            "ObservedBehavior": "The topology fails to launch, and the logs show repeated connection timeouts and errors indicating that the system cannot connect to the Pacemaker service.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2095",
            "Title": "Nimbus Fails to Start Due to DirectoryNotEmptyException During Blobstore Key Deletion",
            "Description": "When a large blobstore key is being created and Nimbus is restarted, it encounters a DirectoryNotEmptyException, preventing it from starting up properly. This issue arises specifically when the blobstore key is partially created and Nimbus attempts to delete it upon restart.",
            "StackTrace": [
                "2016-09-14 15:07:48.581 o.a.s.d.nimbus [ERROR] Error on initialization of server service-handler",
                "java.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file",
                "\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)",
                "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
                "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "\tat java.lang.reflect.Method.invoke(Method.java:497)",
                "\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)",
                "\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)",
                "\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)",
                "\tat clojure.lang.AFn.applyToHelper(AFn.java:156)",
                "\tat clojure.lang.AFn.applyTo(AFn.java:144)",
                "\tat clojure.core$apply.invoke(core.clj:630)",
                "\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)",
                "\tat clojure.lang.RestFn.invoke(RestFn.java:421)",
                "\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)",
                "\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)",
                "\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)",
                "\tat clojure.lang.AFn.applyToHelper(AFn.java:152)",
                "\tat clojure.lang.AFn.applyTo(AFn.java:144)",
                "\tat org.apache.storm.daemon.nimbus.main(Unknown Source)"
            ],
            "StepsToReproduce": [
                "1) Create a blobstore key for a large file (1 or 2 GB). The size of the file does not matter if Nimbus can be killed while the blob is being created.",
                "2) While the blob is being created, restart Nimbus.",
                "3) Observe that Nimbus fails to start due to a DirectoryNotEmptyException."
            ],
            "ExpectedBehavior": "The partial blobstore key should be deleted cleanly, allowing Nimbus to start without issues.",
            "ObservedBehavior": "Nimbus fails to start and continuously logs DirectoryNotEmptyException errors, preventing recovery.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2847",
            "Title": "IllegalArgumentException Thrown After Rebalance in storm-kafka-client Spout",
            "Description": "After a rebalance, the storm-kafka-client spout attempts to check the current position of partitions that are no longer assigned to the current spout instance, leading to an IllegalArgumentException. This issue occurs in a topology with multiple spout instances.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262)",
                "at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)"
            ],
            "StepsToReproduce": [
                "1. Set up a topology with multiple instances of the storm-kafka-client spout.",
                "2. Trigger a rebalance in the topology.",
                "3. Observe the logs for any IllegalArgumentException related to partition positions."
            ],
            "ExpectedBehavior": "The storm-kafka-client spout should handle partition assignments correctly after a rebalance, without throwing exceptions.",
            "ObservedBehavior": "An IllegalArgumentException is thrown when the spout attempts to check the position of partitions that are not assigned to it after a rebalance.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "bug_report": {
            "BugID": "STORM-1114",
            "Title": "Race Condition in Trident Zookeeper Node Creation/Deletion",
            "Description": "In a production environment using a Trident topology, workers encounter a race condition when attempting to create or delete Zookeeper nodes. This results in exceptions being thrown, causing the worker processes to terminate unexpectedly. The issue arises from concurrent attempts to create a node that already exists or delete a node that has already been removed.",
            "StackTrace": [
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "... 9 more",
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "... 12 more"
            ],
            "StepsToReproduce": [
                "Deploy a Trident topology that interacts with Zookeeper.",
                "Simultaneously start multiple worker processes.",
                "Trigger operations that involve creating and deleting Zookeeper nodes."
            ],
            "ExpectedBehavior": "Workers should be able to create and delete Zookeeper nodes without encountering exceptions, ensuring stable operation.",
            "ObservedBehavior": "Workers throw exceptions indicating that they are trying to create a node that already exists or delete a node that does not exist, leading to process termination.",
            "Resolution": "A fix for this issue has been implemented and tested."
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "bug_report": {
            "BugID": "STORM-2811",
            "Title": "NullPointerException in Nimbus when killing the same topology multiple times",
            "Description": "A NullPointerException (NPE) occurs in the Nimbus component of Apache Storm when attempting to kill the same topology multiple times. This issue arises from the method `getTopoId` returning null, which is not handled properly in the `tryReadTopoConfFromName` method, leading to the NPE.",
            "StackTrace": [
                "2017-11-12 08:45:50.353 o.a.s.d.n.Nimbus pool-14-thread-47 [WARN] Kill topology exception. (topology name='SlidingWindowTest-window20-slide10')",
                "java.lang.NullPointerException: null",
                "at org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology named 'SlidingWindowTest-window20-slide10'.",
                "2. Execute the command to kill the topology.",
                "3. Immediately execute the command to kill the same topology again.",
                "4. Observe the logs for any warnings or errors."
            ],
            "ExpectedBehavior": "The topology should be killed without any exceptions, even if the kill command is issued multiple times.",
            "ObservedBehavior": "A NullPointerException is thrown in the Nimbus component when attempting to kill the same topology multiple times.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2903",
            "Title": "NullPointerException in AbstractAutoCreds during Hive token mechanism initialization",
            "Description": "A NullPointerException is thrown when attempting to initialize the Hive token mechanism, specifically in the AbstractAutoCreds class. This issue occurs when the subject parameter is null, leading to a failure in adding tokens to the UserGroupInformation (UGI).",
            "StackTrace": [
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219)",
                "at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118)",
                "at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228)",
                "... 10 more",
                "2018-01-19 16:23:26.157 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")"
            ],
            "StepsToReproduce": [
                "1. Set up the environment for testing the Hive token mechanism.",
                "2. Attempt to initialize the Hive token mechanism.",
                "3. Observe the logs for any exceptions thrown during the process."
            ],
            "ExpectedBehavior": "The Hive token mechanism should initialize successfully without throwing any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown, halting the initialization process.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "bug_report": {
            "BugID": "STORM-3168",
            "Title": "AsyncLocalizer Cleanup Fails to Log and Crashes",
            "Description": "The AsyncLocalizer component in Apache Storm fails to log cleanup messages and appears to crash intermittently, leading to repeated blobstore download error messages in the logs. This issue was observed during a debugging session where the expected cleanup debug messages were not logged, and the component only resumed logging after a restart.",
            "StackTrace": [
                "2018-07-30 23:25:35.691 o.a.s.l.AsyncLocalizer AsyncLocalizer Executor - 2 [ERROR] Could not update blob, will retry again later",
                "java.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...",
                "at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]",
                "at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]",
                "at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]",
                "at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]",
                "Caused by: java.lang.RuntimeException: Could not download...",
                "at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_131]",
                "... 3 more",
                "Caused by: org.apache.storm.generated.KeyNotFoundException",
                "at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]",
                "at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]",
                "at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_131]",
                "... 3 more"
            ],
            "StepsToReproduce": [
                "1. Enable debug logging for the AsyncLocalizer component.",
                "2. Monitor the logs for cleanup messages.",
                "3. Wait for the cleanup process to run (approximately every 30 seconds).",
                "4. Observe that the expected cleanup debug messages are not logged.",
                "5. Restart the supervisor and check the logs again."
            ],
            "ExpectedBehavior": "The AsyncLocalizer should log cleanup messages every 30 seconds without crashing.",
            "ObservedBehavior": "The AsyncLocalizer fails to log cleanup messages and crashes, resulting in repeated error messages regarding blob updates.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "bug_report": {
            "BugID": "STORM-2986",
            "Title": "NullPointerException in LogCleaner due to missing workers-artifacts directory",
            "Description": "When starting the LogCleaner thread with the configuration `logviewer.cleanup.interval.secs: 10`, a NullPointerException occurs because the `workers-artifacts` directory does not exist prior to submitting any topologies. This results in the LogCleaner failing to clean up old logs.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "1. Set the configuration `logviewer.cleanup.interval.secs: 10` in the log viewer settings.",
                "2. Start the LogCleaner thread.",
                "3. Observe the log output for any exceptions."
            ],
            "ExpectedBehavior": "The LogCleaner should start without errors and clean up old logs as per the configured interval.",
            "ObservedBehavior": "A NullPointerException is thrown, indicating that the LogCleaner cannot find the necessary directories to perform its cleanup operation.",
            "Resolution": "A fix has been implemented to ensure that the LogCleaner checks for the existence of the `workers-artifacts` directory before attempting to clean up logs. Users can temporarily resolve the issue by manually creating the directory."
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2197",
            "Title": "NimbusClient Connection Leak Due to Unclosed TSocket in ThriftClient on Connection Errors",
            "Description": "The Nimbus client fails to close TSocket connections when encountering errors during connection attempts to Nimbus. This leads to resource leaks and potential exhaustion of available connections. The issue arises specifically when the SaslClientTransport fails to initiate a session, as indicated by the stack trace.",
            "StackTrace": [
                "org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]",
                "javax.security.auth.Subject.doAs(Subject.java:415) ~[?:1.7.0_60]",
                "backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]"
            ],
            "StepsToReproduce": [
                "1. Attempt to connect to Nimbus using the NimbusClient.",
                "2. Ensure that the connection fails due to a configuration error or network issue.",
                "3. Monitor the system resources to observe if TSocket connections are being closed properly."
            ],
            "ExpectedBehavior": "The NimbusClient should close any TSocket connections upon encountering an error during the connection attempt, preventing resource leaks.",
            "ObservedBehavior": "TSocket connections remain open even after connection errors, leading to potential resource exhaustion.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "bug_report": {
            "BugID": "STORM-1596",
            "Title": "Concurrency Issue with Kerberos TGT Sharing Leading to Service Failures",
            "Description": "When multiple threads access the same Subject, it can lead to a situation where a ServiceTicket in use by one thread is destroyed by another thread. This issue manifests when running the BasicDRPCTopology with high parallelism in a secure cluster, resulting in SASL negotiation failures.",
            "StackTrace": [
                "2016-01-20 15:52:26.904 o.a.t.t.TSaslTransport [ERROR] SASL negotiation failure",
                "javax.security.sasl.SaslException: GSS initiate failed",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]",
                "at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]",
                "at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_40]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]"
            ],
            "StepsToReproduce": [
                "1. Set up a secure cluster with Kerberos authentication.",
                "2. Run the BasicDRPCTopology with high parallelism.",
                "3. Monitor the logs for SASL negotiation failures."
            ],
            "ExpectedBehavior": "The system should handle multiple threads accessing the same Subject without causing any service failures or SASL negotiation errors.",
            "ObservedBehavior": "SASL negotiation failures occur, leading to service disruptions when multiple threads access the same Subject.",
            "Resolution": "[Provide additional details about the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2142",
            "Title": "Async Loop Dies on Exception in EvaluationFilter/EvaluationFunction",
            "Description": "When an Exception is thrown by EvaluationFilter or EvaluationFunction, the async loop for the executor terminates unexpectedly, while other components continue to function. This behavior is contrary to the expected handling of exceptions, particularly for InterruptedException and InterruptedIOException, which should only log the error without terminating the loop.",
            "StackTrace": [
                "2016-10-08 14:12:29.597 o.a.s.u.Utils Thread-23-b-0-LOGICALFILTER_6-LOGICALPROJECT_7-executor[5 5] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "...",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]",
                "at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]",
                "at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]",
                "...",
                "Caused by: java.lang.RuntimeException: Cannot convert null to int",
                "at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]",
                "at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]",
                "at SC.eval0(Unknown Source) ~[?:?]"
            ],
            "StepsToReproduce": [
                "1. Set up an Apache Storm environment with EvaluationFilter and EvaluationFunction.",
                "2. Trigger a scenario where EvaluationFilter or EvaluationFunction throws an Exception.",
                "3. Observe the behavior of the async loop for the executor."
            ],
            "ExpectedBehavior": "The async loop should log the error and continue processing without terminating.",
            "ObservedBehavior": "The async loop dies, causing disruption in processing while other components continue to work.",
            "Resolution": "The implementation of ReportErrorAndDie has been modified to ensure that it behaves consistently with version 1.x, where it only terminates the loop for specific exceptions."
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "bug_report": {
            "BugID": "STORM-2400",
            "Title": "Intermittent KeeperException in LeaderLatch#getLeader() due to Node Removal",
            "Description": "The method `LeaderLatch#getLeader()` intermittently throws a `KeeperException` with code `NONODE`. This issue arises when a participant's ephemeral Zookeeper node is removed due to a closed connection/session. The race condition occurs when a participant node is retrieved, but by the time `LeaderSelector#getLeader()` is invoked, the node has already been removed, leading to the exception. The current implementation does not retry on `NoNode` exceptions, which may lead to unexpected failures in the Nimbus component of Apache Storm.",
            "StackTrace": [
                "2016-11-15 06:09:33.954 o.a.s.d.nimbus [ERROR] Error when processing event",
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)"
            ],
            "StepsToReproduce": [
                "1. Set up a Zookeeper cluster and deploy the Apache Storm application.",
                "2. Start the Nimbus component and ensure it is running with multiple participant nodes.",
                "3. Simulate a network partition or a session timeout for one of the participant nodes.",
                "4. Observe the logs for any occurrences of `KeeperException` with code `NoNode` when calling `LeaderLatch#getLeader()`."
            ],
            "ExpectedBehavior": "The `LeaderLatch#getLeader()` method should successfully return the leader participant without throwing a `KeeperException` when the participant node is still valid.",
            "ObservedBehavior": "The method intermittently throws a `KeeperException` with code `NoNode`, indicating that the participant node has been removed, leading to potential failures in the Nimbus component.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3084",
            "Title": "NullPointerException on Nimbus Startup in Apache Storm 2.x",
            "Description": "During the startup of the Nimbus server in Apache Storm version 2.0.0.y, a NullPointerException is thrown, causing the server to halt. This issue occurs when the Nimbus attempts to read supervisor details, leading to a failure in processing events.",
            "StackTrace": [
                "2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event java.lang.RuntimeException: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event java.lang.RuntimeException: Halting process: Error while processing event at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus server using Apache Storm version 2.0.0.y.",
                "2. Monitor the server logs for any errors during startup."
            ],
            "ExpectedBehavior": "The Nimbus server should start successfully without throwing any exceptions.",
            "ObservedBehavior": "The Nimbus server throws a NullPointerException during startup, causing it to halt.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "bug_report": {
            "BugID": "STORM-3118",
            "Title": "IndexOutOfBoundsException in Pacemaker due to Netty Buffer Overflow",
            "Description": "The Nimbus service encounters an IndexOutOfBoundsException when attempting to write data to a Netty buffer during topology submission. This issue prevents the successful submission of topologies, leading to operational disruptions.",
            "StackTrace": [
                "2018-06-21 08:55:17.762 o.a.s.p.PacemakerClientHandler client-worker-2 [ERROR] Exception occurred in Pacemaker.",
                "org.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus service.",
                "2. Attempt to submit a topology using the command: `storm submit <topology-name>`.",
                "3. Observe the logs for any errors related to Pacemaker."
            ],
            "ExpectedBehavior": "The topology should be submitted successfully without any exceptions.",
            "ObservedBehavior": "An IndexOutOfBoundsException occurs, preventing the topology from being submitted.",
            "Resolution": "[Provide additional details on the resolution or fix applied]"
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "bug_report": {
            "BugID": "STORM-2158",
            "Title": "OutOfMemoryError in Nimbus's SimpleTransportPlugin due to Malformed Thrift Request",
            "Description": "An OutOfMemoryError is thrown by Nimbus's SimpleTransportPlugin when a malformed Thrift request is sent to the server. This issue occurs because the maxReadBufferBytes parameter is not specified, leading to excessive memory consumption when handling requests.",
            "StackTrace": [
                "java.lang.OutOfMemoryError: Java heap space",
                "at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]",
                "at java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus server in an unsecured Storm cluster.",
                "2. Send a malformed Thrift request using the command: echo \"Hello\" | nc localhost 6627.",
                "3. Monitor the Nimbus logs for any errors."
            ],
            "ExpectedBehavior": "The Nimbus server should handle the malformed request gracefully without throwing an OutOfMemoryError.",
            "ObservedBehavior": "The Nimbus server throws an OutOfMemoryError, causing it to shut down unexpectedly.",
            "Resolution": "The issue has been fixed by specifying the maxReadBufferBytes parameter in the THsHaServer's configuration."
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "bug_report": {
            "BugID": "STORM-2682",
            "Title": "Supervisor Crashes with NullPointerException During Blob Update",
            "Description": "The Apache Storm supervisor crashes approximately 30 seconds after startup due to a NullPointerException when processing events related to blob updates. This issue occurs in a Dockerized environment based on Debian Jessie, running on Ubuntu Trusty with OpenJDK8.",
            "StackTrace": [
                "2017-08-07 17:12:34.620 o.a.s.e.EventManagerImp Thread-4 [ERROR] {} Error when processing event",
                "java.lang.NullPointerException: null",
                "    at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]",
                "    at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]",
                "    at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]",
                "    at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]",
                "    at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]",
                "2017-08-07 17:12:34.620 o.a.s.u.Utils Thread-4 [ERROR] Halting process: Error when processing an event",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "    at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]",
                "    at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]",
                "2017-08-07 17:12:34.631 o.a.s.d.s.Supervisor Thread-5 [INFO] Shutting down supervisor 65a0f977-474c-4938-a4f5-bc99939e96ff"
            ],
            "StepsToReproduce": [
                "1. Deploy the Apache Storm supervisor in a Dockerized environment based on Debian Jessie.",
                "2. Start the supervisor and allow it to run for approximately 30 seconds.",
                "3. Monitor the logs for any errors related to blob updates."
            ],
            "ExpectedBehavior": "The supervisor should start successfully and remain operational without crashing.",
            "ObservedBehavior": "The supervisor crashes with a NullPointerException after approximately 30 seconds of operation, leading to a shutdown.",
            "Resolution": "[Provide additional details about the fix or workaround]"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "bug_report": {
            "BugID": "STORM-3103",
            "Title": "Nimbus NullPointerException during Shutdown Causes Leadership Issues",
            "Description": "A NullPointerException (NPE) occurs in the Nimbus class during the shutdown process, leading to leadership confusion and improper handling of topology submissions. This issue arises when Nimbus attempts to read supervisor details and compute new scheduler assignments, resulting in a forced halt of the Nimbus server.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus server with a topology.",
                "2. Trigger a shutdown of the Nimbus server.",
                "3. Observe the logs for any NullPointerExceptions during the shutdown process."
            ],
            "ExpectedBehavior": "The Nimbus server should shut down cleanly without throwing any exceptions, and leadership should be maintained correctly.",
            "ObservedBehavior": "During the shutdown process, a NullPointerException is thrown, causing the Nimbus server to halt unexpectedly and leading to leadership confusion.",
            "Resolution": "A fix for this issue has been implemented and tested, ensuring that the Nimbus server can shut down cleanly without encountering NullPointerExceptions."
        }
    }
]