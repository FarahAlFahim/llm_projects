[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "bug_report": {
            "BugID": "STORM-2443",
            "Title": "NullPointerException in Nimbus when changing log configuration",
            "Description": "A NullPointerException occurs in the Nimbus service when attempting to change the log configuration for a topology via the UI. This issue prevents users from modifying log levels as intended.",
            "StackTrace": [
                "2017-03-30 16:53:26.954 o.a.s.d.n.Nimbus pool-14-thread-56 [WARN] set log config topology exception. (topology id='rolling-1-1490860365')",
                "java.lang.NullPointerException: null",
                "at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]"
            ],
            "StepsToReproduce": [
                "1. Navigate to the UI topology page.",
                "2. Select a topology to modify.",
                "3. Attempt to change the log level configuration.",
                "4. Observe the error in the logs."
            ],
            "ExpectedBehavior": "The log level configuration should be updated without any errors.",
            "ObservedBehavior": "A NullPointerException is thrown, preventing the log level from being changed.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "bug_report": {
            "BugID": "STORM-3213",
            "Title": "500 Server Error on Acker Component Page in Storm UI",
            "Description": "A 500 Server Error occurs when attempting to access the Acker component page in the Storm UI. This issue is related to a NullPointerException in the Nimbus service.",
            "StackTrace": [
                "org.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)",
                "at org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)",
                "at org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)",
                "at org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)",
                "2018-09-05 16:15:24.927 o.a.s.t.ProcessFunction pool-21-thread-55 [ERROR] Internal error processing getComponentPageInfo",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "1. Open the Storm UI.",
                "2. Navigate to the Acker component page.",
                "3. Observe the error message displayed."
            ],
            "ExpectedBehavior": "The Acker component page should load successfully without any errors.",
            "ObservedBehavior": "A 500 Server Error is displayed, indicating an internal error processing the request.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "bug_report": {
            "BugID": "STORM-2496",
            "Title": "Supervisor Fails to Download Artifacts Due to Missing READ Permissions",
            "Description": "When submitting a topology with dependency artifacts, the submitter uploads artifacts to the blobstore using the user account that runs the submission. Since these artifacts are shared globally, other users may need to access them. However, if the uploaded artifacts do not have READ permissions for all users, the Supervisor fails to download the artifact, resulting in a crash.",
            "StackTrace": [
                "2017-04-28 04:56:46.594 o.a.s.l.AsyncLocalizer Async Localizer [WARN] Caught Exception While Downloading (rethrowing)...",
                "org.apache.storm.generated.AuthorizationException: null",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) ~[?:1.8.0_112]",
                "2017-04-28 04:56:46.597 o.a.s.d.s.Slot SLOT_6701 [ERROR] Error when processing event",
                "java.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)",
                "at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]",
                "at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]",
                "at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "Caused by: org.apache.storm.generated.AuthorizationException",
                "at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) ~[?:1.8.0_112]",
                "2017-04-28 04:56:46.597 o.a.s.u.Utils SLOT_6701 [ERROR] Halting process: Error when processing an event",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]",
                "at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]"
            ],
            "StepsToReproduce": [
                "1. Submit a topology using a specific user with dependency artifacts.",
                "2. Ensure that the artifacts are uploaded to the blobstore without READ permissions for all users.",
                "3. Attempt to run the topology."
            ],
            "ExpectedBehavior": "The Supervisor should be able to download the artifacts without crashing.",
            "ObservedBehavior": "The Supervisor fails to download the artifacts due to missing READ permissions, resulting in a crash.",
            "Resolution": "To resolve this issue, ensure that all uploaded artifacts have READ permissions for all users, or at least for the Supervisor."
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "bug_report": {
            "BugID": "STORM-2879",
            "Title": "Supervisor Collapses Continuously Due to Expired Local Assignments",
            "Description": "When a topology is reassigned or killed in a cluster, the supervisor deletes four files related to an overdue storm. However, if an exception occurs during the deletion of these files, an expired local assignment remains on disk. This leads to continuous supervisor collapses when it attempts to recover from the local assignments, resulting in a KeyNotFoundException.",
            "StackTrace": [
                "2017-12-27 14:15:04.434 o.a.s.l.AsyncLocalizer [INFO] Cleaning up unused topologies in /opt/meituan/storm/data/supervisor/stormdist",
                "2017-12-27 14:15:04.434 o.a.s.d.s.AdvancedFSOps [INFO] Deleting path /opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785",
                "2017-12-27 14:15:04.445 o.a.s.d.s.Slot [INFO] STATE EMPTY msInState: 109 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 1",
                "2017-12-27 14:15:04.471 o.a.s.d.s.Supervisor [INFO] Starting supervisor with id 255d3fed-f3ee-4c7e-8a08-b693c9a6a072 at host gq-data-rt48.gq.sankuai.com.",
                "2017-12-27 14:15:04.502 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.",
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]",
                "at org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]"
            ],
            "StepsToReproduce": [
                "1. Assign a topology to a cluster.",
                "2. Kill or reassign the topology.",
                "3. Observe the supervisor's behavior as it attempts to clean up the files.",
                "4. Check for any exceptions in the logs related to blob downloads."
            ],
            "ExpectedBehavior": "The supervisor should successfully clean up the files and recover without any exceptions.",
            "ObservedBehavior": "The supervisor collapses continuously due to KeyNotFoundException when trying to recover from expired local assignments.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3012",
            "Title": "Nimbus Crashes with NullPointerException When Pacemaker is Restarted",
            "Description": "When the Pacemaker service is restarted, the Nimbus component crashes due to a NullPointerException (NPE) caused by a null response from the PacemakerClient. This issue occurs during the heartbeat process, leading to a failure in processing events.",
            "StackTrace": [
                "org.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.",
                "at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "1. Start the Nimbus service.",
                "2. Restart the Pacemaker service.",
                "3. Observe the Nimbus logs for any errors."
            ],
            "ExpectedBehavior": "Nimbus should continue to operate normally after the Pacemaker service is restarted.",
            "ObservedBehavior": "Nimbus crashes with a NullPointerException when the Pacemaker service is restarted.",
            "Resolution": "A fix for this issue has been checked into the codebase and tested."
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "bug_report": {
            "BugID": "STORM-3073",
            "Title": "Worker Crashes Due to Full Pending Emits Queue",
            "Description": "While running the ThroughputVsLatency topology from the Apache Storm examples, an error occurs indicating that the async loop has died due to a full pending emits queue. This issue can lead to worker crashes under certain conditions.",
            "StackTrace": [
                "2018-05-15 11:35:28.365 o.a.s.u.Utils Thread-16-spout-executor[8, 8] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.IllegalStateException: Queue full",
                "at org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]",
                "Caused by: java.lang.IllegalStateException: Queue full",
                "at java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]",
                "at org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Clone the Apache Storm repository from GitHub.",
                "Navigate to the examples directory.",
                "Run the ThroughputVsLatency topology using the command: [Provide command details].",
                "Monitor the logs for errors related to the async loop and pending emits."
            ],
            "ExpectedBehavior": "The topology should run without errors, and the pending emits queue should not become full.",
            "ObservedBehavior": "The topology crashes with an error indicating that the async loop has died due to a full pending emits queue.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "bug_report": {
            "BugID": "STORM-1672",
            "Title": "ClassCastException in StatsUtil when accessing component page",
            "Description": "A ClassCastException occurs in the StatsUtil class when attempting to access the component page in the UI. This issue prevents the proper display of statistics for components.",
            "StackTrace": [
                "2016-03-31 14:21:44.576 o.a.s.t.s.AbstractNonblockingServer$FrameBuffer [ERROR] Unexpected throwable while invoking!",
                "java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map",
                "at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)",
                "at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)",
                "at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)",
                "at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)",
                "at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)",
                "at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)",
                "at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)",
                "at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:744)"
            ],
            "StepsToReproduce": [
                "Navigate to the component page in the Apache Storm UI.",
                "Observe the statistics being loaded for the components."
            ],
            "ExpectedBehavior": "The component page should display the statistics without any errors.",
            "ObservedBehavior": "A ClassCastException is thrown, preventing the statistics from being displayed.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "bug_report": {
            "BugID": "STORM-1520",
            "Title": "Nimbus Clojure/Zookeeper: 'stateChanged' Method Not Found Error",
            "Description": "After deploying or undeploying topologies, Nimbus becomes unresponsive and requires a manual restart. The following error appears in the nimbus.log:\n\n```\n2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception\njava.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n```\n\nBasic functionality does not seem to be affected.",
            "StackTrace": [
                "2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception",
                "java.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "at org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)",
                "at org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)",
                "at org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)",
                "at org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)",
                "at java.util.concurrent.FutureTask.run(FutureTask.java:266)",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "Deploy a topology using Nimbus.",
                "Undeploy the same topology.",
                "Check the nimbus.log for errors."
            ],
            "ExpectedBehavior": "Nimbus should handle topology deployment and undeployment without errors and remain responsive.",
            "ObservedBehavior": "Nimbus becomes unresponsive and requires a manual restart after the error is logged.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1977",
            "Title": "Nimbus crashes on getClusterInfo when missing replicated topology codes",
            "Description": "While investigating STORM-1976, it was found that Nimbus can gain leadership without having all topology codes. This leads to a crash when getClusterInfo is requested, as Nimbus attempts to access a missing topology code.",
            "StackTrace": [
                "KeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)",
                "...",
                "at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)",
                "at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)",
                "...",
                "at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)",
                "at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)",
                "...",
                "java.lang.RuntimeException: (\"Error when processing an event\")",
                "at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)",
                "at clojure.lang.RestFn.invoke(RestFn.java:423)",
                "at org.apache.storm.daemon.nimbus$nimbus_data$fn__8727.invoke(nimbus.clj:205)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "1. Comment out cleanup-corrupt-topologies! from nimbus.clj.",
                "2. Patch the Storm cluster.",
                "3. Launch Nimbus 1 (leader).",
                "4. Run a topology.",
                "5. Kill Nimbus 1.",
                "6. Launch Nimbus 2 from a different node.",
                "7. Request getClusterInfo from Nimbus 2."
            ],
            "ExpectedBehavior": "Nimbus should not crash and should return valid cluster information.",
            "ObservedBehavior": "Nimbus crashes with a KeyNotFoundException when getClusterInfo is requested.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "bug_report": {
            "BugID": "STORM-2988",
            "Title": "Error on Initialization of Worker with JmxStormReporter Configuration",
            "Description": "When using the JmxStormReporter in Apache Storm, workers fail to initialize and throw an IllegalArgumentException. This occurs despite the configuration appearing correct according to the documentation.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String",
                "at org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.RestFn.invoke(RestFn.java:512) [storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]",
                "at clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]",
                "java.lang.RuntimeException: (\"Error on initialization\")",
                "at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.RestFn.invoke(RestFn.java:512) [storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]",
                "at clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]"
            ],
            "StepsToReproduce": [
                "Configure metrics v2 in storm.yaml with the following settings:",
                "storm.metrics.reporters:",
                "  - class: \"org.apache.storm.metrics2.reporters.JmxStormReporter\"",
                "    daemons:",
                "        - \"supervisor\"",
                "        - \"nimbus\"",
                "        - \"worker\"",
                "    report.period: 10",
                "    report.period.units: \"SECONDS\"",
                "Start the nimbus and supervisor processes.",
                "Submit a topology."
            ],
            "ExpectedBehavior": "Workers should initialize successfully and report metrics to JMX without errors.",
            "ObservedBehavior": "Workers fail to initialize and log an IllegalArgumentException related to the JmxStormReporter configuration.",
            "Resolution": "The issue has been resolved in version 1.2.2."
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "bug_report": {
            "BugID": "STORM-2321",
            "Title": "Nimbus Fails to Start After Restart During HA Testing",
            "Description": "During high availability (HA) testing, the Nimbus service was restarted, but it failed to come up afterward. The logs indicate multiple errors related to blob storage and Zookeeper state management.",
            "StackTrace": [
                "2017-01-18 04:57:58.247 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with key KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar",
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)",
                "at org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)",
                "at org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)",
                "at org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)",
                "Caused by: org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)"
            ],
            "StepsToReproduce": [
                "1. Restart the Nimbus service during HA testing.",
                "2. Monitor the logs for any errors or exceptions."
            ],
            "ExpectedBehavior": "The Nimbus service should start successfully after a restart.",
            "ObservedBehavior": "The Nimbus service fails to start, with multiple errors logged related to blob storage and Zookeeper.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "bug_report": {
            "BugID": "STORM-3013",
            "Title": "Exception Thrown When Producing Records to Kafka After Deactivating Storm Topology",
            "Description": "When the Storm topology is deactivated and records are produced into Kafka, an exception is thrown indicating that the consumer has already been closed. This issue needs to be addressed to prevent disruptions in data processing.",
            "StackTrace": [
                "2018-03-28 09:50:23.804 o.a.s.d.executor Thread-83-kafkaLogs-executor[130 130] [INFO] Deactivating spout kafkaLogs:(130)",
                "2018-03-28 09:51:01.289 o.a.s.util Thread-17-kafkaLogs-executor[139 139] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]",
                "Caused by: java.lang.IllegalStateException: This consumer has already been closed.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]",
                "at org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]",
                "at clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$filter$fn__4580.invoke(core.clj:2679) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.Cons.next(Cons.java:39) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.RT.next(RT.java:674) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6478$G__6473__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]",
                "at clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]",
                "at clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]"
            ],
            "StepsToReproduce": [
                "Deactivate the Storm topology.",
                "Produce records into Kafka."
            ],
            "ExpectedBehavior": "No exceptions should be thrown when producing records into Kafka after deactivating the Storm topology.",
            "ObservedBehavior": "An exception is thrown indicating that the consumer has already been closed.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "bug_report": {
            "BugID": "STORM-3117",
            "Title": "Nimbus Restarts When Deleting Blobs for Running Topologies",
            "Description": "Deleting blobs for running topologies causes Nimbus to get stuck and restart. This issue occurs when the following pseudo-code is executed:\n\n```java\ncluster.submitTopology(cluster.getTopologiesJarFile(), topoName, config, topology);\ncluster.waitTopologyUp(topoName);\ncluster.deleteAllBlobs();\n```\n\nThe logs indicate that Nimbus is unable to find the necessary credentials for the topology, leading to a continuous restart loop.",
            "StackTrace": [
                "2018-06-20 15:48:14.979 o.a.s.d.n.Nimbus pool-27-thread-722 [WARN] get blob meta exception.",
                "org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]"
            ],
            "StepsToReproduce": [
                "1. Submit a topology using the provided pseudo-code.",
                "2. Wait for the topology to be fully up.",
                "3. Call the method to delete all blobs."
            ],
            "ExpectedBehavior": "Nimbus should successfully delete the blobs without restarting.",
            "ObservedBehavior": "Nimbus gets stuck and continuously restarts due to missing credentials for the topology.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "bug_report": {
            "BugID": "STORM-2993",
            "Title": "ClosedChannelException in Storm HDFS Bolt with Time Rotation Policy",
            "Description": "The Storm HDFS bolt throws a ClosedChannelException when the Time rotation policy is used, leading to failures in writing data to HDFS. This issue appears to be caused by improper synchronization in the timed rotation policy, which may allow the HDFS bolt to attempt writing to a closed writer.",
            "StackTrace": [
                "java.nio.channels.ClosedChannelException: null",
                "at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?]",
                "at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?]",
                "at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?]",
                "at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?]",
                "at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161]",
                "at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161]",
                "at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?]",
                "at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?]",
                "at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) ~[stormjar.jar:?]",
                "at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) ~[storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]",
                "at clojure.lang.AFn.run(AFn.java:22) ~[clojure-1.7.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_161]"
            ],
            "StepsToReproduce": [
                "1. Configure the Storm HDFS bolt with a Time rotation policy.",
                "2. Start the Storm topology.",
                "3. Monitor the worker logs for any errors."
            ],
            "ExpectedBehavior": "The HDFS bolt should successfully write data to HDFS without throwing exceptions.",
            "ObservedBehavior": "The HDFS bolt throws a ClosedChannelException, indicating that it attempted to write to a closed writer.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "bug_report": {
            "BugID": "STORM-1540",
            "Title": "Trident Topologies Crash During Debug/Sampling",
            "Description": "When deploying a Trident topology with debug/sampling enabled, workers crash due to a NotSerializableException. This issue affects the stability of the topology and prevents successful execution.",
            "StackTrace": [
                "2016-02-11 14:13:23.617 o.a.s.util [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]",
                "\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]",
                "Caused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList",
                "\tat org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]",
                "\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]",
                "\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]",
                "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]",
                "\tat org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]",
                "\tat ... 6 more"
            ],
            "StepsToReproduce": [
                "Deploy a Trident topology.",
                "Turn on debug/sampling."
            ],
            "ExpectedBehavior": "The Trident topology should run without crashing, even with debug/sampling enabled.",
            "ObservedBehavior": "Workers crash with a NotSerializableException when debug/sampling is enabled.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "bug_report": {
            "BugID": "STORM-2275",
            "Title": "Nimbus Crashes with NullPointerException During Topology State Transition",
            "Description": "The Nimbus service crashes with a NullPointerException when processing events during the state transition of a topology. This issue arises due to an assumption that a certain base object will be non-null, which is incorrect.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)",
                "    at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)",
                "Caused by: java.lang.NullPointerException",
                "    at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)",
                "    ... 1 more",
                "java.lang.RuntimeException: Halting process: Error while processing event",
                "    at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)",
                "    at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)"
            ],
            "StepsToReproduce": [
                "Deploy a topology using Nimbus.",
                "Trigger a state transition for the topology.",
                "Monitor the Nimbus logs for errors."
            ],
            "ExpectedBehavior": "Nimbus should handle state transitions without crashing.",
            "ObservedBehavior": "Nimbus crashes with a NullPointerException during the state transition of the topology.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "bug_report": {
            "BugID": "STORM-2873",
            "Title": "Backpressure Implementation Deletes Ephemeral Znodes Too Frequently",
            "Description": "The backpressure implementation deletes the znode when not relevant, which leads to issues with Zookeeper due to too frequent deletion and creation of the same path for ephemeral znodes. This results in a NoAuthException being thrown.",
            "StackTrace": [
                "017-09-18 15:00:34.980 b.s.util WorkerBackpressureThread [WARN] Expecting exception of class: class org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException, but exception chain only contains: (#<NoAuthException org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721>)",
                "2017-09-18 15:00:34.980 b.s.d.worker WorkerBackpressureThread [ERROR] workerBackpressure update failed when connecting to ZK ... will retry",
                "java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721",
                "\tat backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]",
                "\tat backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source) ~[?:?]",
                "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]",
                "\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]",
                "\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]",
                "\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]",
                "\tat org.apache.storm.pacemaker.pacemaker_state_factory$_mkState$reify__4254.delete_node(pacemaker_state_factory.clj:174) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat sun.reflect.GeneratedMethodAccessor859.invoke(Unknown Source) ~[?:?]",
                "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]",
                "\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]",
                "\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]",
                "\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]",
                "\tat backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat sun.reflect.GeneratedMethodAccessor857.invoke(Unknown Source) ~[?:?]",
                "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]",
                "\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]",
                "\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]",
                "\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]",
                "\tat backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat backtype.storm.disruptor$worker_backpressure_handler$reify__6432.onEvent(disruptor.clj:57) [storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]",
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721",
                "\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:113) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]",
                "\t... 23 more"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology that utilizes backpressure.",
                "2. Monitor the Zookeeper logs for deletion events.",
                "3. Observe the frequency of ephemeral znode deletions."
            ],
            "ExpectedBehavior": "The backpressure implementation should manage ephemeral znodes without causing frequent deletions that lead to Zookeeper exceptions.",
            "ObservedBehavior": "Frequent deletion of ephemeral znodes leads to NoAuthException in Zookeeper, causing worker backpressure updates to fail.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "bug_report": {
            "BugID": "STORM-2279",
            "Title": "Internal Server Error when accessing bolt page in Storm UI",
            "Description": "When attempting to access the bolt information page in the Storm UI using the latest storm code, an Internal Server Error is encountered. This issue occurs in a Vagrant setup and is accompanied by a stack trace indicating a TTransportException.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:101)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1369)",
                "at org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1353)",
                "at org.apache.storm.ui.core$component_page.invoke(core.clj:1026)",
                "at org.apache.storm.ui.core$fn__4308.invoke(core.clj:1214)",
                "at org.apache.storm.shade.compojure.core$make_route$fn__789.invoke(core.clj:100)",
                "at org.apache.storm.shade.compojure.core$if_route$fn__777.invoke(core.clj:46)",
                "at org.apache.storm.shade.compojure.core$if_method$fn__770.invoke(core.clj:31)",
                "at org.apache.storm.shade.compojure.core$routing$fn__795.invoke(core.clj:113)",
                "at clojure.core$some.invoke(core.clj:2570)",
                "at org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:113)",
                "at clojure.lang.RestFn.applyTo(RestFn.java:139)",
                "at clojure.core$apply.invoke(core.clj:632)",
                "at org.apache.storm.shade.compojure.core$routes$fn__799.invoke(core.clj:118)",
                "at org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__3573.invoke(json.clj:56)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)",
                "at org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__3102.invoke(reload.clj:22)",
                "at org.apache.storm.ui.helpers$requests_middleware$fn__2152.invoke(helpers.clj:54)",
                "at org.apache.storm.ui.core$catch_errors$fn__4474.invoke(core.clj:1460)",
                "at org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__1844.invoke(keyword_params.clj:35)",
                "at org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__1887.invoke(nested_params.clj:84)",
                "at org.apache.storm.shade.ring.middleware.params$wrap_params$fn__1816.invoke(params.clj:64)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)",
                "at org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__2139.invoke(flash.clj:35)",
                "at org.apache.storm.shade.ring.middleware.session$wrap_session$fn__2125.invoke(session.clj:98)",
                "at org.apache.storm.shade.ring.util.servlet$make_service_method$fn__1674.invoke(servlet.clj:127)",
                "at org.apache.storm.shade.ring.util.servlet$servlet$fn__1678.invoke(servlet.clj:136)",
                "at org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)",
                "at org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)",
                "at org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "Set up the Vagrant environment with the latest Storm code.",
                "Navigate to the Storm UI.",
                "Attempt to access the bolt information page using the URL: http://node1:8080/component.html?id=SlidingTimeCorrectness-winSec1slideSec1VerificationBolt&topology_id=SlidingWindowTestw1s1-2-1483646178."
            ],
            "ExpectedBehavior": "The bolt information page should load successfully without any errors.",
            "ObservedBehavior": "An Internal Server Error is displayed, and the stack trace indicates a TTransportException.",
            "Resolution": "The issue has been identified as an ArrayIndexOutOfBoundsException due to a negative index being calculated. A fix has been implemented and is awaiting verification."
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "bug_report": {
            "BugID": "STORM-3079",
            "Title": "Improve getMessage Support for ThriftExceptions",
            "Description": "The generated Thrift code does not support the getMessage() method, leading to confusion when null messages are logged. This issue has been observed in the following stack trace, and it is suggested to enhance the log messages for better clarity.",
            "StackTrace": [
                "2018-05-16 21:15:04.596 o.a.s.d.n.Nimbus timer [INFO] Exception {}",
                "org.apache.storm.generated.KeyNotFoundException: null",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "Trigger a ThriftException in the application.",
                "Observe the logs generated during the exception handling."
            ],
            "ExpectedBehavior": "The log should provide a meaningful message instead of a null value.",
            "ObservedBehavior": "The log shows a null message for the ThriftException, leading to confusion.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "bug_report": {
            "BugID": "STORM-3096",
            "Title": "Blobstores Deleted Before Topologies Can Be Submitted",
            "Description": "After the fix for STORM-3053, which aimed to resolve a race condition where a Nimbus timer could delete blobs during topology submission, the error persists. The issue has been traced to the method `idsOfTopologiesWithPrivateWorkerKeys()`. The previous change to delay topology deletion is beneficial but should occur after all topologies are discovered.",
            "StackTrace": [
                "2018-06-03 11:53:42.581 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] Received topology submission for topology-testHardCoreFaultTolerance-4 (storm-0.10.2.y.248 JDK-1.8.0_131) with conf {topology.users=[hadoopqa@DEV.YGRID.YAHOO.COM, hadoopqa], topology.acker.executors=0, storm.zookeeper.superACL=sasl:gstorm, topology.workers=3, topology.submitter.principal=hadoopqa@DEV.YGRID.YAHOO.COM, topology.debug=true, topology.disable.loadaware.messaging=true, storm.zookeeper.topology.auth.payload=#########################################, topology.name=topology-testHardCoreFaultTolerance-4, storm.zookeeper.topology.auth.scheme=digest, topology.kryo.register={}, nimbus.task.timeout.secs=200, storm.id=topology-testHardCoreFaultTolerance-4-18-1528026822, topology.kryo.decorators=[], topology.eventlogger.executors=0, topology.submitter.user=hadoopqa, topology.max.task.parallelism=null}",
                "2018-06-03 11:53:42.591 o.a.s.d.n.Nimbus timer [INFO] Cleaning up topology-testHardCoreFaultTolerance-4-18-1528026822",
                "2018-06-03 11:53:42.597 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] uploadedJar /home/y/var/storm/nimbus/inbox/stormjar-3c73de98-ced7-4fd0-86d9-8fba3e5100f1.jar",
                "2018-06-03 11:53:42.601 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1",
                "2018-06-03 11:53:42.621 o.a.s.d.n.Nimbus timer [INFO] Exception {}",
                "org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "2018-06-03 11:53:42.888 o.a.s.d.n.Nimbus pool-37-thread-1014 [WARN] Topology submission exception. (topology name='topology-testHardCoreFaultTolerance-4')",
                "org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]",
                "at org.apache.thrift.TBaseProcessor.process(ProcessFunction.java:39) [libthrift-0.11.0.jar:0.11.0]",
                "at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [storm-client-2.0.0.y.jar:2.0.0]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]"
            ],
            "StepsToReproduce": [
                "Submit a topology with the name 'topology-testHardCoreFaultTolerance-4'.",
                "Monitor the Nimbus logs for any cleanup actions.",
                "Observe if the blobs are deleted before the topology submission is completed."
            ],
            "ExpectedBehavior": "The topology should be submitted successfully without any blob deletion errors.",
            "ObservedBehavior": "The submission fails with a WrappedKeyNotFoundException indicating that the required blobs are missing.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "bug_report": {
            "BugID": "STORM-1642",
            "Title": "NullPointerException During Deserialization in Apache Storm",
            "Description": "An NPE occurs when Apache Storm attempts to deserialize a thrift object. The issue arises despite not using OutputCollector concurrently in the code. The serializer for the thrift object has been provided for review.",
            "StackTrace": [
                "2016-03-04 17:17:43.583 b.s.util [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]",
                "Caused by: java.lang.NullPointerException",
                "    at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]",
                "    at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]",
                "    ... 6 more",
                "2016-03-04 17:17:43.648 b.s.util [ERROR] Halting process: (\"Worker died\")",
                "java.lang.RuntimeException: (\"Worker died\")",
                "    at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.6.0.jar:?]",
                "    at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]",
                "    at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]",
                "    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]"
            ],
            "StepsToReproduce": [
                "1. Set up an Apache Storm environment with the provided thrift object.",
                "2. Implement the serializer for the thrift object.",
                "3. Run the Storm topology that utilizes the serializer.",
                "4. Observe the logs for any NullPointerException during deserialization."
            ],
            "ExpectedBehavior": "The thrift object should be deserialized without any exceptions.",
            "ObservedBehavior": "A NullPointerException is thrown during the deserialization process, causing the worker to die.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "bug_report": {
            "BugID": "STORM-2700",
            "Title": "Blobstore ACL Check Occurs Even When Validation is Disabled",
            "Description": "When the configuration `storm.blobstore.acl.validation.enabled` is set to false, the blobstore still performs ACL checks, leading to authorization errors.",
            "StackTrace": [
                "2017-08-21 13:56:19.800 o.a.s.d.s.Slot SLOT_6702 [ERROR] Error when processing event",
                "java.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)",
                "    at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]",
                "    at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]",
                "    at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: org.apache.storm.generated.AuthorizationException",
                "    at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]",
                "    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "    at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_131]",
                "2017-08-21 13:56:19.800 o.a.s.u.Utils SLOT_6702 [ERROR] Halting process: Error when processing an event",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "    at org.apache.storm.utils.Utils.exitProcess(Utils.java:437) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "    at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:823) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "2017-08-21 13:56:19.802 o.a.s.d.s.Supervisor Thread-6 [INFO] Shutting down supervisor b350cfb4-b333-4ea5-965e-b0698aaea80f-10.88.214.182",
                "2017-08-21 13:56:19.803 o.a.s.e.EventManagerImp Thread-5 [INFO] Event manager interrupted"
            ],
            "StepsToReproduce": [
                "1. Create a blobstore with permission set to one user (e.g., mapredqa).",
                "   Command: sudo -u mapredqa storm blobstore create --file test-blobstore.txt --acl u:mapredqa:rwa key1",
                "2. Submit a topology with topology.blobstore.map config as someone else (e.g., ethan).",
                "   Command: sudo -u ethan storm jar /tmp/storm-starter-2.0.0-SNAPSHOT.jar org.apache.storm.starter.WordCountTopology wc -c topology.blobstore.map='{\"key1\":{\"localname\":\"test-blobstore.txt\", \"uncompress\":false}}'"
            ],
            "ExpectedBehavior": "The blobstore should not perform ACL checks when `storm.blobstore.acl.validation.enabled` is set to false.",
            "ObservedBehavior": "The blobstore still checks ACLs and throws an AuthorizationException for users without READ access.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "bug_report": {
            "BugID": "STORM-1663",
            "Title": "Exception Thrown When Refreshing Active Topology Page in Storm UI",
            "Description": "When clicking on an active topology from the Storm UI home page and then refreshing the page, an exception is thrown. This issue impacts the usability of the Storm UI, preventing users from viewing topology details after refreshing.",
            "StackTrace": [
                "org.apache.storm.thrift.transport.TTransportException",
                "at org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)",
                "at org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:101)",
                "at org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)",
                "at org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)",
                "at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)",
                "at org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)",
                "at org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)",
                "at org.apache.storm.ui.core$topology_page.invoke(core.clj:638)",
                "at org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)",
                "at org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)",
                "at org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)",
                "at org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)",
                "at org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)",
                "at clojure.core$some.invoke(core.clj:2570)",
                "at org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)",
                "at clojure.lang.RestFn.applyTo(RestFn.java:139)",
                "at clojure.core$apply.invoke(core.clj:632)",
                "at org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)",
                "at org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)",
                "at org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)",
                "at org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)",
                "at org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)",
                "at org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)",
                "at org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)",
                "at org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)",
                "at org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)",
                "at org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)",
                "at org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)",
                "at org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)",
                "at org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)",
                "at org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)",
                "at org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)",
                "at org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)",
                "at org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)",
                "at org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)",
                "at org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)",
                "at org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)",
                "at org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)",
                "at org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)",
                "at java.lang.Thread.run(Thread.java:745)"
            ],
            "StepsToReproduce": [
                "Navigate to the Storm UI home page.",
                "Click on an active topology.",
                "Refresh the page."
            ],
            "ExpectedBehavior": "The active topology details should be displayed without any exceptions.",
            "ObservedBehavior": "An exception is thrown, preventing the display of topology details.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "bug_report": {
            "BugID": "STORM-2518",
            "Title": "NullPointerException when adding ACL to USER during artifact upload",
            "Description": "While adding ACL to USER from uploading artifacts, the 'name' field is optional for thrift specification. However, Nimbus reads the value without checking for null, leading to a NullPointerException. This results in failure to upload artifacts and submit topology.",
            "StackTrace": [
                "2017-05-16 14:57:02.527 o.a.s.t.s.TThreadPoolServer pool-45-thread-136 [ERROR] Error occurred during processing of message.",
                "java.lang.NullPointerException: null",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]",
                "at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]",
                "at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]",
                "at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]",
                "at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]"
            ],
            "StepsToReproduce": [
                "1. Attempt to upload an artifact with ACL settings.",
                "2. Ensure that the 'name' field is left empty (null).",
                "3. Observe the error during the upload process."
            ],
            "ExpectedBehavior": "The artifact should upload successfully without any errors, even if the 'name' field is null.",
            "ObservedBehavior": "The upload fails with a NullPointerException, preventing the artifact from being uploaded and the topology from being submitted.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "bug_report": {
            "BugID": "STORM-3124",
            "Title": "Sporadic Failures in Connecting to Pacemaker",
            "Description": "We're experiencing sporadic failures when attempting to communicate with the Pacemaker service. This issue prevents the successful launch of topologies in Apache Storm.",
            "StackTrace": [
                "java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.",
                "at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "... 2 more"
            ],
            "StepsToReproduce": [
                "Attempt to launch a topology in Apache Storm.",
                "Monitor the logs for connection attempts to the Pacemaker service.",
                "Observe the sporadic failures and error messages in the logs."
            ],
            "ExpectedBehavior": "The topology should launch successfully without any connection errors to the Pacemaker service.",
            "ObservedBehavior": "The topology fails to launch sporadically due to connection errors with the Pacemaker service, as indicated by multiple error messages in the logs.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2095",
            "Title": "Nimbus Fails to Start Due to DirectoryNotEmptyException on Blobstore Key Creation",
            "Description": "When creating a blobstore key for a large file and restarting Nimbus during the creation process, Nimbus fails to start due to a DirectoryNotEmptyException. This issue prevents Nimbus from recovering and impacts the overall functionality of the system.",
            "StackTrace": [
                "2016-09-14 15:07:48.518 o.a.s.zookeeper [INFO] Queued up for leader lock.",
                "2016-09-14 15:07:48.576 o.a.s.zookeeper [INFO] xxx gained leadership",
                "2016-09-14 15:07:48.581 o.a.s.d.nimbus [ERROR] Error on initialization of server service-handler",
                "java.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file",
                "\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)",
                "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)",
                "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)",
                "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)",
                "\tat java.lang.reflect.Method.invoke(Method.java:497)",
                "\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)",
                "\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)",
                "\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)",
                "\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)",
                "\tat clojure.lang.AFn.applyToHelper(AFn.java:156)",
                "\tat clojure.lang.AFn.applyTo(AFn.java:144)",
                "\tat clojure.core$apply.invoke(core.clj:630)",
                "\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)",
                "\tat clojure.lang.RestFn.invoke(RestFn.java:421)",
                "\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)",
                "\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)",
                "\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)",
                "\tat clojure.lang.AFn.applyToHelper(AFn.java:152)",
                "\tat clojure.lang.AFn.applyTo(AFn.java:144)",
                "\tat org.apache.storm.daemon.nimbus.main(Unknown Source)",
                "Caused by: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file",
                "\tat sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)",
                "\tat sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)",
                "\tat java.nio.file.Files.deleteIfExists(Files.java:1165)",
                "\tat org.apache.storm.blobstore.FileBlobStoreImpl.delete(FileBlobStoreImpl.java:239)",
                "\tat org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey(FileBlobStoreImpl.java:178)",
                "\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:226)",
                "\tat ... 19 more",
                "2016-09-14 15:07:48.588 o.a.s.util [ERROR] Halting process: (\"Error on initialization\")",
                "java.lang.RuntimeException: (\"Error on initialization\")",
                "\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)",
                "\tat clojure.lang.RestFn.invoke(RestFn.java:423)",
                "\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)",
                "\tat clojure.lang.RestFn.invoke(RestFn.java:421)",
                "\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)",
                "\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)",
                "\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)",
                "\tat clojure.lang.AFn.applyToHelper(AFn.java:152)",
                "\tat clojure.lang.AFn.applyTo(AFn.java:144)",
                "\tat org.apache.storm.daemon.nimbus.main(Unknown Source)"
            ],
            "StepsToReproduce": [
                "1) Create a blobstore key for a large file (1 or 2 GB). Size of the file does not matter if Nimbus can be killed while the blob is being created.",
                "2) While the blob is being created, restart Nimbus.",
                "3) Observe that Nimbus fails to start due to DirectoryNotEmptyException."
            ],
            "ExpectedBehavior": "Partial blobstore key is deleted cleanly and doesn't affect Nimbus.",
            "ObservedBehavior": "Nimbus fails to start and keeps dying due to DirectoryNotEmptyException.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2847",
            "Title": "IllegalArgumentException Thrown After Rebalance in storm-kafka-client Spout",
            "Description": "After a rebalance, the storm-kafka-client spout attempts to check the current position of partitions that are no longer assigned to the current spout. This issue occurs in a topology with multiple spout instances, leading to an IllegalArgumentException.",
            "StackTrace": [
                "java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer.",
                "at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262)",
                "at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)"
            ],
            "StepsToReproduce": [
                "1. Set up a topology with multiple instances of the storm-kafka-client spout.",
                "2. Trigger a rebalance in the topology.",
                "3. Observe the logs for any exceptions thrown by the spout."
            ],
            "ExpectedBehavior": "The storm-kafka-client spout should only check the position for partitions that are assigned to it, without throwing any exceptions.",
            "ObservedBehavior": "An IllegalArgumentException is thrown indicating that the spout is attempting to check the position for partitions that are not assigned to it.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "bug_report": {
            "BugID": "STORM-1114",
            "Title": "Race Condition in Trident Zookeeper Node Creation/Deletion",
            "Description": "In production for some Trident topology, we encountered a bug where some workers attempt to create a Zookeeper node that already exists or delete a Zookeeper node that has already been deleted. This results in the worker process crashing. The issue stems from a race condition in the Trident TransactionalState's Zookeeper node create and delete operations.",
            "StackTrace": [
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "... 9 more",
                "2015-10-14 18:10:43.786 b.s.util [ERROR] Halting process: (\"Worker died\")",
                "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "... 12 more",
                "2015-10-14 18:10:28.799 b.s.util [ERROR] Halting process: (\"Worker died\")",
                "java.lang.RuntimeException: (\"Worker died\")"
            ],
            "StepsToReproduce": [
                "Deploy a Trident topology that interacts with Zookeeper.",
                "Trigger the creation of a Zookeeper node that already exists.",
                "Trigger the deletion of a Zookeeper node that has already been deleted."
            ],
            "ExpectedBehavior": "The worker should handle the creation and deletion of Zookeeper nodes gracefully without crashing.",
            "ObservedBehavior": "The worker process crashes with a NodeExistsException or NoNodeException, leading to a halt in processing.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "bug_report": {
            "BugID": "STORM-2811",
            "Title": "NullPointerException when killing the same topology multiple times in Nimbus",
            "Description": "The Nimbus service throws a NullPointerException (NPE) when attempting to kill the same topology multiple times. This issue occurs during integration tests where the same topology is killed repeatedly, leading to unexpected behavior and potential service disruptions.",
            "StackTrace": [
                "2017-11-12 08:45:50.353 o.a.s.d.n.Nimbus pool-14-thread-47 [WARN] Kill topology exception. (topology name='SlidingWindowTest-window20-slide10')",
                "java.lang.NullPointerException: null",
                "at org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[libthrift-0.10.0.jar:0.10.0]",
                "at org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[libthrift-0.10.0.jar:0.10.0]",
                "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]",
                "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]"
            ],
            "StepsToReproduce": [
                "1. Deploy a topology named 'SlidingWindowTest-window20-slide10'.",
                "2. Attempt to kill the same topology multiple times using the Nimbus service.",
                "3. Observe the logs for any warnings or errors."
            ],
            "ExpectedBehavior": "The topology should be killed successfully without throwing any exceptions, regardless of how many times the kill command is issued.",
            "ObservedBehavior": "A NullPointerException is thrown in the logs when attempting to kill the same topology multiple times.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2903",
            "Title": "NullPointerException in AbstractAutoCreds during Hive token initialization",
            "Description": "A NullPointerException occurs when testing the Hive token mechanism, which halts the process. This issue needs to be addressed to ensure proper initialization of tokens.",
            "StackTrace": [
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]",
                "at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]",
                "at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]",
                "... 10 more",
                "2018-01-19 16:23:26.157 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")"
            ],
            "StepsToReproduce": [
                "1. Set up the Hive token mechanism in the Apache Storm environment.",
                "2. Attempt to initialize the Hive token.",
                "3. Observe the logs for any exceptions thrown."
            ],
            "ExpectedBehavior": "The Hive token should initialize without any exceptions, allowing for proper authentication and authorization.",
            "ObservedBehavior": "A NullPointerException is thrown, causing the initialization process to halt.",
            "Resolution": "A fix for this issue has been checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "bug_report": {
            "BugID": "STORM-3168",
            "Title": "AsyncLocalizer Cleanup Fails to Log Errors and Crashes",
            "Description": "The AsyncLocalizer component in Apache Storm fails to log cleanup messages and appears to crash intermittently. This issue was observed while investigating repeated blobstore download messages in the supervisor and nimbus logs. After enabling debug logging, expected cleanup messages were not logged until the supervisor was restarted.",
            "StackTrace": [
                "2018-07-30 23:25:35.691 o.a.s.l.AsyncLocalizer AsyncLocalizer Executor - 2 [ERROR] Could not update blob, will retry again later",
                "java.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...",
                "    at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]",
                "    at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]",
                "    at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]",
                "    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]",
                "    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]",
                "    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]",
                "    at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]",
                "Caused by: java.lang.RuntimeException: Could not download...",
                "    at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]",
                "    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]",
                "    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]",
                "    ... 3 more",
                "Caused by: org.apache.storm.generated.KeyNotFoundException",
                "    at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]",
                "    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]",
                "    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]",
                "    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]",
                "    ... 3 more"
            ],
            "StepsToReproduce": [
                "Enable debug logging for the AsyncLocalizer component.",
                "Monitor the supervisor and nimbus logs for blobstore download messages.",
                "Observe the absence of expected cleanup debug messages every 30 seconds.",
                "Restart the supervisor and check if logging resumes."
            ],
            "ExpectedBehavior": "The AsyncLocalizer should log cleanup messages every 30 seconds and handle errors without crashing.",
            "ObservedBehavior": "The AsyncLocalizer fails to log cleanup messages and crashes, requiring a restart to resume logging.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "bug_report": {
            "BugID": "STORM-2986",
            "Title": "NullPointerException in LogCleaner due to missing workers-artifacts directory",
            "Description": "When starting the LogCleaner thread with the configuration `logviewer.cleanup.interval.secs: 10`, a NullPointerException occurs because the `workers-artifacts` directory does not exist before any topologies are submitted. Users can manually create the directory to resolve the issue, but an automatic fix is preferable.",
            "StackTrace": [
                "java.lang.NullPointerException: null",
                "at java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Set the configuration `logviewer.cleanup.interval.secs: 10`.",
                "Start the LogCleaner thread.",
                "Observe the log output for errors."
            ],
            "ExpectedBehavior": "The LogCleaner should start without errors and clean up old logs as configured.",
            "ObservedBehavior": "A NullPointerException is thrown due to the absence of the `workers-artifacts` directory.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "bug_report": {
            "BugID": "STORM-2197",
            "Title": "NimbusClient Connection Leak Due to ThriftClient Error Handling",
            "Description": "Nimbus client connections are not closed when there are errors while connecting to Nimbus. The TSocket in ThriftClient should be closed in case of errors.",
            "StackTrace": [
                "2016-11-03 08:09:37.766 b.s.s.a.k.KerberosSaslTransportPlugin [ERROR] Client failed to open SaslClientTransport to interact with a server during session initiation: org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed",
                "org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed",
                "at org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]",
                "at javax.security.auth.Subject.doAs(Subject.java:415) [?:1.7.0_60]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]",
                "at clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]"
            ],
            "StepsToReproduce": [
                "Attempt to connect to Nimbus using the NimbusClient.",
                "Simulate a connection error (e.g., incorrect server address or credentials).",
                "Observe the behavior of the client connections."
            ],
            "ExpectedBehavior": "The NimbusClient should close any open connections upon encountering an error during the connection attempt.",
            "ObservedBehavior": "Connections remain open even after a connection error occurs, leading to resource leaks.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "bug_report": {
            "BugID": "STORM-1596",
            "Title": "Kerberos TGT Sharing Causes Service Failures in Multi-threaded Environment",
            "Description": "When multiple threads access the same Subject, it can lead to a situation where a ServiceTicket in use by one thread is destroyed by another thread. This issue is particularly evident when running the BasicDRPCTopology with high parallelism in a secure cluster.",
            "StackTrace": [
                "2016-01-20 15:52:26.904 o.a.t.t.TSaslTransport [ERROR] SASL negotiation failure",
                "javax.security.sasl.SaslException: GSS initiate failed",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]",
                "at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]",
                "at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_40]",
                "at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]",
                "at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]",
                "at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]",
                "Caused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)",
                "at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:770) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]",
                "... 23 more",
                "Caused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME",
                "at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.8.0_40]",
                "at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.getReply:259) ~[?:1.8.0_40]",
                "at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.sendAndGetCreds:270) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.serviceCreds:302) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.acquireServiceCreds:120) ~[?:1.8.0_40]",
                "at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.acquireServiceCreds:458) ~[?:1.8.0_40]",
                "at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.initSecContext:693) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:248) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:179) ~[?:1.8.0_40]",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.evaluateChallenge:192) ~[?:1.8.0_40]",
                "... 23 more",
                "Caused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)",
                "at sun.security.krb5.internal.KDCRep.init(KDCRep.init:140) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.TGSRep.init(TGSRep.init:65) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.TGSRep.<init>(TGSRep.<init>:60) ~[?:1.8.0_40]",
                "at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.<init>:55) ~[?:1.8.0_40]",
                "at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.getReply:259) ~[?:1.8.0_40]",
                "at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.sendAndGetCreds:270) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.serviceCreds:302) ~[?:1.8.0_40]",
                "at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.acquireServiceCreds:120) ~[?:1.8.0_40]",
                "at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.acquireServiceCreds:458) ~[?:1.8.0_40]",
                "at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.initSecContext:693) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:248) ~[?:1.8.0_40]",
                "at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:179) ~[?:1.8.0_40]",
                "at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.evaluateChallenge:192) ~[?:1.8.0_40]",
                "... 23 more"
            ],
            "StepsToReproduce": [
                "Run BasicDRPCTopology with high parallelism in a secure cluster.",
                "Ensure multiple threads are accessing the same Subject."
            ],
            "ExpectedBehavior": "The service should handle multiple threads accessing the same Subject without causing any service failures.",
            "ObservedBehavior": "Service fails with a SASL negotiation failure and GSS initiate failure due to Kerberos TGT sharing issues.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "bug_report": {
            "BugID": "STORM-2142",
            "Title": "Async Loop Dies on Exception in EvaluationFilter/EvaluationFunction",
            "Description": "When an Exception is thrown by EvaluationFilter or EvaluationFunction, the async loop for the executor dies, while other components continue to function. This behavior is inconsistent with the expected handling of InterruptedException or InterruptedIOException, which should only log the error without terminating the loop.",
            "StackTrace": [
                "2016-10-08 14:12:29.597 o.a.s.u.Utils Thread-23-b-0-LOGICALFILTER_6-LOGICALPROJECT_7-executor[5 5] [ERROR] Async loop died!",
                "java.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException",
                "at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]",
                "Caused by: java.lang.reflect.InvocationTargetException",
                "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]",
                "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]",
                "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]",
                "at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]",
                "at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]",
                "Caused by: java.lang.RuntimeException: Cannot convert null to int",
                "at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]",
                "at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]",
                "at SC.eval0(Unknown Source) ~[?:?]"
            ],
            "StepsToReproduce": [
                "1. Trigger an EvaluationFilter or EvaluationFunction that is expected to throw an Exception.",
                "2. Observe the behavior of the async loop for the executor."
            ],
            "ExpectedBehavior": "The async loop should log the error and continue functioning without dying.",
            "ObservedBehavior": "The async loop dies when an Exception is thrown, while other components continue to work.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "bug_report": {
            "BugID": "STORM-2400",
            "Title": "Intermittent KeeperException in LeaderLatch#getLeader() due to NoNode",
            "Description": "This issue is reported to Curator with CURATOR-358. The method `LeaderLatch#getLeader()` intermittently throws a `KeeperException` with code `NONODE`. This may occur if a participant's ephemeral ZK node is removed because its connection/session is closed. The issue seems to stem from a race condition where a participant node is retrieved, but by the time `LeaderSelector#getLeader()` is invoked, the node may have been removed due to session timeout. The current implementation does not retry on `NoNode` exceptions, which could be improved by allowing configuration of retry behavior for specific `KeeperException` codes.",
            "StackTrace": [
                "2016-11-15 06:09:33.954 o.a.s.d.nimbus [ERROR] Error when processing event",
                "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)",
                "at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)",
                "at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)",
                "at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)",
                "at org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)",
                "at org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)"
            ],
            "StepsToReproduce": [
                "1. Set up a Zookeeper cluster with ephemeral nodes.",
                "2. Start the application that uses LeaderLatch.",
                "3. Simulate a session timeout for a participant node.",
                "4. Observe the logs for KeeperException being thrown."
            ],
            "ExpectedBehavior": "The method `LeaderLatch#getLeader()` should successfully return the leader participant without throwing a `KeeperException` when the session is valid.",
            "ObservedBehavior": "The method intermittently throws a `KeeperException` with code `NoNode`, indicating that the leader participant node does not exist.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "bug_report": {
            "BugID": "STORM-3084",
            "Title": "NullPointerException on Nimbus Startup in Apache Storm 2.x",
            "Description": "A NullPointerException occurs during the startup of the Nimbus server in Apache Storm version 2.0.0.y, causing the server to halt unexpectedly.",
            "StackTrace": [
                "2018-05-24 09:27:05.636 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.0.0.y'",
                "2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event java.lang.RuntimeException: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "... 2 more",
                "2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event java.lang.RuntimeException: Halting process: Error while processing event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "2018-05-24 09:27:06.032 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master",
                "2018-05-24 09:27:06.032 o.a.s.u.Utils Thread-13 [INFO] Halting after 5 seconds"
            ],
            "StepsToReproduce": [
                "Start the Nimbus server using Apache Storm version 2.0.0.y.",
                "Monitor the logs for any errors during the startup process."
            ],
            "ExpectedBehavior": "The Nimbus server should start without any errors.",
            "ObservedBehavior": "The Nimbus server fails to start and logs a NullPointerException.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "bug_report": {
            "BugID": "STORM-3118",
            "Title": "Netty EncoderException and IllegalStateException in Pacemaker",
            "Description": "Nimbus encounters issues with Pacemaker, leading to exceptions that prevent topology submission.",
            "StackTrace": [
                "2018-06-21 08:55:17.762 o.a.s.p.PacemakerClientHandler client-worker-2 [ERROR] Exception occurred in Pacemaker.",
                "org.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelInboundHandlerAdapter.java:64) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline$HeadContext.channelActive(DefaultChannelPipeline.java:1422) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.fireChannelActive(DefaultChannelPipeline.java:941) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:311) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:341) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:635) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]",
                "Caused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)",
                "at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]",
                "... 26 more"
            ],
            "StepsToReproduce": [
                "1. Start Nimbus with Pacemaker enabled.",
                "2. Attempt to submit a topology.",
                "3. Observe the error messages in the logs."
            ],
            "ExpectedBehavior": "Topology should be submitted successfully without errors.",
            "ObservedBehavior": "Topology submission fails with EncoderException and IllegalStateException.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "bug_report": {
            "BugID": "STORM-2158",
            "Title": "OutOfMemoryError in Nimbus' SimpleTransportPlugin due to malformed Thrift request",
            "Description": "An OutOfMemoryError is thrown by Nimbus' SimpleTransportPlugin when a malformed Thrift request is posted. This issue occurs in an unsecured Storm cluster environment.",
            "StackTrace": [
                "java.lang.OutOfMemoryError: Java heap space",
                "at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]",
                "at java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]",
                "at org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]"
            ],
            "StepsToReproduce": [
                "Start the Nimbus server.",
                "Post a malformed Thrift request using the command: echo 'Hello' | nc localhost 6627.",
                "Monitor the nimbus.log for errors."
            ],
            "ExpectedBehavior": "The Nimbus server should handle malformed requests gracefully without throwing an OutOfMemoryError.",
            "ObservedBehavior": "The Nimbus server throws an OutOfMemoryError and shuts down when a malformed Thrift request is posted.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "bug_report": {
            "BugID": "STORM-2682",
            "Title": "Supervisor Crashes with NullPointerException After 30 Seconds",
            "Description": "When the supervisor is started, it crashes approximately 30 seconds later due to a NullPointerException. The logs indicate that the supervisor fails while processing an event, leading to a halt in the process.",
            "StackTrace": [
                "2017-08-07 17:12:34.620 o.a.s.e.EventManagerImp Thread-4 [ERROR] {} Error when processing event",
                "java.lang.NullPointerException: null",
                "at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]",
                "at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]",
                "2017-08-07 17:12:34.620 o.a.s.u.Utils Thread-4 [ERROR] Halting process: Error when processing an event",
                "java.lang.RuntimeException: Halting process: Error when processing an event",
                "at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]",
                "at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]",
                "2017-08-07 17:12:34.631 o.a.s.d.s.Supervisor Thread-5 [INFO] Shutting down supervisor 65a0f977-474c-4938-a4f5-bc99939e96ff"
            ],
            "StepsToReproduce": [
                "Start the supervisor in a Dockerized environment based on Debian Jessie.",
                "Wait for approximately 30 seconds after the supervisor starts."
            ],
            "ExpectedBehavior": "The supervisor should run without crashing and handle events properly.",
            "ObservedBehavior": "The supervisor crashes with a NullPointerException after about 30 seconds.",
            "Resolution": "Fixed"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "bug_report": {
            "BugID": "STORM-3103",
            "Title": "Nimbus Shutdown Causes Leadership Issues on Startup",
            "Description": "When debugging a NullPointerException (NPE) in Nimbus that caused restarts, it was observed that a forced halt occurred, leading to leadership confusion during startup. This issue needs to be addressed to ensure clean shutdowns and proper leadership management.",
            "StackTrace": [
                "2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event",
                "java.lang.RuntimeException: java.lang.NullPointerException",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "Caused by: java.lang.NullPointerException",
                "    at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    ... 2 more",
                "2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event",
                "java.lang.RuntimeException: Halting process: Error while processing event",
                "    at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]",
                "    at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
            ],
            "StepsToReproduce": [
                "Start the Nimbus server.",
                "Trigger a condition that causes a NullPointerException.",
                "Observe the logs for shutdown and leadership messages."
            ],
            "ExpectedBehavior": "Nimbus should shut down cleanly without causing leadership confusion.",
            "ObservedBehavior": "Nimbus encounters a NullPointerException, leading to forced shutdown and subsequent leadership issues.",
            "Resolution": "A fix for this issue is checked into the tree and tested."
        }
    }
]