[
    {
        "filename": "HDFS-4558.json",
        "creation_time": "2013-03-06T11:10:08.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockPlacementPolicy during Balancer initialization",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS Namenode.",
                    "2. Execute the Balancer command to initiate the balancing process.",
                    "3. Observe the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown during the initialization of the Balancer, causing the process to fail.",
                "possibleCause": "The BlockPlacementPolicy instance may not be properly initialized or configured, leading to a null reference when accessed."
            },
            "stackTrace": "java.lang.NullPointerException\n at org.apache.hadoop.hdfs.server.namenode.BlockPlacementPolicy.getInstance(BlockPlacementPolicy.java:165)\n at org.apache.hadoop.hdfs.server.balancer.Balancer.checkReplicationPolicyCompatibility(Balancer.java:799)\n at org.apache.hadoop.hdfs.server.balancer.Balancer.<init>(Balancer.java:808)\n at org.apache.hadoop.hdfs.server.balancer.Balancer.main(Balancer.java:831)"
        }
    },
    {
        "filename": "HDFS-13039.json",
        "creation_time": "2018-01-19T18:52:12.000+0000",
        "bug_report": {
            "title": "IOException: Too many open files",
            "description": {
                "stepsToReproduce": [
                    "1. Start the server application that uses Netty for handling socket connections.",
                    "2. Simulate a high number of concurrent connections to the server.",
                    "3. Monitor the server logs for any IOException related to open files."
                ],
                "actualBehavior": "The server throws an IOException indicating 'Too many open files' and fails to accept new connections.",
                "possibleCause": "The server may be exceeding the maximum number of file descriptors allowed by the operating system, possibly due to insufficient configuration or a resource leak."
            },
            "stackTrace": "java.io.IOException: Too many open files\n        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)\n        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)\n        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)\n        at io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(NioServerSocketChannel.java:135)\n        at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:75)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:563)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:504)\n        at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:418)\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:390)\n        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:742)\n        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:145)\n        at java.lang.Thread.run(Thread.java:748)"
        }
    },
    {
        "filename": "HDFS-13023.json",
        "creation_time": "2018-01-16T20:27:39.000+0000",
        "bug_report": {
            "title": "Authorization Exception for QJournalProtocol Access",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to access the QJournalProtocol interface using a user with PROXY authentication.",
                    "2. Ensure that the JournalNode is configured to require KERBEROS authentication.",
                    "3. Execute a command that triggers the sync with the journal."
                ],
                "actualBehavior": "The operation fails with an AuthorizationException indicating that the user is not authorized for the QJournalProtocol interface.",
                "possibleCause": "The user attempting to access the QJournalProtocol may not have the necessary permissions or the authentication method is not correctly configured."
            },
            "stackTrace": "com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User nn/xxx (auth:PROXY) via jn/xxx (auth:KERBEROS) is not authorized for protocol interface org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol: this service is only accessible by nn/xxx@EXAMPLE.COM\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:242)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n at com.sun.proxy.$Proxy16.getEditLogManifest(Unknown Source)\n at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncWithJournalAtIndex(JournalNodeSyncer.java:254)\n at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.syncJournals(JournalNodeSyncer.java:230)\n at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:190)\n at java.lang.Thread.run(Thread.java:748)\n Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User nn/xxx (auth:PROXY) via jn/xxx (auth:KERBEROS) is not authorized for protocol interface org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocol: this service is only accessible by nn/xxx\n at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1491)\n at org.apache.hadoop.ipc.Client.call(Client.java:1437)\n at org.apache.hadoop.ipc.Client.call(Client.java:1347)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)"
        }
    },
    {
        "filename": "HDFS-3157.json",
        "creation_time": "2012-03-28T14:35:53.000+0000",
        "bug_report": {
            "title": "IOException during block deletion in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Upload a file to the HDFS.",
                    "3. Attempt to delete the uploaded file."
                ],
                "actualBehavior": "An IOException is thrown indicating an error in deleting blocks.",
                "possibleCause": "The issue may be related to insufficient permissions, corrupted block data, or a misconfiguration in the HDFS setup."
            },
            "stackTrace": "java.io.IOException: Error in deleting blocks.\n\tat org.apache.hadoop.hdfs.server.datanode.FSDataset.invalidate(FSDataset.java:2061)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActive(BPOfferService.java:581)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommandFromActor(BPOfferService.java:545)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.processCommand(BPServiceActor.java:690)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:522)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:662)\n\tat java.lang.Thread.run(Thread.java:619)"
        }
    },
    {
        "filename": "HDFS-4850.json",
        "creation_time": "2013-05-25T00:18:15.000+0000",
        "bug_report": {
            "title": "NegativeArraySizeException in OfflineImageViewer",
            "description": {
                "stepsToReproduce": [
                    "Run the OfflineImageViewer tool on a specific HDFS image file.",
                    "Ensure that the image file contains directory entries with invalid or corrupted permissions.",
                    "Observe the output or logs for any exceptions thrown."
                ],
                "actualBehavior": "The application throws a NegativeArraySizeException, causing it to terminate unexpectedly.",
                "possibleCause": "The exception may be caused by an attempt to create an array with a negative size, likely due to incorrect parsing of directory permissions or metadata."
            },
            "stackTrace": "Exception in thread \"main\" java.lang.NegativeArraySizeException\n\tat org.apache.hadoop.io.Text.readString(Text.java:458)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processPermission(ImageLoaderCurrent.java:370)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processINode(ImageLoaderCurrent.java:671)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processChildren(ImageLoaderCurrent.java:557)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processDirectoryWithSnapshot(ImageLoaderCurrent.java:464)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processDirectoryWithSnapshot(ImageLoaderCurrent.java:470)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processDirectoryWithSnapshot(ImageLoaderCurrent.java:470)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processLocalNameINodesWithSnapshot(ImageLoaderCurrent.java:444)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processINodes(ImageLoaderCurrent.java:398)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.loadImage(ImageLoaderCurrent.java:199)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewer.go(OfflineImageViewer.java:136)\n\tat org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewer.main(OfflineImageViewer.java:260)"
        }
    },
    {
        "filename": "HDFS-3415.json",
        "creation_time": "2012-05-13T13:44:43.000+0000",
        "bug_report": {
            "title": "NullPointerException in NNStorage.getStorageFile",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop NameNode service.",
                    "Attempt to load the filesystem image from disk.",
                    "Observe the logs for any exceptions."
                ],
                "actualBehavior": "The NameNode fails to start and throws a NullPointerException.",
                "possibleCause": "It is possible that a required storage file or directory is missing or not properly initialized, leading to a null reference in the NNStorage class."
            },
            "stackTrace": "java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.namenode.NNStorage.getStorageFile(NNStorage.java:686)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImagePreTransactionalStorageInspector.getEditsInStorageDir(FSImagePreTransactionalStorageInspector.java:243)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImagePreTransactionalStorageInspector.getLatestEditsFiles(FSImagePreTransactionalStorageInspector.java:261)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImagePreTransactionalStorageInspector.getEditLogStreams(FSImagePreTransactionalStorageInspector.java:276)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:596)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:247)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:498)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:390)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:354)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:368)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:402)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:564)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:545)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1093)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1151)"
        }
    },
    {
        "filename": "HDFS-2245.json",
        "creation_time": "2011-08-10T22:55:33.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockManager.chooseTarget",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Attempt to add a block to the NameNode.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "An IOException is thrown due to a NullPointerException in the BlockManager.chooseTarget method.",
                "possibleCause": "The BlockManager may be trying to access a target node that has not been properly initialized or is null."
            },
            "stackTrace": "java.io.IOException: java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1225)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1455)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:786)"
        }
    },
    {
        "filename": "HDFS-10320.json",
        "creation_time": "2016-04-20T23:02:09.000+0000",
        "bug_report": {
            "title": "InvalidTopologyException when choosing datanode in Hadoop",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop cluster with multiple racks and datanodes.",
                    "2. Configure the network topology with specific rack assignments.",
                    "3. Attempt to write data to HDFS that requires replication across the configured racks."
                ],
                "actualBehavior": "The operation fails with an InvalidTopologyException indicating that a datanode could not be found for the specified rack.",
                "possibleCause": "The issue may be caused by an incorrect or incomplete configuration of the network topology, leading to the exclusion of all available datanodes in the specified scope."
            },
            "stackTrace": "org.apache.hadoop.net.NetworkTopology$InvalidTopologyException: Failed to find datanode (scope=\"\" excludedScope=\"/rack_a5\").\n\tat org.apache.hadoop.net.NetworkTopology.chooseRandom(NetworkTopology.java:729)\n\tat org.apache.hadoop.net.NetworkTopology.chooseRandom(NetworkTopology.java:694)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:635)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:580)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:348)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:214)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:111)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.chooseTargets(BlockManager.java:3746)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.access$200(BlockManager.java:3711)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1400)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1306)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3682)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3634)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-4201.json",
        "creation_time": "2012-11-16T21:28:57.000+0000",
        "bug_report": {
            "title": "NullPointerException in BPServiceActor during Heartbeat",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Ensure that DataNodes are running and connected to the NameNode.",
                    "3. Monitor the logs for heartbeat messages from DataNodes."
                ],
                "actualBehavior": "A NullPointerException is thrown in the BPServiceActor when attempting to send a heartbeat.",
                "possibleCause": "It is possible that a required object or variable is not initialized before the sendHeartBeat method is called."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:434)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:520)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:673)\n        at java.lang.Thread.run(Thread.java:722)"
        }
    },
    {
        "filename": "HDFS-6904.json",
        "creation_time": "2014-08-21T10:17:21.000+0000",
        "bug_report": {
            "title": "IOException when renewing WEBHDFS delegation token",
            "description": {
                "stepsToReproduce": [
                    "1. Submit an application to the YARN ResourceManager that requires a WEBHDFS delegation token.",
                    "2. Wait for the token renewal process to trigger.",
                    "3. Observe the logs for any IOException related to token renewal."
                ],
                "actualBehavior": "An IOException is thrown indicating a failure to renew the token, with an unexpected HTTP response code.",
                "possibleCause": "The issue may be caused by an invalid or unreachable NameNode service, leading to an unexpected HTTP response during the token renewal process."
            },
            "stackTrace": "java.io.IOException: Failed to renew token: Kind: WEBHDFS delegation, Service: NameNodeIP:8020, Ident: (WEBHDFS delegation token 2222 for hrt_qa)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.handleAppSubmitEvent(DelegationTokenRenewer.java:394)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.access$5(DelegationTokenRenewer.java:357)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.handleDTRenewerAppSubmitEvent(DelegationTokenRenewer.java:657)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.run(DelegationTokenRenewer.java:638)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: Unexpected HTTP response: code=-1 != 200, op=RENEWDELEGATIONTOKEN, message=null\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:331)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:90)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:598)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:448)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:477)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:473)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.renewDelegationToken(WebHdfsFileSystem.java:1318)\n        at org.apache.hadoop.hdfs.web.TokenAspect$TokenManager.renew(TokenAspect.java:73)\n        at org.apache.hadoop.security.token.Token.renew(Token.java:377)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:477)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:1)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.renewToken(DelegationTokenRenewer.java:473)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.handleAppSubmitEvent(DelegationTokenRenewer.java:392)\n        ... 6 more\nCaused by: java.io.IOException: The error stream is null.\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.jsonParse(WebHdfsFileSystem.java:304)\n        at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:329)"
        }
    },
    {
        "filename": "HDFS-13721.json",
        "creation_time": "2018-07-05T20:11:57.000+0000",
        "bug_report": {
            "title": "NullPointerException in DataNode.getDiskBalancerStatus",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with DataNode running.",
                    "2. Access the JMX metrics via the JMXJsonServlet endpoint.",
                    "3. Attempt to retrieve the disk balancer status attribute."
                ],
                "actualBehavior": "A NullPointerException is thrown when trying to access the disk balancer status, resulting in a RuntimeMBeanException.",
                "possibleCause": "The DataNode.getDiskBalancerStatus method may be attempting to access an uninitialized or null object, leading to the NullPointerException."
            },
            "stackTrace": "javax.management.RuntimeMBeanException: java.lang.NullPointerException\n at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrow(DefaultMBeanServerInterceptor.java:839)\n at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.rethrowMaybeMBeanException(DefaultMBeanServerInterceptor.java:852)\n at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:651)\n at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)\n at org.apache.hadoop.jmx.JMXJsonServlet.writeAttribute(JMXJsonServlet.java:338)\n at org.apache.hadoop.jmx.JMXJsonServlet.listBeans(JMXJsonServlet.java:316)\n at org.apache.hadoop.jmx.JMXJsonServlet.doGet(JMXJsonServlet.java:210)\n at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\n at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)\n at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1537)\n at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n at org.apache.hadoop.http.NoCacheFilter.doFilter(ServletHandler.java:45)\n at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n at org.eclipse.jetty.server.Server.handle(Server.java:534)\n at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n at java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n at org.apache.hadoop.hdfs.server.datanode.DataNode.getDiskBalancerStatus(DataNode.java:3146)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n at java.lang.reflect.Method.invoke(Method.java:498)\n at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)\n at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)\n at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)\n at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)\n at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)\n at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)\n at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)\n at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)\n at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)\n at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)"
        }
    },
    {
        "filename": "HDFS-7180.json",
        "creation_time": "2014-10-02T03:07:04.000+0000",
        "bug_report": {
            "title": "IOException: Bad response ERROR for block from datanode",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with the specified datanodes.",
                    "2. Attempt to write a large file to HDFS.",
                    "3. Monitor the logs for any IOException related to datanodes."
                ],
                "actualBehavior": "An IOException is thrown indicating a bad response from the datanode, preventing the file from being written successfully.",
                "possibleCause": "The datanode may be experiencing connectivity issues or is misconfigured, leading to an inability to process the block request correctly."
            },
            "stackTrace": "java.io.IOException: Bad response ERROR for block BP-1960069741-10.0.3.170-1410430543652:blk_1074363564_623643 from datanode 10.0.3.176:50010\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:828)"
        }
    },
    {
        "filename": "HDFS-6102.json",
        "creation_time": "2014-03-13T18:27:36.000+0000",
        "bug_report": {
            "title": "Protocol Buffer Message Size Limit Exceeded",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to process a large protocol buffer message using the Hadoop HDFS namenode.",
                    "2. Ensure that the message exceeds the default size limit set for protocol buffers.",
                    "3. Observe the behavior of the application when processing the oversized message."
                ],
                "actualBehavior": "The application throws a com.google.protobuf.InvalidProtocolBufferException indicating that the protocol message was too large.",
                "possibleCause": "The default size limit for protocol buffer messages is exceeded, which may indicate either a legitimate large message or a potential malicious attempt to exploit the system."
            },
            "stackTrace": "com.google.protobuf.InvalidProtocolBufferException: Protocol message was too large.  May be malicious.  Use CodedInputStream.setSizeLimit() to increase the size limit.\n        at com.google.protobuf.InvalidProtocolBufferException.sizeLimitExceeded(InvalidProtocolBufferException.java:110)\n        at com.google.protobuf.CodedInputStream.refillBuffer(CodedInputStream.java:755)\n        at com.google.protobuf.CodedInputStream.readRawByte(CodedInputStream.java:769)\n        at com.google.protobuf.CodedInputStream.readRawVarint64(CodedInputStream.java:462)\n        at com.google.protobuf.CodedInputStream.readUInt64(CodedInputStream.java:188)\n        at org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry.<init>(FsImageProto.java:9839)\n        at org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry.<init>(FsImageProto.java:9770)\n        at org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry$1.parsePartialFrom(FsImageProto.java:9901)\n        at org.apache.hadoop.hdfs.server.namenode.FsImageProto$INodeDirectorySection$DirEntry$1.parsePartialFrom(FsImageProto.java:9896)"
        }
    },
    {
        "filename": "HDFS-6250.json",
        "creation_time": "2014-04-16T16:14:32.000+0000",
        "bug_report": {
            "title": "Assertion Error in TestBalancerWithNodeGroup.testBalancerWithRackLocality",
            "description": {
                "stepsToReproduce": [
                    "Run the test suite for the Hadoop HDFS balancer module.",
                    "Ensure that the TestBalancerWithNodeGroup class is included in the test run.",
                    "Execute the test method testBalancerWithRackLocality."
                ],
                "actualBehavior": "The test fails with an AssertionError indicating that the expected value was 1800 but the actual value was 1810.",
                "possibleCause": "There may be an issue with the logic in the balancer that calculates the expected value, or the test setup may not be correctly initializing the conditions for the test."
            },
            "stackTrace": "java.lang.AssertionError: expected:<1800> but was:<1810>\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:147)\n\tat org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup.testBalancerWithRackLocality(TestBalancerWithNodeGroup.java:253)"
        }
    },
    {
        "filename": "HDFS-11377.json",
        "creation_time": "2017-01-26T23:40:53.000+0000",
        "bug_report": {
            "title": "HDFS Balancer Thread Stuck in TIMED_WAITING State",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS balancer service.",
                    "2. Monitor the balancer's performance and thread states.",
                    "3. Observe the behavior of the Dispatcher and Balancer threads."
                ],
                "actualBehavior": "The Dispatcher thread is stuck in a TIMED_WAITING state, causing delays in block move completions and overall performance degradation of the HDFS balancer.",
                "possibleCause": "The issue may be related to improper handling of sleep intervals in the Dispatcher class, leading to excessive waiting times."
            },
            "stackTrace": "java.lang.Thread.State: TIMED_WAITING (sleeping)\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher.waitForMoveCompletion(Dispatcher.java:1043)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher.dispatchBlockMoves(Dispatcher.java:1017)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher.dispatchAndCheckContinue(Dispatcher.java:981)\n        at org.apache.hadoop.hdfs.server.balancer.Balancer.runOneIteration(Balancer.java:611)\n        at org.apache.hadoop.hdfs.server.balancer.Balancer.run(Balancer.java:663)\n        at org.apache.hadoop.hdfs.server.balancer.Balancer$Cli.run(Balancer.java:776)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.hdfs.server.balancer.Balancer.main(Balancer.java:905)"
        }
    },
    {
        "filename": "HDFS-6753.json",
        "creation_time": "2014-07-25T11:36:43.000+0000",
        "bug_report": {
            "title": "DiskOutOfSpaceException when attempting to write to HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop cluster with HDFS.",
                    "2. Ensure that the block size is set to 134217728 B (128 MB).",
                    "3. Fill the available disk space on the data node to a point where only 4096 B is left.",
                    "4. Attempt to write a file larger than the available space to HDFS."
                ],
                "actualBehavior": "The operation fails with a DiskOutOfSpaceException indicating that the available space is less than the block size.",
                "possibleCause": "The data node is unable to allocate space for new blocks due to insufficient available disk space."
            },
            "stackTrace": "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Out of space: The volume with the most available space (=4096 B) is less than the block size (=134217728 B).\n\nat org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:60)\n\njava.io.IOException: Invalid directory or I/O error occurred for dir: /mnt/tmp_Datanode/current/BP-1384489961-XX2.XX2.XX2.XX2-845784615183/current/finalized\n\nat org.apache.hadoop.fs.FileUtil.listFiles(FileUtil.java:1164)\n\nat org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:596)"
        }
    },
    {
        "filename": "HDFS-3443.json",
        "creation_time": "2012-05-18T11:30:50.000+0000",
        "bug_report": {
            "title": "NullPointerException during NameNode transition to active state",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster with High Availability (HA) enabled.",
                    "2. Trigger a failover to transition the Standby NameNode to Active state.",
                    "3. Monitor the logs for any exceptions during the transition process."
                ],
                "actualBehavior": "A NullPointerException is thrown, causing the transition to active state to fail.",
                "possibleCause": "The exception may be caused by an uninitialized variable or resource in the FSNamesystem class during the activation process."
            },
            "stackTrace": "java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:602)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1287)\n\tat org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)\n\tat org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:63)\n\tat org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1219)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:978)\n\tat org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)\n\tat org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:3633)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:427)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:916)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1686)\n\njava.nio.channels.ClosedChannelException\n\tat sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:133)\n\tat sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)\n\tat org.apache.hadoop.ipc.Server.channelWrite(Server.java:2092)\n\tat org.apache.hadoop.ipc.Server.access$2000(Server.java:107)\n\tat org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:930)\n\tat org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:994)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1738)"
        }
    },
    {
        "filename": "HDFS-11479.json",
        "creation_time": "2017-03-01T11:08:07.000+0000",
        "bug_report": {
            "title": "ChannelException: Failed to bind to address due to Address already in use",
            "description": {
                "stepsToReproduce": [
                    "Start the NFS service on the server.",
                    "Attempt to bind the service to the UDP port 4242.",
                    "Observe the logs for any binding errors."
                ],
                "actualBehavior": "The service fails to start with a ChannelException indicating that the address is already in use.",
                "possibleCause": "Another process may already be using UDP port 4242, preventing the NFS service from binding to it."
            },
            "stackTrace": "org.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:4242\n        at org.jboss.netty.bootstrap.ConnectionlessBootstrap.bind(ConnectionlessBootstrap.java:204)\n        at org.apache.hadoop.oncrpc.SimpleUdpServer.run(SimpleUdpServer.java:68)\n        at org.apache.hadoop.mount.MountdBase.startUDPServer(MountdBase.java:64)\n        at org.apache.hadoop.mount.MountdBase.start(MountdBase.java:97)\n        at org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.startServiceInternal(Nfs3.java:56)\n        at org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.startService(Nfs3.java:69)\n        at org.apache.hadoop.hdfs.nfs.nfs3.PrivilegedNfsGatewayStarter.start(PrivilegedNfsGatewayStarter.java:71)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at org.apache.commons.daemon.support.DaemonLoader.start(DaemonLoader.java:243)\nCaused by: java.net.BindException: Address already in use\n        at sun.nio.ch.Net.bind0(Native Method)\n        at sun.nio.ch.Net.bind(Net.java:433)\n        at sun.nio.ch.DatagramChannelImpl.bind(DatagramChannelImpl.java:691)\n        at sun.nio.ch.DatagramSocketAdaptor.bind(DatagramSocketAdaptor.java:91)\n        at org.jboss.netty.channel.socket.nio.NioDatagramPipelineSink.bind(NioDatagramPipelineSink.java:129)\n        at org.jboss.netty.channel.socket.nio.NioDatagramPipelineSink.eventSunk(NioDatagramPipelineSink.java:77)\n        at org.jboss.netty.channel.Channels.bind(Channels.java:561)\n        at org.jboss.netty.channel.AbstractChannel.bind(AbstractChannel.java:189)\n        at org.jboss.netty.bootstrap.ConnectionlessBootstrap.bind(ConnectionlessBootstrap.java:198)"
        }
    },
    {
        "filename": "HDFS-8055.json",
        "creation_time": "2015-04-02T23:21:55.000+0000",
        "bug_report": {
            "title": "NullPointerException in DatanodeManager during Block Location Retrieval",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with HDFS enabled.",
                    "2. Attempt to access a file stored in HDFS using a client application.",
                    "3. Monitor the logs for any exceptions or errors."
                ],
                "actualBehavior": "A NullPointerException is thrown in the DatanodeManager while trying to sort located blocks, leading to failure in retrieving block locations.",
                "possibleCause": "The issue may be caused by a null reference being passed to the sortLocatedBlocks method, possibly due to an uninitialized or improperly configured Datanode."
            },
            "stackTrace": "org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException\n         at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:359)\n         at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1789)\n         at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:542)\n         at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:362)\n         at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n         at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n         at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n         at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)\n         at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)\n         at java.security.AccessController.doPrivileged(Native Method)\n         at javax.security.auth.Subject.doAs(Subject.java:415)\n         at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n         at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)\n         at org.apache.hadoop.ipc.Client.call(Client.java:1468)\n         at org.apache.hadoop.ipc.Client.call(Client.java:1399)\n         at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n         at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)\n         at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)\n         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n         at java.lang.reflect.Method.invoke(Method.java:606)\n         at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n         at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n         at com.sun.proxy.$Proxy15.getBlockLocations(Unknown Source)\n         at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1220)\n         at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1210)\n         at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1200)\n         at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:271)\n         at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:238)\n         at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:231)\n         at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1498)\n         at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)\n         at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)\n         at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n         at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)\n         at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)\n         at org.apache.hadoop.hbase.util.HFileV1Detector$1.call(HFileV1Detector.java:320)\n         at org.apache.hadoop.hbase.util.HFileV1Detector$1.call(HFileV1Detector.java:300)\n         at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n         at java.lang.Thread.run(Thread.java:745)\n\norg.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException\n         at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:359)\n         at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1789)\n         at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:542)\n         at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:362)"
        }
    },
    {
        "filename": "HDFS-6533.json",
        "creation_time": "2014-06-14T16:15:02.000+0000",
        "bug_report": {
            "title": "Mockito Verification Failure in TestBPOfferService",
            "description": {
                "stepsToReproduce": [
                    "Run the test suite for the Hadoop HDFS module.",
                    "Locate the TestBPOfferService class.",
                    "Execute the testBasicFunctionality method."
                ],
                "actualBehavior": "The test fails with a Mockito verification error indicating that the registerDatanode method was expected to be called but was never invoked.",
                "possibleCause": "The mock object for datanodeProtocolClientSideTranslatorPB may not have been properly set up or the method registerDatanode was not called during the execution of the test."
            },
            "stackTrace": "org.mockito.exceptions.verification.WantedButNotInvoked: \nWanted but not invoked:\ndatanodeProtocolClientSideTranslatorPB.registerDatanode(\n    <any>\n);\n-> at org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBasicFunctionality(TestBPOfferService.java:175)\nActually, there were zero interactions with this mock.\n\n\tat org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBasicFunctionality(TestBPOfferService.java:175)"
        }
    },
    {
        "filename": "HDFS-10609.json",
        "creation_time": "2016-07-11T17:14:39.000+0000",
        "bug_report": {
            "title": "InvalidEncryptionKeyException during Data Transfer in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop HDFS cluster with encryption enabled.",
                    "2. Attempt to write data to the HDFS using a client that has an outdated or missing encryption key.",
                    "3. Monitor the logs for exceptions during the data transfer process."
                ],
                "actualBehavior": "The operation fails with an InvalidEncryptionKeyException, indicating that the required block key does not exist.",
                "possibleCause": "The client may be using an outdated encryption key that does not match the key required for the block being accessed."
            },
            "stackTrace": "org.apache.hadoop.hdfs.protocol.datatransfer.InvalidEncryptionKeyException: Can't re-compute encryption key for nonce, since the required block key (keyID=557709482) doesn't exist. Current key: 1350592619\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiatedCipherOption(DataTransferSaslUtil.java:417)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:474)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getEncryptedStreams(SaslDataTransferClient.java:299)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:242)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:211)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:1308)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1272)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1433)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1147)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:632)\n\nCaused by: org.apache.hadoop.hdfs.protocol.datatransfer.InvalidEncryptionKeyException: Can't re-compute encryption key for nonce, since the required block key (keyID=557709482) doesn't exist. Current key: 1350592619\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiatedCipherOption(DataTransferSaslUtil.java:417)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:474)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getEncryptedStreams(SaslDataTransferClient.java:299)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:242)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:211)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:1308)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1272)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1433)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1147)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:632)"
        }
    },
    {
        "filename": "HDFS-2310.json",
        "creation_time": "2011-09-05T15:31:00.000+0000",
        "bug_report": {
            "title": "IOException: Unknown protocol: org.apache.hadoop.hdfs.server.protocol.JournalProtocol",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Attempt to connect to the HDFS server using a client that requires JournalProtocol.",
                    "3. Observe the logs for any exceptions or errors."
                ],
                "actualBehavior": "An IOException is thrown indicating an unknown protocol: org.apache.hadoop.hdfs.server.protocol.JournalProtocol.",
                "possibleCause": "The JournalProtocol may not be properly registered or the required libraries for the protocol are missing from the classpath."
            },
            "stackTrace": "java.io.IOException: java.io.IOException: Unknown protocol: org.apache.hadoop.hdfs.server.protocol.JournalProtocol\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:622)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)\n\njava.io.IOException: java.io.IOException: Unknown protocol: org.apache.hadoop.hdfs.server.protocol.JournalProtocol\n\tat org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:622)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)"
        }
    },
    {
        "filename": "HDFS-3385.json",
        "creation_time": "2012-05-08T12:45:31.000+0000",
        "bug_report": {
            "title": "ClassCastException in FSNamesystem during file append operation",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Attempt to append data to an existing file in HDFS using the DistributedFileSystem API.",
                    "3. Observe the logs for any exceptions thrown during the operation."
                ],
                "actualBehavior": "A ClassCastException is thrown indicating that BlockInfo cannot be cast to BlockInfoUnderConstruction.",
                "possibleCause": "The issue may be caused by an inconsistency in the block management state, where the system is trying to append to a block that is not in the expected state."
            },
            "stackTrace": "Exception in thread \"main\" java.lang.ClassCastException: org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo cannot be cast to org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoUnderConstruction\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1787)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1584)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1824)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:425)\n\t...\n\tat org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1150)\n\tat org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1189)\n\tat org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1177)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:221)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:1)\n\tat org.apache.hadoop.fs.FileSystem.append(FileSystem.java:981)\n\tat org.apache.hadoop.hdfs.server.datanode.DeleteMe.main(DeleteMe.java:26)"
        }
    },
    {
        "filename": "HDFS-4006.json",
        "creation_time": "2012-10-04T22:05:14.000+0000",
        "bug_report": {
            "title": "NullPointerException in SecondaryNameNode during checkpointing",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Trigger a checkpoint operation on the SecondaryNameNode.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown, causing the SecondaryNameNode to fail during the checkpoint process.",
                "possibleCause": "The NullPointerException may be caused by an uninitialized variable or a missing configuration that is required for the checkpoint operation."
            },
            "stackTrace": "org.apache.hadoop.util.ExitUtil$ExitException: Fatal exception with message null\njava.lang.NullPointerException\nat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:480)\nat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:331)\nat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$2.run(SecondaryNameNode.java:298)\nat org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:452)\nat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:294)\nat java.lang.Thread.run(Thread.java:662)"
        }
    },
    {
        "filename": "HDFS-6715.json",
        "creation_time": "2014-07-21T21:26:25.000+0000",
        "bug_report": {
            "title": "IOException: Namenode is in startup mode",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop Namenode service.",
                    "Attempt to connect to the Namenode from a client application.",
                    "Perform any operation that requires interaction with the Namenode."
                ],
                "actualBehavior": "The client application throws an IOException indicating that the Namenode is in startup mode.",
                "possibleCause": "The Namenode may not have completed its startup process, leading to the inability to handle client requests."
            },
            "stackTrace": "java.io.IOException: Namenode is in startup mode\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:525)"
        }
    },
    {
        "filename": "HDFS-2392.json",
        "creation_time": "2011-09-30T20:29:09.000+0000",
        "bug_report": {
            "title": "DistCp Job Failure with IOException",
            "description": {
                "stepsToReproduce": [
                    "1. Initiate a DistCp job to copy files from a source to a destination.",
                    "2. Monitor the job execution through the Hadoop job tracker or logs.",
                    "3. Observe the job completion status and any error messages."
                ],
                "actualBehavior": "The DistCp job fails with an IOException indicating that no files were copied, skipped, or failed, but the job itself is marked as failed.",
                "possibleCause": "The failure may be due to permission issues, network problems, or an invalid source/destination path."
            },
            "stackTrace": "java.io.IOException: Copied: 0 Skipped: 0 Failed: 1\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.close(DistCp.java:582)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)\n        at org.apache.hadoop.mapred.Child.main(Child.java:249)\n\njava.io.IOException: Copied: 0 Skipped: 0 Failed: 1\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.close(DistCp.java:582)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)\n        at org.apache.hadoop.mapred.Child.main(Child.java:249)\n\njava.io.IOException: Copied: 0 Skipped: 0 Failed: 1\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.close(DistCp.java:582)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n        at org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)\n        at org.apache.hadoop.mapred.Child.main(Child.java:249)\n\nCopy failed: java.io.IOException: Job failed!\n        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1257)\n        at org.apache.hadoop.tools.DistCp.copy(DistCp.java:667)\n        at org.apache.hadoop.tools.DistCp.run(DistCp.java:881)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)\n        at org.apache.hadoop.tools.DistCp.main(DistCp.java:908)"
        }
    },
    {
        "filename": "HDFS-11472.json",
        "creation_time": "2017-02-28T18:39:13.000+0000",
        "bug_report": {
            "title": "IOException during Replica Recovery in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS DataNode service.",
                    "2. Trigger a block recovery process by simulating a block failure.",
                    "3. Monitor the logs for any exceptions during the recovery process."
                ],
                "actualBehavior": "An IOException is thrown indicating that the bytes on disk are less than the visible length during the replica recovery process.",
                "possibleCause": "This may be caused by a mismatch between the expected and actual state of the block data, possibly due to concurrent modifications or corruption."
            },
            "stackTrace": "java.io.IOException: THIS IS NOT SUPPOSED TO HAPPEN: getBytesOnDisk() < getVisibleLength(), rip=ReplicaBeingWritten, blk_2526438952_1101394519586, RBW\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.initReplicaRecovery(FsDatasetImpl.java:2284)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.initReplicaRecovery(FsDatasetImpl.java:2260)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initReplicaRecovery(DataNode.java:2566)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.callInitReplicaRecovery(DataNode.java:2577)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:2645)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.access$400(DataNode.java:245)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode$5.run(DataNode.java:2551)\n        at java.lang.Thread.run(Thread.java:745)\n\njava.nio.channels.ClosedByInterruptException\n        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)\n        at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:269)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.adjustCrcChannelPosition(FsDatasetImpl.java:1484)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.adjustCrcFilePosition(BlockReceiver.java:994)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:670)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:857)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:797)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:169)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:106)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:244)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-10760.json",
        "creation_time": "2016-08-12T08:29:24.000+0000",
        "bug_report": {
            "title": "Expired Block Token Access Error in Hadoop HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to read a block from HDFS using a block token.",
                    "2. Ensure that the block token has expired before the read operation.",
                    "3. Execute the read operation to access the block."
                ],
                "actualBehavior": "The system throws an InvalidToken exception indicating that the block token is expired.",
                "possibleCause": "The block token's expiry date is reached before the read operation is attempted, leading to access denial."
            },
            "stackTrace": "org.apache.hadoop.security.token.SecretManager$InvalidToken: Block token with block_token_identifier (expiryDate=1470850746803, keyId=-2093956963, userId=hbase, blockPoolId=BP-641703426-10.17.1.2-1468517918886, blockId=1077120201, access modes=[READ]) is expired.\n        at org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.checkAccess(BlockTokenSecretManager.java:280)\n        at org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.checkAccess(BlockTokenSecretManager.java:301)\n        at org.apache.hadoop.hdfs.security.token.block.BlockPoolTokenSecretManager.checkAccess(BlockPoolTokenSecretManager.java:97)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.checkAccess(DataXceiver.java:1236)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:481)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:242)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-13635.json",
        "creation_time": "2018-05-29T19:54:50.000+0000",
        "bug_report": {
            "title": "ReplicaNotFoundException when attempting to append to a non-existent replica",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Attempt to append data to a file that has a replica that is not present in the DataNode.",
                    "3. Observe the logs for any exceptions thrown."
                ],
                "actualBehavior": "An org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException is thrown, indicating that the system cannot append to a non-existent replica.",
                "possibleCause": "The replica may have been deleted or not properly created, leading to the DataNode being unable to find it when an append operation is attempted."
            },
            "stackTrace": "org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Cannot append to a non-existent replica BP-725378529-10.236.236.8-1410027444173:13276792346\n at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:792)\n at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaVisibleLength(FsDatasetImpl.java:2588)\n at org.apache.hadoop.hdfs.server.datanode.DataNode.getReplicaVisibleLength(DataNode.java:2756)\n at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getReplicaVisibleLength(ClientDatanodeProtocolServerSideTranslatorPB.java:107)\n at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:17873)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2211)"
        }
    },
    {
        "filename": "HDFS-11608.json",
        "creation_time": "2017-03-31T17:37:20.000+0000",
        "bug_report": {
            "title": "IOException due to Incorrect Packet Payload Size in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop HDFS cluster with multiple data nodes.",
                    "2. Attempt to write a large file (greater than the maximum packet size) to the HDFS.",
                    "3. Monitor the logs for any exceptions or errors during the write operation."
                ],
                "actualBehavior": "An IOException is thrown indicating an incorrect value for packet payload size: 2147483128.",
                "possibleCause": "The packet payload size exceeds the maximum allowable value for an integer in Java, leading to an overflow or incorrect size being processed."
            },
            "stackTrace": "java.io.IOException: Incorrect value for packet payload size: 2147483128\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:159)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:502)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:898)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:806)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-12638.json",
        "creation_time": "2017-10-11T11:29:04.000+0000",
        "bug_report": {
            "title": "NullPointerException in ReplicationWork.chooseTargets",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Trigger a replication event by adding or modifying a file in HDFS.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "The system throws a NullPointerException, causing the replication process to fail.",
                "possibleCause": "It is possible that a required object or configuration is not initialized or is set to null before the chooseTargets method is called."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.blockmanagement.ReplicationWork.chooseTargets(ReplicationWork.java:55)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1532)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1491)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3792)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3744)\n        at java.lang.Thread.run(Thread.java:834)"
        }
    },
    {
        "filename": "HDFS-12383.json",
        "creation_time": "2017-08-31T20:43:50.000+0000",
        "bug_report": {
            "title": "CancellationException in ReencryptionUpdater",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS namenode service.",
                    "2. Initiate a reencryption task that involves multiple files.",
                    "3. Monitor the task execution and observe for any cancellation events."
                ],
                "actualBehavior": "The reencryption task fails with a CancellationException, preventing successful completion of the task.",
                "possibleCause": "The task may be getting cancelled due to a timeout or an external interruption, leading to the CancellationException being thrown."
            },
            "stackTrace": "java.util.concurrent.CancellationException\n        at java.util.concurrent.FutureTask.report(FutureTask.java:121)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:192)\n        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.takeAndProcessTasks(ReencryptionUpdater.java:404)\n        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.run(ReencryptionUpdater.java:250)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-5322.json",
        "creation_time": "2013-10-07T22:52:54.000+0000",
        "bug_report": {
            "title": "HDFS Delegation Token Not Found in Cache",
            "description": {
                "stepsToReproduce": [
                    "1. Submit a job to the Hadoop cluster that requires HDFS access.",
                    "2. Ensure that the job is executed by a Yarn application.",
                    "3. Monitor the logs for any errors related to delegation tokens."
                ],
                "actualBehavior": "The job fails with an error indicating that the HDFS delegation token cannot be found in the cache.",
                "possibleCause": "The HDFS delegation token may have expired or was not properly cached, leading to the inability to retrieve it during the job execution."
            },
            "stackTrace": "at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)\nat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)\nError: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 11 for hrt_qa) can't be found in cache\nat org.apache.hadoop.ipc.Client.call(Client.java:1347)\nat org.apache.hadoop.ipc.Client.call(Client.java:1300)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\nat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)"
        }
    },
    {
        "filename": "HDFS-11741.json",
        "creation_time": "2017-05-02T17:57:25.000+0000",
        "bug_report": {
            "title": "InvalidEncryptionKeyException during Data Transfer in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop HDFS cluster with encryption enabled.",
                    "2. Attempt to transfer data between nodes in the cluster.",
                    "3. Monitor the logs for any encryption key-related errors."
                ],
                "actualBehavior": "An InvalidEncryptionKeyException is thrown, indicating that the required block key does not exist.",
                "possibleCause": "The exception may occur due to a mismatch between the expected encryption key ID and the current key ID, possibly due to key rotation or misconfiguration."
            },
            "stackTrace": "org.apache.hadoop.hdfs.protocol.datatransfer.InvalidEncryptionKeyException: Can't re-compute encryption key for nonce, since the required block key (keyID=1005215027) doesn't exist. Current key: 1005215030\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessageAndNegotiatedCipherOption(DataTransferSaslUtil.java:417)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:474)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getEncryptedStreams(SaslDataTransferClient.java:299)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:242)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:211)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:183)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:311)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$2300(Dispatcher.java:182)\n        at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:899)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-3936.json",
        "creation_time": "2012-09-14T05:35:12.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockManager during replication work computation",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Trigger a replication event by adding or modifying files in HDFS.",
                    "3. Monitor the logs for any exceptions or errors."
                ],
                "actualBehavior": "The service throws a NullPointerException, leading to a fatal exit.",
                "possibleCause": "The BlocksMap.getBlockCollection method is likely receiving a null reference, which could indicate an issue with block metadata or an uninitialized block collection."
            },
            "stackTrace": "org.apache.hadoop.util.ExitUtil$ExitException: Fatal exception with message null\nstack trace\njava.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.getBlockCollection(BlocksMap.java:101)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1132)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1107)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3061)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3023)\n\tat java.lang.Thread.run(Thread.java:662)"
        }
    },
    {
        "filename": "HDFS-6348.json",
        "creation_time": "2014-05-07T12:34:54.000+0000",
        "bug_report": {
            "title": "ClassNotFoundException for MyBlockPlacementPolicy in Hadoop HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Configure the block placement policy to use com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy.",
                    "3. Attempt to initialize the Secondary NameNode."
                ],
                "actualBehavior": "The service fails to start, throwing a ClassNotFoundException for com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy.",
                "possibleCause": "The class com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy is not included in the classpath or is missing from the deployment."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1900)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.getInstance(BlockPlacementPolicy.java:199)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:256)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:635)\n\tat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.initialize(SecondaryNameNode.java:260)\n\tat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.<init>(SecondaryNameNode.java:205)\n\tat org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.main(SecondaryNameNode.java:695)\nCaused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1868)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1892)\n\t... 6 more\nCaused by: java.lang.ClassNotFoundException: Class com.huawei.hadoop.hdfs.server.blockmanagement.MyBlockPlacementPolicy not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1774)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1866)"
        }
    },
    {
        "filename": "HDFS-7884.json",
        "creation_time": "2015-03-04T15:47:50.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockSender Initialization",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Attempt to read a block from the data node using the DataXceiver.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown during the initialization of the BlockSender, causing the read operation to fail.",
                "possibleCause": "The BlockSender may be trying to access an uninitialized or null reference, possibly due to a misconfiguration or missing data."
            },
            "stackTrace": "java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:264)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:506)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:116)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:71)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:249)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-7996.json",
        "creation_time": "2015-03-26T21:19:55.000+0000",
        "bug_report": {
            "title": "ReplicaNotFoundException when finalizing block in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS cluster with a DataNode.",
                    "2. Attempt to write a file to HDFS that generates a block.",
                    "3. Simulate a failure or interruption that causes the block replica to be lost.",
                    "4. Attempt to finalize the block after the failure."
                ],
                "actualBehavior": "The system throws a ReplicaNotFoundException indicating that it cannot append to a non-existent replica.",
                "possibleCause": "The block replica may have been deleted or not properly created due to a failure during the write process."
            },
            "stackTrace": "org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Cannot append to a non-existent replica BP-51301509-10.20.202.114-1427296597742:blk_1073742979_2160\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:615)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.finalizeBlock(FsDatasetImpl.java:1362)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.finalizeBlock(BlockReceiver.java:1281)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1241)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-4302.json",
        "creation_time": "2012-12-11T19:44:59.000+0000",
        "bug_report": {
            "title": "IllegalStateException in NameNode during initialization",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop NameNode service.",
                    "Ensure that the necessary edit log files are present.",
                    "Monitor the logs for any exceptions during the startup process."
                ],
                "actualBehavior": "The NameNode fails to start and throws an IllegalStateException indicating that the input stream must be obtained before the length is available.",
                "possibleCause": "The issue may be caused by an attempt to access the length of an input stream before it has been properly initialized, possibly due to a misconfiguration or corrupted edit log files."
            },
            "stackTrace": "FATAL namenode.NameNode (NameNode.java:main(1224)) - Exception in namenode join\njava.lang.IllegalStateException: must get input stream before length is available\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:145)\n        at org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream$URLLog.length(EditLogFileInputStream.java:405)\n        at org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.length(EditLogFileInputStream.java:258)\n        at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.length(RedundantEditLogInputStream.java:256)\n        at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.length(RedundantEditLogInputStream.java:256)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:125)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:88)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:697)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:642)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:259)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:604)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:447)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:409)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:400)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:434)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:606)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:591)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1153)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1219)"
        }
    },
    {
        "filename": "HDFS-11849.json",
        "creation_time": "2017-05-18T11:31:48.000+0000",
        "bug_report": {
            "title": "Login Failure for Keytab Authentication in JournalNode",
            "description": {
                "stepsToReproduce": [
                    "1. Configure the Hadoop environment with a valid keytab file.",
                    "2. Attempt to start the JournalNode service using the configured keytab.",
                    "3. Observe the logs for any authentication errors."
                ],
                "actualBehavior": "The JournalNode fails to start, throwing a LoginException indicating a login failure for the specified user from the keytab.",
                "possibleCause": "The keytab file may be invalid, the user may not have the correct permissions, or there may be a misconfiguration in the Kerberos setup."
            },
            "stackTrace": "Exception in thread \"main\" java.io.IOException: Login failure for xxx/yyyy@ZZZZ.COM from keytab dummy.keytab: javax.security.auth.login.LoginException: host1\n        at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:994)\n        at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:281)\n        at org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:153)\n        at org.apache.hadoop.hdfs.qjournal.server.JournalNode.run(JournalNode.java:132)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)\n        at org.apache.hadoop.hdfs.qjournal.server.JournalNode.main(JournalNode.java:318)"
        }
    },
    {
        "filename": "HDFS-4841.json",
        "creation_time": "2013-05-22T17:01:36.000+0000",
        "bug_report": {
            "title": "IllegalStateException during shutdown hook addition in Hadoop",
            "description": {
                "stepsToReproduce": [
                    "1. Start a Hadoop application that utilizes WebHDFS.",
                    "2. Trigger a shutdown of the Hadoop application while it is still processing.",
                    "3. Observe the logs for any exceptions thrown during the shutdown process."
                ],
                "actualBehavior": "An IllegalStateException is thrown indicating that a shutdown is in progress and a shutdown hook cannot be added.",
                "possibleCause": "The application attempts to add a shutdown hook after the shutdown process has already begun, leading to this exception."
            },
            "stackTrace": "java.lang.IllegalStateException: Shutdown in progress, cannot add a shutdownHook\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:152)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2400)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2372)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:352)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$DtRenewer.getWebHdfs(WebHdfsFileSystem.java:1001)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem$DtRenewer.cancel(WebHdfsFileSystem.java:1013)\n\tat org.apache.hadoop.security.token.Token.cancel(Token.java:382)\n\tat org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction.cancel(DelegationTokenRenewer.java:152)\n\tat org.apache.hadoop.fs.DelegationTokenRenewer$RenewAction.access$200(DelegationTokenRenewer.java:58)\n\tat org.apache.hadoop.fs.DelegationTokenRenewer.removeRenewAction(DelegationTokenRenewer.java:241)\n\tat org.apache.hadoop.hdfs.web.WebHdfsFileSystem.close(WebHdfsFileSystem.java:822)\n\tat org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2446)\n\tat org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2463)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)"
        }
    },
    {
        "filename": "HDFS-3384.json",
        "creation_time": "2012-05-08T09:01:10.000+0000",
        "bug_report": {
            "title": "EOFException and NullPointerException during HDFS Data Streaming",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to write data to HDFS using DFSOutputStream.",
                    "2. Ensure that the datanode at 10.18.40.20:50010 is either down or unreachable.",
                    "3. Observe the behavior of the application during the write operation."
                ],
                "actualBehavior": "The application throws an EOFException followed by a NullPointerException, and ultimately fails with an IOException indicating that all datanodes are bad.",
                "possibleCause": "The issue may be caused by the datanode being unavailable, leading to a failure in establishing a connection for data streaming, which results in the EOFException and subsequent NullPointerException."
            },
            "stackTrace": "java.io.EOFException: Premature EOF: no length prefix available\n\tat org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:162)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1039)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:939)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:510)\n\njava.io.IOException: All datanodes 10.18.40.20:50010 are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:908)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.io.IOException: All datanodes 10.18.40.20:50010 are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:908)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)"
        }
    },
    {
        "filename": "HDFS-5657.json",
        "creation_time": "2013-12-11T21:59:46.000+0000",
        "bug_report": {
            "title": "IllegalStateException in AsyncDataService due to false async status",
            "description": {
                "stepsToReproduce": [
                    "1. Start the NFS service with the AsyncDataService enabled.",
                    "2. Attempt to perform a write operation on a file using the OpenFileCtx.",
                    "3. Monitor the logs for any errors during the write operation."
                ],
                "actualBehavior": "The system throws an IllegalStateException indicating that the openFileCtx has a false async status, preventing the write operation from completing.",
                "possibleCause": "The OpenFileCtx may not have been properly initialized or the async status was incorrectly set to false, leading to the failure during the write back operation."
            },
            "stackTrace": "ERROR nfs3.AsyncDataService (AsyncDataService.java:run(136)) - Asyn data service got error:java.lang.IllegalStateException: The openFileCtx has false async status\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:145)\n        at org.apache.hadoop.hdfs.nfs.nfs3.OpenFileCtx.executeWriteBack(OpenFileCtx.java:890)\n        at org.apache.hadoop.hdfs.nfs.nfs3.AsyncDataService$WriteBackTask.run(AsyncDataService.java:134)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)"
        }
    },
    {
        "filename": "HDFS-11827.json",
        "creation_time": "2017-05-16T06:28:49.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockPlacementPolicyDefault.chooseRandom",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Trigger a replication event that requires block placement decisions.",
                    "3. Monitor the logs for any exceptions thrown during the block placement process."
                ],
                "actualBehavior": "A NullPointerException is thrown in the BlockPlacementPolicyDefault.chooseRandom method, causing the replication process to fail.",
                "possibleCause": "The method may be attempting to access an object that has not been initialized or is null, possibly due to an incorrect configuration or state of the block manager."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:666)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:607)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:375)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:446)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:446)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:240)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:119)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyWithMultiDC.chooseTargetInternal(BlockPlacementPolicyWithMultiDC.java:263)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyWithMultiDC.chooseTarget(BlockPlacementPolicyWithMultiDC.java:214)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.chooseTargets(BlockManager.java:3836)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationWork.access$200(BlockManager.java:3801)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1394)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1300)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3764)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3711)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-6804.json",
        "creation_time": "2014-08-01T05:37:23.000+0000",
        "bug_report": {
            "title": "Checksum Error During Block Write in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop cluster with HDFS.",
                    "2. Attempt to write a block of data to the HDFS from a client node.",
                    "3. Monitor the logs for any checksum errors during the write operation."
                ],
                "actualBehavior": "The write operation fails with a checksum error, causing the process to terminate unexpectedly.",
                "possibleCause": "The issue may be related to network instability or data corruption during transmission, leading to a checksum mismatch."
            },
            "stackTrace": "java.io.IOException: Terminating due to a checksum error.java.io.IOException: Unexpected checksum mismatch while writing BP-2072804351-192.168.2.104-1406008383435:blk_1073741997_9248 from /192.168.2.101:39495\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:536)\n        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:703)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:575)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:115)\n        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:68)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:221)\n        at java.lang.Thread.run(Thread.java:744)"
        }
    },
    {
        "filename": "HDFS-5843.json",
        "creation_time": "2014-01-28T06:05:16.000+0000",
        "bug_report": {
            "title": "IOException and ArithmeticException during block checksum retrieval in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop HDFS cluster with multiple data nodes.",
                    "2. Upload a file to the HDFS.",
                    "3. Attempt to retrieve the file checksum using the DFSClient."
                ],
                "actualBehavior": "An IOException is thrown indicating failure to get block MD5, followed by an ArithmeticException due to division by zero.",
                "possibleCause": "The division by zero in the blockChecksum method may indicate that the block size or related metadata is not properly initialized or corrupted."
            },
            "stackTrace": "java.io.IOException: Fail to get block MD5 for BP-341493254-192.168.1.10-1390888724459:blk_1073741825_1001\n\tat org.apache.hadoop.hdfs.DFSClient.getFileChecksum(DFSClient.java:1965)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileChecksum(DFSClient.java:1771)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1186)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$21.doCall(DistributedFileSystem.java:1)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1194)\n\njava.lang.ArithmeticException: / by zero\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.blockChecksum(DataXceiver.java:658)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opBlockChecksum(Receiver.java:169)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:77)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:221)\n\tat java.lang.Thread.run(Thread.java:695)"
        }
    },
    {
        "filename": "HDFS-8070.json",
        "creation_time": "2015-04-06T19:57:58.000+0000",
        "bug_report": {
            "title": "IOException and ClosedChannelException in Hadoop Short-Circuit Cache",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service with short-circuit read enabled.",
                    "2. Attempt to read data from HDFS using a client that utilizes short-circuit reads.",
                    "3. Monitor the logs for any exceptions or errors during the read operation."
                ],
                "actualBehavior": "The application throws IOException with ERROR_INVALID indicating no shared memory segment is registered, followed by ClosedChannelException and EOFException.",
                "possibleCause": "The issue may be caused by improper handling of shared memory segments in the short-circuit cache, possibly due to a race condition or resource cleanup issue."
            },
            "stackTrace": "java.io.IOException: ERROR_INVALID: there is no shared memory segment registered with shmId a86ee34576d93c4964005d90b0d97c38\n\tat org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:208)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.nio.channels.ClosedChannelException\n\tat org.apache.hadoop.util.CloseableReferenceCount.reference(CloseableReferenceCount.java:57)\n\tat org.apache.hadoop.net.unix.DomainSocket.shutdown(DomainSocket.java:387)\n\tat org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.shutdown(DfsClientShmManager.java:378)\n\tat org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:223)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.io.IOException: ERROR_INVALID: there is no shared memory segment registered with shmId a86ee34576d93c4964005d90b0d97c38\n\tat org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:208)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.io.EOFException\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitFds(DataXceiver.java:352)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitFds(Receiver.java:187)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:89)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-1085.json",
        "creation_time": "2010-04-06T22:49:40.000+0000",
        "bug_report": {
            "title": "File Size Mismatch Error During DistCp Operation",
            "description": {
                "stepsToReproduce": [
                    "Initiate a DistCp operation to copy files from an HFTP source to an HDFS destination.",
                    "Ensure that the source file size is significantly larger than the destination file size.",
                    "Monitor the logs for any IOException related to file size mismatch."
                ],
                "actualBehavior": "The DistCp operation fails with an IOException indicating that the copied file size does not match the expected file size.",
                "possibleCause": "There may be an issue with the source file being incomplete or corrupted, or there could be a misconfiguration in the source or destination paths."
            },
            "stackTrace": "java.io.IOException: File size not matched: copied 193855488 bytes (184.9m) to tmpfile (=hdfs://omehost.com:8020/somepath/part-00032) but expected 1710327403 bytes (1.6g) from hftp://someotherhost/somepath/part-00032\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.copy(DistCp.java:435)\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:543)\n        at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:310)\n        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)\n        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:358)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:307)\n        at org.apache.hadoop.mapred.Child.main(Child.java:159)"
        }
    },
    {
        "filename": "HDFS-12339.json",
        "creation_time": "2017-08-23T03:16:49.000+0000",
        "bug_report": {
            "title": "Unregistration Failure Due to Closed Socket",
            "description": {
                "stepsToReproduce": [
                    "1. Initialize the SimpleUdpClient.",
                    "2. Attempt to send a datagram after the socket has been closed.",
                    "3. Observe the error that occurs during the send operation."
                ],
                "actualBehavior": "The application throws a RuntimeException indicating 'Unregistration failure' due to a SocketException stating 'Socket is closed'.",
                "possibleCause": "The socket may have been closed prematurely or not properly managed, leading to attempts to send data on a closed socket."
            },
            "stackTrace": "java.lang.RuntimeException: Unregistration failure\nCaused by: java.net.SocketException: Socket is closed\n at java.net.DatagramSocket.send(DatagramSocket.java:641)\n at org.apache.hadoop.oncrpc.SimpleUdpClient.run(SimpleUdpClient.java:62)"
        }
    },
    {
        "filename": "HDFS-6520.json",
        "creation_time": "2014-06-12T02:32:29.000+0000",
        "bug_report": {
            "title": "IOException during block copy in NamenodeFsck",
            "description": {
                "stepsToReproduce": [
                    "Run the NamenodeFsck command to check the filesystem.",
                    "Attempt to copy a block that is suspected to be corrupted.",
                    "Observe the output for any exceptions or errors."
                ],
                "actualBehavior": "An IOException is thrown indicating an expected empty end-of-read packet was not received, leading to a failure in copying block data.",
                "possibleCause": "The issue may be caused by a corrupted block or a network issue that prevents the proper reading of the block data."
            },
            "stackTrace": "java.io.IOException: Expected empty end-of-read packet! Header: PacketHeader with packetLen=66048 header data: offsetInBlock: 65536\nseqno: 1\nlastPacketInBlock: false\ndataLen: 65536\n\n        at org.apache.hadoop.hdfs.RemoteBlockReader2.readTrailingEmptyPacket(RemoteBlockReader2.java:259)\n        at org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:220)\n        at org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:138)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlock(NamenodeFsck.java:649)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlocksToLostFound(NamenodeFsck.java:543)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(NamenodeFsck.java:460)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(NamenodeFsck.java:324)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.fsck(NamenodeFsck.java:233)\n        at org.apache.hadoop.hdfs.server.namenode.FsckServlet$1.run(FsckServlet.java:67)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.hdfs.server.namenode.FsckServlet.doGet(FsckServlet.java:58)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1192)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.NoCacheFilter.doFilter(ServletHandler.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:326)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n\njava.lang.Exception: Could not copy block data for BP-654596295-10.37.7.84-1402466764642:blk_1073741825_1001\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlock(NamenodeFsck.java:664)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlocksToLostFound(NamenodeFsck.java:543)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(NamenodeFsck.java:460)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(NamenodeFsck.java:324)\n        at org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.fsck(NamenodeFsck.java:233)\n        at org.apache.hadoop.hdfs.server.namenode.FsckServlet$1.run(FsckServlet.java:67)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.hdfs.server.namenode.FsckServlet.doGet(FsckServlet.java:58)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.NoCacheFilter.doFilter(ServletHandler.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:326)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)"
        }
    },
    {
        "filename": "HDFS-10715.json",
        "creation_time": "2016-08-02T08:10:23.000+0000",
        "bug_report": {
            "title": "NullPointerException in AvailableSpaceBlockPlacementPolicy",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Attempt to add a new block to the file system.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown during the block placement process, causing the block addition to fail.",
                "possibleCause": "The exception may be caused by a null reference in the AvailableSpaceBlockPlacementPolicy class, possibly due to uninitialized data nodes or missing configuration."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy.compareDataNode(AvailableSpaceBlockPlacementPolicy.java:95)\n        at org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy.chooseDataNode(AvailableSpaceBlockPlacementPolicy.java:80)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:691)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:665)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:572)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:457)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:367)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:242)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:114)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:130)\n        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1606)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3315)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:679)\n        at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:214)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:489)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)"
        }
    },
    {
        "filename": "HDFS-3332.json",
        "creation_time": "2012-04-27T04:42:38.000+0000",
        "bug_report": {
            "title": "NullPointerException in DatanodeID Initialization",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Trigger a block report from a DataNode.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown during the initialization of DatanodeID, causing the block report process to fail.",
                "possibleCause": "It is possible that a required parameter for the DatanodeID constructor is not being properly initialized or passed, leading to a null reference."
            },
            "stackTrace": "java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.protocol.DatanodeID.<init>(DatanodeID.java:66)\n\tat org.apache.hadoop.hdfs.protocol.DatanodeInfo.<init>(DatanodeInfo.java:87)\n\tat org.apache.hadoop.hdfs.server.datanode.BPServiceActor.reportBadBlocks(BPServiceActor.java:238)\n\tat org.apache.hadoop.hdfs.server.datanode.BPOfferService.reportBadBlocks(BPOfferService.java:187)\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.reportBadBlocks(DataNode.java:559)\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.checkAndUpdate(FsDatasetImpl.java:1377)\n\tat org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile(DirectoryScanner.java:318)\n\tat org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run(DirectoryScanner.java:284)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n\tat java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:181)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:205)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)"
        }
    },
    {
        "filename": "HDFS-6130.json",
        "creation_time": "2014-03-20T07:15:47.000+0000",
        "bug_report": {
            "title": "NullPointerException in NameNode during FSImage loading",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop NameNode service.",
                    "Attempt to load a previously saved FSImage file.",
                    "Monitor the logs for any exceptions or errors."
                ],
                "actualBehavior": "The NameNode fails to start and throws a NullPointerException during the FSImage loading process.",
                "possibleCause": "The issue may be caused by a missing or improperly initialized object in the FSDirectory class, specifically related to reserved names."
            },
            "stackTrace": "FATAL namenode.NameNode: Exception in namenode join\njava.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.isReservedName(FSDirectory.java:2984)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode$Loader.addToParent(FSImageFormatPBINode.java:205)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode$Loader.loadINodeDirectorySection(FSImageFormatPBINode.java:162)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.loadInternal(FSImageFormatProtobuf.java:243)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.load(FSImageFormatProtobuf.java:168)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat$LoaderDelegator.java:120)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:895)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:881)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:704)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:642)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:271)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:894)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:653)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initializeSharedEdits(NameNode.java:912)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1276)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1360)"
        }
    },
    {
        "filename": "HDFS-2827.json",
        "creation_time": "2012-01-23T09:34:51.000+0000",
        "bug_report": {
            "title": "IOException when saving leases in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS namenode service.",
                    "2. Create a file at the path /test1/est/abc.txt.",
                    "3. Attempt to save the filesystem image."
                ],
                "actualBehavior": "An IOException is thrown indicating that the path /test1/est/abc.txt was found but has no matching entry in the namespace.",
                "possibleCause": "The file /test1/est/abc.txt may not have been properly registered in the namespace, possibly due to a failure during file creation or a race condition."
            },
            "stackTrace": "java.io.IOException: saveLeases found path /test1/est/abc.txt but no matching entry in namespace.[/test1/est/abc.txt]\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.saveFilesUnderConstruction(FSNamesystem.java:4336)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Saver.save(FSImageFormat.java:588)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImage(FSImage.java:761)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage$FSImageSaver.run(FSImage.java:789)\n\tat java.lang.Thread.run(Unknown Source)"
        }
    },
    {
        "filename": "HDFS-11056.json",
        "creation_time": "2016-10-25T23:00:33.000+0000",
        "bug_report": {
            "title": "IOException and ChecksumException during file operations in Hadoop",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to read a block from HDFS that is reported as missing.",
                    "2. Try to append data to a file in HDFS that has insufficient replication.",
                    "3. Execute a read operation on a file that has a checksum mismatch."
                ],
                "actualBehavior": "The system throws IOException indicating no data exists for the specified block, followed by a ChecksumException for a file, and finally an IOException indicating that the last block of the file is not sufficiently replicated.",
                "possibleCause": "The issues may be caused by data node failures leading to missing blocks, insufficient replication factors for the file, or corruption in the data leading to checksum mismatches."
            },
            "stackTrace": "java.io.IOException: No data exists for block BP-837130339-172.16.1.88-1477434851452:blk_1073741825_1182\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStream(FsDatasetImpl.java:773)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:400)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:581)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:150)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:102)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:289)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.io.IOException: No data exists for block BP-837130339-172.16.1.88-1477434851452:blk_1073741825_1182\n\tat org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStream(FsDatasetImpl.java:773)\n\tat org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:400)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:581)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:150)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:102)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:289)\n\tat java.lang.Thread.run(Thread.java:745)\n\nException in thread \"Thread-144\" java.lang.RuntimeException: org.apache.hadoop.fs.ChecksumException: Checksum CRC32C not matched for file /tmp/bar.txt at position 0: expected=C893FEDE but computed=69322F90, algorithm=PureJavaCrc32C\n\tat org.apache.hadoop.fs.http.client.BaseTestHttpFSWith$1ReaderRunnable.run(BaseTestHttpFSWith.java:309)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.fs.ChecksumException: Checksum CRC32C not matched for file /tmp/bar.txt at position 0: expected=C893FEDE but computed=69322F90, algorithm=PureJavaCrc32C\n\tat org.apache.hadoop.util.DataChecksum.throwChecksumException(DataChecksum.java:407)\n\tat org.apache.hadoop.util.DataChecksum.verifyChunked(DataChecksum.java:351)\n\tat org.apache.hadoop.util.DataChecksum.verifyChunkedSums(DataChecksum.java:311)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.readNextPacket(BlockReaderRemote.java:216)\n\tat org.apache.hadoop.hdfs.client.impl.BlockReaderRemote.read(BlockReaderRemote.java:144)\n\tat org.apache.hadoop.hdfs.ByteArrayStrategy.readFromBlock(ReaderStrategy.java:119)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:704)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:765)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:814)\n\tat java.io.DataInputStream.read(DataInputStream.java:149)\n\tat org.apache.hadoop.fs.http.client.BaseTestHttpFSWith$1ReaderRunnable.run(BaseTestHttpFSWith.java:302)\n\t... 1 more\n\njava.io.IOException: append: lastBlock=blk_1073741825_1185 of src=/tmp/bar.txt is not sufficiently replicated yet.\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:136)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2423)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.append(NameNodeRpcServer.java:773)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:444)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:467)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:990)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:845)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:788)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1795)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2535)\n\nException in thread \"Thread-143\" java.lang.RuntimeException: java.io.IOException: HTTP status [500], exception [org.apache.hadoop.ipc.RemoteException], message [append: lastBlock=blk_1073741825_1185 of src=/tmp/bar.txt is not sufficiently replicated yet.] \n\tat org.apache.hadoop.fs.http.client.BaseTestHttpFSWith$1.run(BaseTestHttpFSWith.java:283)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: HTTP status [500], exception [org.apache.hadoop.ipc.RemoteException], message [append: lastBlock=blk_1073741825_1185 of src=/tmp/bar.txt is not sufficiently replicated yet.] \n\tat org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:159)\n\tat org.apache.hadoop.fs.http.client.HttpFSFileSystem$HttpFSDataOutputStream.close(HttpFSFileSystem.java:470)\n\tat org.apache.hadoop.fs.http.client.BaseTestHttpFSWith$1.run(BaseTestHttpFSWith.java:279)"
        }
    },
    {
        "filename": "HDFS-6825.json",
        "creation_time": "2014-08-06T01:31:34.000+0000",
        "bug_report": {
            "title": "FileNotFoundException when accessing tlog file in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with HDFS.",
                    "2. Attempt to access the tlog file located at /solr/hierarchy/core_node1/data/tlog/tlog.xyz.",
                    "3. Observe the error message generated."
                ],
                "actualBehavior": "A FileNotFoundException is thrown indicating that the path /solr/hierarchy/core_node1/data/tlog/tlog.xyz cannot be found.",
                "possibleCause": "The specified tlog file may not exist at the given path, or there may be an issue with the HDFS configuration or permissions preventing access to the file."
            },
            "stackTrace": "java.io.FileNotFoundException: Path not found: /solr/hierarchy/core_node1/data/tlog/tlog.xyz\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceConsumed(FSDirectory.java:1807)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitOrCompleteLastBlock(FSNamesystem.java:3975)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.closeFileCommitBlocks(FSNamesystem.java:4178)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:4146)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:662)\n        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolServerSideTranslatorPB.java:270)\n        at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:28073)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1986)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1982)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1554)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1980)"
        }
    },
    {
        "filename": "HDFS-5710.json",
        "creation_time": "2014-01-01T04:06:03.000+0000",
        "bug_report": {
            "title": "NullPointerException in Block Placement Policy during Replication Work Computation",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Upload a file to the HDFS.",
                    "3. Trigger a replication event (e.g., by changing the replication factor or simulating a datanode failure)."
                ],
                "actualBehavior": "The system throws a NullPointerException, causing the replication process to fail.",
                "possibleCause": "It is possible that a required object or variable is not properly initialized before being accessed in the FSDirectory.getFullPathName method."
            },
            "stackTrace": "java.lang.NullPointerException\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.getFullPathName(FSDirectory.java:1871)\n\tat org.apache.hadoop.hdfs.server.namenode.INode.getFullPathName(INode.java:482)\n\tat org.apache.hadoop.hdfs.server.namenode.INodeFile.getName(INodeFile.java:316)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy.chooseTarget(BlockPlacementPolicy.java:118)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlocks(BlockManager.java:1259)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(BlockManager.java:1167)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:3158)\n\tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run(BlockManager.java:3112)\n\tat java.lang.Thread.run(Thread.java:724)"
        }
    },
    {
        "filename": "HDFS-3555.json",
        "creation_time": "2012-06-20T17:36:48.000+0000",
        "bug_report": {
            "title": "SocketTimeoutException during Block Transfer in Hadoop HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster with a data node.",
                    "2. Attempt to read a large block of data from the HDFS.",
                    "3. Monitor the network conditions to simulate a slow or unresponsive connection."
                ],
                "actualBehavior": "The operation fails with a SocketTimeoutException after 480000 milliseconds, indicating that the channel is not ready for writing.",
                "possibleCause": "The issue may be caused by network latency or an overloaded data node that is unable to process the write request in a timely manner."
            },
            "stackTrace": "java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/10.10.120.67:50010 remote=/10.10.120.67:59282]\nat org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:246)\nat org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:159)\nat org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:198)\nat org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:397)\nat org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:493)\nat org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:267)\nat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:163)"
        }
    },
    {
        "filename": "HDFS-10962.json",
        "creation_time": "2016-10-05T04:31:45.000+0000",
        "bug_report": {
            "title": "Mockito Verification Failure in TestRequestHedgingProxyProvider",
            "description": {
                "stepsToReproduce": [
                    "Run the test suite for the Hadoop HDFS module.",
                    "Locate the test case TestRequestHedgingProxyProvider.testHedgingWhenOneFails.",
                    "Observe the output for verification errors related to Mockito."
                ],
                "actualBehavior": "The test fails with a verification error indicating that the method namenodeProtocols.getStats() was expected to be invoked but was not.",
                "possibleCause": "The mock object 'namenodeProtocols' may not have been properly set up or the method getStats() was not called during the test execution."
            },
            "stackTrace": "org.mockito.exceptions.verification.WantedButNotInvoked: \nWanted but not invoked:\nnamenodeProtocols.getStats();\n-> at org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenOneFails(TestRequestHedgingProxyProvider.java:78)\nActually, there were zero interactions with this mock.\n\n\tat org.apache.hadoop.hdfs.server.namenode.ha.TestRequestHedgingProxyProvider.testHedgingWhenOneFails(TestRequestHedgingProxyProvider.java:78)"
        }
    },
    {
        "filename": "HDFS-12363.json",
        "creation_time": "2017-08-28T05:34:21.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockManager during StorageInfo defragmentation",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Trigger the storage defragmentation process in BlockManager.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown, causing the defragmentation process to fail.",
                "possibleCause": "The issue may be caused by uninitialized storage information or a missing reference in the StorageInfoDefragmenter class."
            },
            "stackTrace": "ERROR org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Thread received Runtime exception.\njava.lang.NullPointerException\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.scanAndCompactStorages(BlockManager.java:3897)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:3852)\nat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-7916.json",
        "creation_time": "2015-03-11T10:40:00.000+0000",
        "bug_report": {
            "title": "BPServiceActorActionException when reporting bad block to namenode",
            "description": {
                "stepsToReproduce": [
                    "1. Identify a bad block in the HDFS system.",
                    "2. Attempt to report the bad block using the datanode service.",
                    "3. Observe the logs for any exceptions thrown during the reporting process."
                ],
                "actualBehavior": "The system throws a BPServiceActorActionException indicating failure to report the bad block to the namenode.",
                "possibleCause": "The namenode may be unreachable or there could be a network issue preventing the datanode from reporting the bad block."
            },
            "stackTrace": "org.apache.hadoop.hdfs.server.datanode.BPServiceActorActionException: Failed to report bad block BP-1384821822-10.224.54.68-1422634566395:blk_1079544278_5812006 to namenode:\n        at org.apache.hadoop.hdfs.server.datanode.ReportBadBlockAction.reportTo(ReportBadBlockAction.java:63)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.processQueueMessages(BPServiceActor.java:1020)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:762)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:856)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-9549.json",
        "creation_time": "2015-12-11T16:25:08.000+0000",
        "bug_report": {
            "title": "AssertionError in TestCacheDirectives due to non-empty pending cached list",
            "description": {
                "stepsToReproduce": [
                    "Run the TestCacheDirectives test suite.",
                    "Execute the test method testExceedsCapacity.",
                    "Observe the assertion failure in the checkPendingCachedEmpty method."
                ],
                "actualBehavior": "The test fails with an AssertionError indicating that the pending cached list is not empty when it is expected to be.",
                "possibleCause": "The test may not be properly clearing the pending cached list after operations, leading to an unexpected state during assertions."
            },
            "stackTrace": "java.lang.AssertionError: Pending cached list of 127.0.0.1:54134 is not empty, [{blockId=1073741841, replication=1, mark=true}]\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.checkPendingCachedEmpty(TestCacheDirectives.java:1479)\n\tat org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.testExceedsCapacity(TestCacheDirectives.java:1502)"
        }
    },
    {
        "filename": "HDFS-11164.json",
        "creation_time": "2016-11-22T05:58:03.000+0000",
        "bug_report": {
            "title": "IOException during block replacement in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS cluster with multiple data nodes.",
                    "2. Attempt to replace a block that is currently pinned.",
                    "3. Monitor the logs for any IOException related to block operations."
                ],
                "actualBehavior": "An IOException is thrown indicating that the block cannot be copied because it is pinned, leading to a failure in the block move operation.",
                "possibleCause": "The block being replaced is marked as pinned, preventing it from being moved or copied as part of the replacement process."
            },
            "stackTrace": "java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-1772076264-10.252.146.200-1479792322960:blk_1073741825_1001 received exception java.io.IOException: Got error, status=ERROR, status message Not able to copy block 1073741825 to /127.0.0.1:19826 because it's pinned , copy block BP-1772076264-10.252.146.200-1479792322960:blk_1073741825_1001 from /127.0.0.1:19501, reportedBlock move is failed\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:118)\n\tat org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:417)\n\tat org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:358)\n\tat org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$5(Dispatcher.java:322)\n\tat org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1075)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-5291.json",
        "creation_time": "2013-10-02T23:52:02.000+0000",
        "bug_report": {
            "title": "InterruptedException during EditLogTailer sleep",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop HDFS Namenode with High Availability (HA) enabled.",
                    "Trigger a condition that causes the EditLogTailer to sleep (e.g., during log tailing).",
                    "Interrupt the thread that is responsible for the EditLogTailer."
                ],
                "actualBehavior": "An InterruptedException is thrown, indicating that the sleep was interrupted.",
                "possibleCause": "The thread responsible for the EditLogTailer may be interrupted due to external factors, such as a shutdown signal or resource management issues."
            },
            "stackTrace": "java.lang.InterruptedException: sleep interrupted\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:334)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:279)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:296)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:356)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1463)\n        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:454)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTail"
        }
    },
    {
        "filename": "HDFS-12836.json",
        "creation_time": "2017-11-17T20:26:32.000+0000",
        "bug_report": {
            "title": "Premature EOF Exception in HDFS Edit Log Processing",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS namenode service.",
                    "2. Attempt to load the edit logs from the specified directory.",
                    "3. Monitor the logs for any exceptions or errors during the loading process."
                ],
                "actualBehavior": "The system throws a PrematureEOFException indicating a premature end-of-file at transaction ID 86, followed by an EditLogInputException for transaction ID 87.",
                "possibleCause": "The edit log file may be corrupted or incomplete, leading to mismatched transaction IDs during the replay process."
            },
            "stackTrace": "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$PrematureEOFException: got premature end-of-file at txid 86; expected file to go up to 85\n        at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:197)\n        at org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)\n        at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:189)\n        at org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:205)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:882)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:863)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:293)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:427)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:380)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:397)\n        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:393)\n\norg.apache.hadoop.hdfs.server.namenode.EditLogInputException: Error replaying edit log at offset 1048576.  Expected transaction ID was 87\nRecent opcode offsets: 1048576\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:218)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:158)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:882)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:863)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:293)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:427)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:380)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:397)\n        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:393)"
        }
    },
    {
        "filename": "HDFS-8113.json",
        "creation_time": "2015-04-09T11:29:31.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlockInfo Constructor",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Trigger a block report from a DataNode.",
                    "3. Monitor the NameNode logs for exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown during the processing of the block report, causing disruptions in block management.",
                "possibleCause": "The BlockInfo constructor is likely receiving a null reference for one of its parameters, which leads to the NullPointerException."
            },
            "stackTrace": "org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo.(BlockInfo.java:80)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockToMarkCorrupt.(BlockManager.java:1696)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.checkReplicaCorrupt(BlockManager.java:2185)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReportedBlock(BlockManager.java:2047)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.reportDiff(BlockManager.java:1950)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1823)\nat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1750)\nat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1069)\nat org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:152)\nat org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:26382)\nat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)\nat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\nat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\nat java.security.AccessController.doPrivileged(Native Method)\nat javax.security.auth.Subject.doAs(Subject.java:415)\nat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1623)\nat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)"
        }
    },
    {
        "filename": "HDFS-10512.json",
        "creation_time": "2016-06-09T14:34:04.000+0000",
        "bug_report": {
            "title": "NullPointerException in DataNode during Block Reporting",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Trigger a volume scan on the DataNode.",
                    "3. Monitor the logs for any exceptions."
                ],
                "actualBehavior": "A NullPointerException is thrown in the DataNode when attempting to report bad blocks.",
                "possibleCause": "It is possible that a required object or variable is not properly initialized before being accessed in the reportBadBlocks method."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.reportBadBlocks(DataNode.java:1018)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner$ScanResultHandler.handle(VolumeScanner.java:287)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.scanBlock(VolumeScanner.java:443)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.runLoop(VolumeScanner.java:547)\n        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)"
        }
    },
    {
        "filename": "HDFS-10729.json",
        "creation_time": "2016-08-08T02:36:05.000+0000",
        "bug_report": {
            "title": "NullPointerException during Edit Log Tailer processing due to Max Directory Items Exceeded",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS NameNode with a directory containing more than 1,048,576 items.",
                    "2. Trigger an edit log operation that attempts to add more items to the directory.",
                    "3. Observe the logs for any exceptions thrown during the operation."
                ],
                "actualBehavior": "A NullPointerException is thrown while processing the edit log, indicating that the directory item limit has been exceeded.",
                "possibleCause": "The issue may be caused by the system attempting to access file encryption information for a directory that has exceeded its maximum item limit, leading to a NullPointerException."
            },
            "stackTrace": "java.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.getFileEncryptionInfo(FSDirectory.java:2914)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.createFileStatus(FSDirectory.java:2469)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:375)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:230)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:139)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:829)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:810)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:232)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:331)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:284)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:301)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:360)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1651)\n        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:410)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:297)\n\norg.apache.hadoop.hdfs.protocol.FSLimitException$MaxDirectoryItemsExceededException: The directory item limit of [path] is exceeded: limit=1048576 items=1049332\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxDirItems(FSDirectory.java:2060)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addChild(FSDirectory.java:2112)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:2081)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1900)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedAddFile(FSDirectory.java:368)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:365)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:230)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:139)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:829)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:810)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:232)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:188)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$1.run(EditLogTailer.java:182)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)\n        at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:445)\n        at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:426)\n        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.catchupDuringFailover(EditLogTailer.java:182)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1205)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1762)\n        at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)\n        at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)\n        at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1635)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1351)\n        at org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)\n        at org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4460)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)"
        }
    },
    {
        "filename": "HDFS-13040.json",
        "creation_time": "2018-01-19T19:47:02.000+0000",
        "bug_report": {
            "title": "Edit Log Failover Error in Hadoop NameNode",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with multiple NameNode instances.",
                    "2. Trigger a failover scenario by simulating a failure in the active NameNode.",
                    "3. Attempt to read the edit logs during the failover process."
                ],
                "actualBehavior": "An IOException occurs indicating that all remaining edit log streams are shorter than the current one, leading to potential metadata loss.",
                "possibleCause": "The issue may be caused by a mismatch in transaction IDs between the edit logs of the NameNodes, possibly due to a failure in log synchronization or a network issue."
            },
            "stackTrace": "org.apache.hadoop.ipc.RemoteException(java.io.IOException): We encountered an error reading https://nn2.example.com:8481/getJournal?jid=ns1&segmentTxId=8662&storageInfo=-60%3A353531113%3A0%3Acluster3, https://nn1.example.com:8481/getJournal?jid=ns1&segmentTxId=8662&storageInfo=-60%3A353531113%3A0%3Acluster3.  During automatic edit log failover, we noticed that all of the remaining edit log streams are shorter than the current one!  The best remaining edit log ends at transaction 8683, but we thought we could read up to transaction 8684.  If you continue, metadata will be lost forever! at org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:213) at org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.readOp(NameNodeRpcServer.java:1701) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getEditsFromTxid(NameNodeRpcServer.java:1763) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getEditsFromTxid(AuthorizationProviderProxyClientProtocol.java:1011) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getEditsFromTxid(ClientNamenodeProtocolServerSideTranslatorPB.java:1490) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2216) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2212) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2210)"
        }
    },
    {
        "filename": "HDFS-3374.json",
        "creation_time": "2012-05-04T22:08:19.000+0000",
        "bug_report": {
            "title": "No Edit Streams Accessible Exception in HDFS",
            "description": {
                "stepsToReproduce": [
                    "Start the HDFS namenode service.",
                    "Attempt to perform an operation that requires logging updates to the edit log.",
                    "Observe the system behavior when no edit streams are available."
                ],
                "actualBehavior": "The system throws a 'No edit streams are accessible' exception and fails to log updates.",
                "possibleCause": "The namenode may not have access to the necessary edit log storage directories, or they may not be properly configured."
            },
            "stackTrace": "java.lang.Exception: No edit streams are accessible\n    at org.apache.hadoop.hdfs.server.namenode.FSEditLog.fatalExit(FSEditLog.java:388)\n    at org.apache.hadoop.hdfs.server.namenode.FSEditLog.exitIfNoStreams(FSEditLog.java:407)\n    at org.apache.hadoop.hdfs.server.namenode.FSEditLog.removeEditsAndStorageDir(FSEditLog.java:432)\n    at org.apache.hadoop.hdfs.server.namenode.FSEditLog.removeEditsStreamsAndStorageDirs(FSEditLog.java:468)\n    at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync(FSEditLog.java:1028)\n    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.logUpdateMasterKey(FSNamesystem.java:5641)\n    at org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.logUpdateMasterKey(DelegationTokenSecretManager.java:286)\n    at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.updateCurrentKey(AbstractDelegationTokenSecretManager.java:150)\n    at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.rollMasterKey(AbstractDelegationTokenSecretManager.java:174)\n    at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:385)\n    at java.lang.Thread.run(Thread.java:662)"
        }
    },
    {
        "filename": "HDFS-2359.json",
        "creation_time": "2011-09-23T00:20:53.000+0000",
        "bug_report": {
            "title": "IOException and NullPointerException in DataNode Operations",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS DataNode service.",
                    "2. Attempt to delete blocks from the DataNode.",
                    "3. Monitor the logs for any exceptions thrown during the operation."
                ],
                "actualBehavior": "An IOException is thrown indicating an error in deleting blocks, followed by a NullPointerException during the log file handling.",
                "possibleCause": "The IOException may be caused by issues with the underlying storage or permissions, while the NullPointerException could indicate that a required object is not initialized properly in the DataBlockScanner."
            },
            "stackTrace": "java.io.IOException: Error in deleting blocks.\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset.invalidate(FSDataset.java:1820)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.processCommand(DataNode.java:1074)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.processCommand(DataNode.java:1036)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:891)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1419)\n        at java.lang.Thread.run(Thread.java:619)\n\njava.lang.NullPointerException\n        at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner$LogFileHandler.appendLine(DataBlockScanner.java:788)\n        at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.updateScanStatusInternal(DataBlockScanner.java:365)\n        at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifiedByClient(DataBlockScanner.java:308)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:205)\n        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:99)\n        at java.lang.Thread.run(Thread.java:619)"
        }
    },
    {
        "filename": "HDFS-10986.json",
        "creation_time": "2016-10-08T00:50:36.000+0000",
        "bug_report": {
            "title": "Connection Refused Error in DFSAdmin Tool",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Attempt to run the DFSAdmin tool to check the status of the HDFS.",
                    "3. Observe the output for any connection errors."
                ],
                "actualBehavior": "The DFSAdmin tool fails to connect to the HDFS service and throws a 'Connection refused' error.",
                "possibleCause": "The HDFS service may not be running, or it may be configured to listen on a different port than the one the DFSAdmin tool is trying to connect to."
            },
            "stackTrace": "java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat org.apache.hadoop.hdfs.tools.DFSAdmin.run(DFSAdmin.java:2073)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.hdfs.tools.DFSAdmin.main(DFSAdmin.java:2225)"
        }
    },
    {
        "filename": "HDFS-6455.json",
        "creation_time": "2014-05-28T18:01:15.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException due to incorrectly formatted NFS export line",
            "description": {
                "stepsToReproduce": [
                    "1. Configure NFS exports with the line 'host1 ro:host2 rw'.",
                    "2. Start the NFS service.",
                    "3. Observe the application logs for any exceptions."
                ],
                "actualBehavior": "The application throws an IllegalArgumentException indicating that the line is incorrectly formatted.",
                "possibleCause": "The format of the NFS export line may not conform to the expected syntax required by the NfsExports class."
            },
            "stackTrace": "Exception in thread \"main\" java.lang.IllegalArgumentException: Incorrectly formatted line 'host1 ro:host2 rw'\n\tat org.apache.hadoop.nfs.NfsExports.getMatch(NfsExports.java:356)\n\tat org.apache.hadoop.nfs.NfsExports.<init>(NfsExports.java:151)\n\tat org.apache.hadoop.nfs.NfsExports.getInstance(NfsExports.java:54)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.<init>(RpcProgramNfs3.java:176)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.<init>(Nfs3.java:43)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.main(Nfs3.java:59)\n\nException in thread \"main\" java.lang.IllegalArgumentException: Incorrectly formatted line 'host1 ro:host2 rw'\n\tat org.apache.hadoop.nfs.NfsExports.getMatch(NfsExports.java:356)\n\tat org.apache.hadoop.nfs.NfsExports.<init>(NfsExports.java:151)\n\tat org.apache.hadoop.nfs.NfsExports.getInstance(NfsExports.java:54)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.<init>(RpcProgramNfs3.java:176)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.<init>(Nfs3.java:43)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.main(Nfs3.java:59)"
        }
    },
    {
        "filename": "HDFS-2882.json",
        "creation_time": "2012-02-02T18:11:20.000+0000",
        "bug_report": {
            "title": "IOException: Mkdirs failed to create directory in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS service.",
                    "2. Attempt to write data to the HDFS using a data node.",
                    "3. Monitor the logs for any IOException related to directory creation."
                ],
                "actualBehavior": "The system throws an IOException indicating that it failed to create the specified directory.",
                "possibleCause": "The directory path may not have the necessary permissions, or the parent directory may not exist."
            },
            "stackTrace": "java.io.IOException: Mkdirs failed to create /data/1/scratch/todd/styx-datadir/current/BP-448349972-172.29.5.192-1323816762969/tmp\n        at org.apache.hadoop.hdfs.server.datanode.FSDataset$BlockPoolSlice.<init>(FSDataset.java:335)"
        }
    },
    {
        "filename": "HDFS-5185.json",
        "creation_time": "2013-09-11T14:38:23.000+0000",
        "bug_report": {
            "title": "IOException: Mkdirs failed to create directory in HDFS DataNode",
            "description": {
                "stepsToReproduce": [
                    "1. Start the HDFS DataNode service.",
                    "2. Attempt to initialize a new block pool.",
                    "3. Monitor the logs for any IOException related to directory creation."
                ],
                "actualBehavior": "The DataNode fails to start due to an IOException indicating that it could not create the specified directory.",
                "possibleCause": "The directory path may not have the necessary permissions, or the parent directory may not exist."
            },
            "stackTrace": "java.io.IOException: Mkdirs failed to create /opt/nish/data/current/BP-123456-1234567/tmp\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.<init>(BlockPoolSlice.java:105)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.addBlockPool(FsVolumeImpl.java:216)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.addBlockPool(FsVolumeList.java:155)\n        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addBlockPool(FsDatasetImpl.java:1593)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:834)\n        at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:311)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:217)\n        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:660)\n        at java.lang.Thread.run(Thread.java:662)"
        }
    },
    {
        "filename": "HDFS-13164.json",
        "creation_time": "2018-02-17T00:40:21.000+0000",
        "bug_report": {
            "title": "DiskSpace Quota Exceeded Exception in HDFS",
            "description": {
                "stepsToReproduce": [
                    "1. Set a disk space quota of 2,000,000 bytes (approximately 1.91 MB) on the directory /DIR.",
                    "2. Attempt to write data to the directory /tmp/logs/systest/logs that exceeds the quota limit.",
                    "3. Observe the system's response to the write operation."
                ],
                "actualBehavior": "The system throws a DSQuotaExceededException indicating that the disk space quota has been exceeded.",
                "possibleCause": "The application is attempting to write more data than the allowed quota, leading to the exception being thrown."
            },
            "stackTrace": "org.apache.hadoop.hdfs.protocol.DSQuotaExceededException: The DiskSpace quota of /DIR is exceeded: quota = 2000000 B = 1.91 MB but diskspace consumed = 404139552 B = 385.42 MB\n        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyDiskspaceQuota(DirectoryWithQuotaFeature.java:149)\n        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:159)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:2124)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1991)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1966)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addBlock(FSDirectory.java:463)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.saveAllocatedBlock(FSNamesystem.java:3896)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3484)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:686)\n        at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:217)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:506)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2226)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2222)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2220)\n\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.DSQuotaExceededException): The DiskSpace quota of /tmp/logs/systest/logs is exceeded: quota = 2000000 B = 1.91 MB but diskspace consumed = 404139552 B = 385.42 MB\n        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyDiskspaceQuota(DirectoryWithQuotaFeature.java:149)\n        at org.apache.hadoop.hdfs.server.namenode.DirectoryWithQuotaFeature.verifyQuota(DirectoryWithQuotaFeature.java:159)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota(FSDirectory.java:2124)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1991)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1966)\n        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addBlock(FSDirectory.java:463)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.saveAllocatedBlock(FSNamesystem.java:3896)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3484)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:686)\n        at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.addBlock(AuthorizationProviderProxyClientProtocol.java:217)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:506)\n        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2226)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2222)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2220)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1504)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1441)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy82.addBlock(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:423)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(sun.reflect.NativeMethodAccessorImpl.java:62)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:258)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:104)\n        at com.sun.proxy.$Proxy83.addBlock(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1830)"
        }
    },
    {
        "filename": "HDFS-11508.json",
        "creation_time": "2017-03-07T04:55:50.000+0000",
        "bug_report": {
            "title": "ChannelException: Failed to bind to address due to Address already in use",
            "description": {
                "stepsToReproduce": [
                    "Start the NFS service on the server.",
                    "Attempt to bind the service to the address 0.0.0.0:4242.",
                    "Observe the logs for any binding errors."
                ],
                "actualBehavior": "The service fails to start with a ChannelException indicating that the address is already in use.",
                "possibleCause": "Another process may already be using the port 4242, preventing the NFS service from binding to it."
            },
            "stackTrace": "org.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:4242\n\tat org.jboss.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)\n\tat org.apache.hadoop.oncrpc.SimpleTcpServer.run(SimpleTcpServer.java:86)\n\tat org.apache.hadoop.mount.MountdBase.startTCPServer(MountdBase.java:83)\n\tat org.apache.hadoop.mount.MountdBase.start(MountdBase.java:98)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.startServiceInternal(Nfs3.java:56)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.Nfs3.startService(Nfs3.java:69)\n\tat org.apache.hadoop.hdfs.nfs.nfs3.PrivilegedNfsGatewayStarter.start(PrivilegedNfsGatewayStarter.java:71)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.commons.daemon.support.DaemonLoader.start(DaemonLoader.java:243)\nCaused by: java.net.BindException: Address already in use\n\tat sun.nio.ch.Net.bind0(Native Method)\n\tat sun.nio.ch.Net.bind(Net.java:433)\n\tat sun.nio.ch.Net.bind(Net.java:425)\n\tat sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)\n\tat sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)\n\tat org.jboss.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)\n\tat org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:366)\n\tat org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:290)\n\tat org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "HDFS-2991.json",
        "creation_time": "2012-02-23T02:06:51.000+0000",
        "bug_report": {
            "title": "ClassCastException during Edit Log Replay in HDFS",
            "description": {
                "stepsToReproduce": [
                    "Start the HDFS namenode service.",
                    "Attempt to replay the edit log from a specific offset.",
                    "Observe the logs for any exceptions thrown during the process."
                ],
                "actualBehavior": "An IOException is thrown indicating an error replaying the edit log, specifically a ClassCastException occurs when trying to cast INodeFile to INodeFileUnderConstruction.",
                "possibleCause": "The edit log may contain an entry that is not compatible with the expected type, possibly due to a bug in the handling of file states during the edit log writing process."
            },
            "stackTrace": "java.io.IOException: Error replaying edit log at offset 1354251\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:418)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:93)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:79)\nCaused by: java.lang.ClassCastException: org.apache.hadoop.hdfs.server.namenode.INodeFile cannot be cast to org.apache.hadoop.hdfs.server.namenode.INodeFileUnderConstruction\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:213)"
        }
    },
    {
        "filename": "HDFS-4404.json",
        "creation_time": "2013-01-15T01:43:17.000+0000",
        "bug_report": {
            "title": "SocketTimeoutException during HDFS file creation",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Hadoop cluster with a Namenode running on vm2:8020.",
                    "2. Attempt to create a file in HDFS using the DistributedFileSystem API.",
                    "3. Ensure that the network connection to the Namenode is unstable or slow."
                ],
                "actualBehavior": "The operation fails with a SocketTimeoutException after 10000 milliseconds, indicating that the connection to the Namenode could not be established in time.",
                "possibleCause": "The issue may be caused by network latency or an unresponsive Namenode, leading to a timeout when trying to establish a connection."
            },
            "stackTrace": "java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]\n at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:213)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:524)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)\n at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:474)\n at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:568)\n at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:217)\n at org.apache.hadoop.ipc.Client.getConnection(Client.java:1286)\n at org.apache.hadoop.ipc.Client.call(Client.java:1156)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)\n at $Proxy9.create(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n at java.lang.reflect.Method.invoke(Method.java:597)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:84)\n at $Proxy10.create(Unknown Source)\n at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)\n at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)\n at test.TestLease.main(TestLease.java:45)\n\njava.net.SocketTimeoutException: Call From szxy1x001833091/172.0.0.13 to vm2:8020 failed on socket timeout exception: java.net.SocketTimeoutException: 10000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/160.161.0.155:8020]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout\n at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:743)\n at org.apache.hadoop.ipc.Client.call(Client.java:1180)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:184)\n at $Proxy9.create(Unknown Source)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:187)\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n at java.lang.reflect.Method.invoke(Method.java:597)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:165)\n at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:84)\n at $Proxy10.create(Unknown Source)\n at org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:1261)\n at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1280)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1128)\n at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1086)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:232)\n at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:75)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:806)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:715)\n at test.TestLease.main(TestLease.java:45)"
        }
    },
    {
        "filename": "HDFS-8276.json",
        "creation_time": "2015-04-28T10:11:35.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException due to zero interval for dfs.namenode.lazypersist.file.scrub.interval.sec",
            "description": {
                "stepsToReproduce": [
                    "1. Configure the Hadoop HDFS settings.",
                    "2. Set the property dfs.namenode.lazypersist.file.scrub.interval.sec to 0.",
                    "3. Start the Hadoop NameNode service."
                ],
                "actualBehavior": "The NameNode fails to start and throws an IllegalArgumentException indicating that the interval must be non-zero.",
                "possibleCause": "The configuration for dfs.namenode.lazypersist.file.scrub.interval.sec is set to an invalid value (zero), which is not allowed."
            },
            "stackTrace": "java.lang.IllegalArgumentException: dfs.namenode.lazypersist.file.scrub.interval.sec must be non-zero.\nat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:828)"
        }
    },
    {
        "filename": "HDFS-12369.json",
        "creation_time": "2017-08-28T22:56:02.000+0000",
        "bug_report": {
            "title": "FileNotFoundException when loading FSImage in Hadoop",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop NameNode service.",
                    "Ensure that the specified file path '/home/Events/CancellationSurvey_MySQL/2015/12/31/.part-00000.9nlJ3M' does not exist.",
                    "Monitor the logs for any exceptions during the initialization of the NameNode."
                ],
                "actualBehavior": "The NameNode fails to start and throws a FileNotFoundException indicating that the specified file does not exist.",
                "possibleCause": "The file may have been deleted or not created properly during a previous operation, leading to the NameNode being unable to load the necessary FSImage."
            },
            "stackTrace": "java.io.FileNotFoundException: File does not exist: /home/Events/CancellationSurvey_MySQL/2015/12/31/.part-00000.9nlJ3M\n        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:66)\n        at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.applyEditLogOp(FSEditLogLoader.java:429)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:232)\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:141)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:897)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:750)\n        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:318)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1125)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:789)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:614)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:676)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:844)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:823)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1547)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1615)"
        }
    },
    {
        "filename": "HDFS-6462.json",
        "creation_time": "2014-05-29T00:19:03.000+0000",
        "bug_report": {
            "title": "SaslException: GSS initiate failed due to missing Kerberos TGT",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to connect to the Hadoop cluster using Kerberos authentication.",
                    "2. Ensure that the Kerberos ticket granting ticket (TGT) is not available or has expired.",
                    "3. Execute a command that requires access to the Hadoop file system."
                ],
                "actualBehavior": "The connection fails with a SaslException indicating that no valid credentials were provided.",
                "possibleCause": "The user may not have a valid Kerberos TGT, which is required for authentication."
            },
            "stackTrace": "javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1414)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1363)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy14.getFsStats(Unknown Source)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:601)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:190)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy14.getFsStats(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getStats(ClientNamenodeProtocolTranslatorPB.java:554)\n        at org.apache.hadoop.hdfs.DFSClient.getDiskStatus(DFSClient.java:2165)\n        at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.fsstat(RpcProgramNfs3.java:1659)\n        at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.handleInternal(RpcProgramNfs3.java:1961)\n        at org.apache.hadoop.oncrpc.RpcProgram.messageReceived(RpcProgram.java:162)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)\n        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:281)\n        at org.apache.hadoop.oncrpc.RpcUtil$RpcMessageParserStage.messageReceived(RpcUtil.java:132)\n        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)\n        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:555)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)\n        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)\n        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)\n        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:677)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)\n        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:640)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)\n        at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1462)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1381)"
        }
    },
    {
        "filename": "HDFS-5425.json",
        "creation_time": "2013-10-25T06:53:28.000+0000",
        "bug_report": {
            "title": "IllegalStateException during NameNode initialization",
            "description": {
                "stepsToReproduce": [
                    "Start the Hadoop NameNode service.",
                    "Attempt to load the filesystem image from disk.",
                    "Observe the logs for any exceptions thrown during the initialization process."
                ],
                "actualBehavior": "The NameNode fails to initialize and throws an IllegalStateException.",
                "possibleCause": "The issue may be related to an inconsistent state in the filesystem image or a problem with the snapshot handling in the INodeDirectory."
            },
            "stackTrace": "java.lang.IllegalStateException\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:133)\n\tat org.apache.hadoop.hdfs.server.namenode.snapshot.INodeDirectoryWithSnapshot$ChildrenDiff.replace(INodeDirectoryWithSnapshot.java:82)\n\tat org.apache.hadoop.hdfs.server.namenode.snapshot.INodeDirectoryWithSnapshot$ChildrenDiff.access$700(INodeDirectoryWithSnapshot.java:62)\n\tat org.apache.hadoop.hdfs.server.namenode.snapshot.INodeDirectoryWithSnapshot$DirectoryDiffList.replaceChild(INodeDirectoryWithSnapshot.java:397)\n\tat org.apache.hadoop.hdfs.server.namenode.snapshot.INodeDirectoryWithSnapshot$DirectoryDiffList.access$900(INodeDirectoryWithSnapshot.java:376)\n\tat org.apache.hadoop.hdfs.server.namenode.snapshot.INodeDirectoryWithSnapshot.replaceChild(INodeDirectoryWithSnapshot.java:598)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedReplaceINodeFile(FSDirectory.java:1548)\n\tat org.apache.hadoop.hdfs.server.namenode.FSDirectory.replaceINodeFile(FSDirectory.java:1537)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadFilesUnderConstruction(FSImageFormat.java:855)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.load(FSImageFormat.java:350)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:910)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:899)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImageFormat.java:751)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:720)\n\tat org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:266)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:784)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:563)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:422)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:472)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:670)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:655)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1245)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1311)"
        }
    },
    {
        "filename": "HDFS-13145.json",
        "creation_time": "2018-02-13T19:22:56.000+0000",
        "bug_report": {
            "title": "IllegalStateException when transitioning NameNode to active state",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop cluster with a NameNode in standby state.",
                    "2. Attempt to transition the NameNode to active state while there is an ongoing read stream.",
                    "3. Observe the logs for any exceptions thrown during the transition."
                ],
                "actualBehavior": "An IllegalStateException is thrown indicating that writing cannot start due to an active read stream.",
                "possibleCause": "The NameNode is trying to start writing to the edit log while a read stream is still open, which violates the expected state management of the NameNode."
            },
            "stackTrace": "java.lang.IllegalStateException: Cannot start writing at txid 24312595802 when there is a stream available for read: ......\n        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.openForWrite(FSEditLog.java:329)\n        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1196)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1839)\n        at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)\n        at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:64)\n        at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)\n        at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1707)\n        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1622)\n        at org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)\n        at org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4460)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:851)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:794)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2490)"
        }
    },
    {
        "filename": "HDFS-8807.json",
        "creation_time": "2015-07-22T20:45:55.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException due to invalid URI scheme in Hadoop DataNode",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop DataNode service with an improperly formatted storage location.",
                    "2. Ensure the storage location is set to 'file://tmp/hadoop-aengineer/disk1/dfs/data'.",
                    "3. Observe the logs for any exceptions thrown during the initialization of the DataNode."
                ],
                "actualBehavior": "The DataNode fails to start and throws an IllegalArgumentException indicating an illegal character in the scheme name.",
                "possibleCause": "The storage location URI is incorrectly formatted, specifically the scheme 'file://' is not recognized due to the presence of an illegal character at index 0."
            },
            "stackTrace": "java.lang.IllegalArgumentException: java.net.URISyntaxException: Illegal character in scheme name at index 0:  file://tmp/hadoop-aengineer/disk1/dfs/data\n        at org.apache.hadoop.fs.Path.initialize(Path.java:204)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:170)\n        at org.apache.hadoop.hdfs.server.datanode.StorageLocation.parse(StorageLocation.java:97)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.getStorageLocations(DataNode.java:2314)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2298)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2349)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2529)\n        at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2553)\nCaused by: java.net.URISyntaxException: Illegal character in scheme name at index 0:  file://tmp/hadoop-aengineer/disk1/dfs/data\n        at java.net.URI$Parser.fail(URI.java:2829)\n        at java.net.URI$Parser.checkChars(URI.java:3002)\n        at java.net.URI$Parser.checkChar(URI.java:3012)\n        at java.net.URI$Parser.parse(URI.java:3028)\n        at java.net.URI.<init>(URI.java:753)\n        at org.apache.hadoop.fs.Path.initialize(Path.java:201)"
        }
    },
    {
        "filename": "HDFS-3436.json",
        "creation_time": "2012-05-17T10:36:31.000+0000",
        "bug_report": {
            "title": "IOException and EOFException during HDFS Data Streaming",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Hadoop HDFS cluster.",
                    "2. Attempt to write a large file to HDFS using the DataStreamer.",
                    "3. Monitor the logs for any exceptions during the write process."
                ],
                "actualBehavior": "The write operation fails with IOException and multiple EOFExceptions, indicating issues with data streaming and block replication.",
                "possibleCause": "The issue may be related to network instability or misconfiguration of the DataNode, leading to premature EOF and incorrect block states."
            },
            "stackTrace": "java.io.IOException: Bad connect ack with firstBadLink as *******:50010\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1053)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:943)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.io.EOFException: Premature EOF: no length prefix available\n\tat org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:162)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:866)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:843)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:934)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.io.EOFException: Premature EOF: no length prefix available\n\tat org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:162)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:866)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:843)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:934)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.io.EOFException: Premature EOF: no length prefix available\n\tat org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:162)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:866)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:843)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:934)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:461)\n\njava.io.IOException: BP-2001850558-xx.xx.xx.xx-1337249347060:blk_-8165642083860293107_1002 is neither a RBW nor a Finalized, r=ReplicaBeingWritten, blk_-8165642083860293107_1003, RBW\n\tat org.apache.hadoop.hdfs.server.datanode.DataNode.transferReplicaForPipelineRecovery(DataNode.java:2038)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.transferBlock(DataXceiver.java:525)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opTransferBlock(Receiver.java:114)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:78)\n\tat org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:189)\n\tat java.lang.Thread.run(Unknown Source)"
        }
    }
]