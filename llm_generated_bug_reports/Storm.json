[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus.setLogConfig",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Attempt to set the log configuration using the Nimbus interface.",
                    "3. Observe the logs for any exceptions thrown."
                ],
                "actualBehavior": "A NullPointerException is thrown when attempting to set the log configuration.",
                "possibleCause": "It is possible that a required configuration object is not being initialized before it is accessed in the setLogConfig method."
            },
            "stackTrace": "java.lang.NullPointerException: null\n        at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]"
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus.getComponentPageInfo",
            "description": {
                "stepsToReproduce": [
                    "1. Deploy a topology in Apache Storm.",
                    "2. Attempt to access the component page information for the deployed topology.",
                    "3. Observe the response from the Nimbus server."
                ],
                "actualBehavior": "An Internal error occurs while processing the request, resulting in a NullPointerException.",
                "possibleCause": "The issue may be caused by missing or improperly initialized resources for the components in the topology."
            },
            "stackTrace": "org.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)\n\tat org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)\n\tat org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)\n\njava.lang.RuntimeException: java.lang.NullPointerException\n\tat org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.NullPointerException\n\tat org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "bug_report": {
            "title": "AuthorizationException during Blob Download in Apache Storm",
            "description": {
                "stepsToReproduce": [
                    "1. Deploy a Storm topology that requires access to external blobs.",
                    "2. Ensure that the user running the Storm supervisor does not have READ access to the required blob.",
                    "3. Start the Storm supervisor and observe the logs."
                ],
                "actualBehavior": "The process halts with an AuthorizationException indicating that the user does not have READ access to the specified blob.",
                "possibleCause": "The user permissions for accessing the required blob are not correctly configured, leading to an authorization failure."
            },
            "stackTrace": "org.apache.storm.generated.AuthorizationException: null\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n\njava.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]\n\tat org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\nCaused by: org.apache.storm.generated.AuthorizationException\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]"
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "bug_report": {
            "title": "KeyNotFoundException during Blob Download in Apache Storm",
            "description": {
                "stepsToReproduce": [
                    "Deploy a Storm application with blob resources.",
                    "Start the Storm supervisor.",
                    "Attempt to download the blob resources from Nimbus."
                ],
                "actualBehavior": "The application throws a KeyNotFoundException indicating that the requested blob could not be found.",
                "possibleCause": "The blob may not have been uploaded correctly to Nimbus, or the path to the blob may be incorrect."
            },
            "stackTrace": "org.apache.storm.generated.KeyNotFoundException: null\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\n\njava.io.FileNotFoundException: File '/opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785/stormconf.ser' does not exist\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:292) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1815) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfGivenPath(ConfigUtils.java:264) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfImpl(ConfigUtils.java:376) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConf(ConfigUtils.java:370) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:226) ~[storm-core-1.1.2-mt001.jar:?]\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:213) ~[storm-core-1.1.2-mt001.jar:?]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]"
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "bug_report": {
            "title": "PacemakerConnectionException and NullPointerException in Nimbus Cleanup Process",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster with multiple topologies running.",
                    "2. Trigger a cleanup process in Nimbus, possibly by stopping one of the topologies.",
                    "3. Monitor the logs for any exceptions during the cleanup process."
                ],
                "actualBehavior": "The system throws a PacemakerConnectionException indicating a timeout while waiting for the channel to be ready, followed by a NullPointerException during the Nimbus cleanup process.",
                "possibleCause": "The PacemakerClient may not be properly initialized or connected, leading to timeouts. Additionally, there may be a missing or null reference in the PaceMakerStateStorage class when attempting to retrieve worker heartbeat children."
            },
            "stackTrace": "org.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2508) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "bug_report": {
            "title": "Queue Full Exception in Storm Executor",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm application with a spout that generates a high volume of messages.",
                    "2. Monitor the system for message processing and queue utilization.",
                    "3. Observe the logs for any exceptions or errors related to queue management."
                ],
                "actualBehavior": "The application throws a java.lang.IllegalStateException indicating that the queue is full, leading to a RuntimeException in the Executor.",
                "possibleCause": "The spout is emitting messages at a rate that exceeds the processing capacity of the downstream components, causing the queue to fill up."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.IllegalStateException: Queue full\n\tat org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\nCaused by: java.lang.IllegalStateException: Queue full\n\tat java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]\n\tat org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "bug_report": {
            "title": "ClassCastException when processing component page info in Storm",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Submit a topology that generates statistics.",
                    "3. Attempt to retrieve component page information for the submitted topology."
                ],
                "actualBehavior": "A ClassCastException is thrown indicating that a Long cannot be cast to a Map.",
                "possibleCause": "The code is likely expecting a Map structure for certain statistics but is receiving a Long value instead, which suggests a mismatch in the expected data types."
            },
            "stackTrace": "java.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map\n        at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)\n        at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)\n        at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)\n        at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)\n        at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)\n        at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:744)"
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException: No matching method found for stateChanged",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster with Zookeeper integration.",
                    "2. Trigger a state change event in the cluster.",
                    "3. Observe the logs for any exceptions thrown."
                ],
                "actualBehavior": "An IllegalArgumentException is thrown indicating that no matching method 'stateChanged' was found for the specified class.",
                "possibleCause": "The method 'stateChanged' may not be defined in the reified class or there may be a mismatch in the expected method signature."
            },
            "stackTrace": "java.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "bug_report": {
            "title": "KeyNotFoundException in LocalFsBlobStore when accessing topology blobs",
            "description": {
                "stepsToReproduce": [
                    "Deploy a topology with the name 'production-topology-2'.",
                    "Attempt to retrieve the blob metadata for 'stormcode.ser' and 'stormconf.ser'.",
                    "Monitor the logs for any exceptions thrown during the retrieval process."
                ],
                "actualBehavior": "The system throws a KeyNotFoundException indicating that the blobs 'stormcode.ser' and 'stormconf.ser' cannot be found.",
                "possibleCause": "The blobs may not have been properly stored in the local file system, or there may be a mismatch in the expected blob names."
            },
            "stackTrace": "KeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)\n        ...\n        at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)\n        at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)\n        ...\n        at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3708)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\nKeyNotFoundException(msg:production-topology-2-1468745167-stormconf.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:239)\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:271)\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:300)\n        ...\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n        at org.apache.storm.daemon.nimbus$read_storm_conf_as_nimbus.invoke(nimbus.clj:548)\n        at org.apache.storm.daemon.nimbus$read_topology_details.invoke(nimbus.clj:555)\n        at org.apache.storm.daemon.nimbus$mk_assignments$iter__9205__9209$fn__9210.invoke(nimbus.clj:912)\n        ...\n        at org.apache.storm.daemon.nimbus$mk_assignments.doInvoke(nimbus.clj:911)\n        at clojure.lang.RestFn.invoke(RestFn.java:410)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781$fn__9782.invoke(nimbus.clj:2216)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770.invoke(nimbus.clj:2215)\n        at org.apache.storm.timer$schedule_recurring$this__1732.invoke(timer.clj:105)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:50)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n\njava.lang.RuntimeException: (\"Error when processing an event\")\n        at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n        at clojure.lang.RestFn.invoke(RestFn.java:423)\n        at org.apache.storm.daemon.nimbus$nimbus_data$fn__8727.invoke(nimbus.clj:205)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:71)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n        at clojure.lang.AFn.run(AFn.java:22)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException during JmxStormReporter initialization",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm worker process.",
                    "2. Configure the JmxStormReporter with the specified parameters.",
                    "3. Observe the logs for any errors during initialization."
                ],
                "actualBehavior": "The worker fails to initialize and throws an IllegalArgumentException indicating it doesn't know how to convert a specific configuration to String.",
                "possibleCause": "The configuration provided to JmxStormReporter may contain unsupported types or formats that cannot be converted to a String."
            },
            "stackTrace": "java.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String\n\tat org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]\n\tat clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:423) [storm-core-1.2.1.jar:?]\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [storm-core-1.2.1.jar:1.2.1]\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]"
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "bug_report": {
            "title": "NoNodeException and RuntimeException in Nimbus Blobstore Synchronization",
            "description": {
                "stepsToReproduce": [
                    "1. Submit a new topology to the Storm cluster.",
                    "2. Kill the leader node of the Storm cluster.",
                    "3. Attempt to submit a new topology while the leader is down."
                ],
                "actualBehavior": "The system throws a NoNodeException followed by a series of RuntimeExceptions, indicating that the blobstore state could not be created in Zookeeper.",
                "possibleCause": "The issue may be caused by the absence of the expected Zookeeper node for the blobstore, which leads to the failure in retrieving the key sequence number and subsequent errors in blob synchronization."
            },
            "stackTrace": "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:200)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.util.NoSuchElementException\n\tat java.util.TreeMap.key(TreeMap.java:1327)\n\tat java.util.TreeMap.lastKey(TreeMap.java:297)\n\tat java.util.TreeSet.last(TreeSet.java:401)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:206)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)\n\tat org.apache.storm.daemon.nimbus$fn__9373.invoke(nimbus.clj:1452)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:233)\n\tat org.apache.storm.daemon.nimbus$fn__9770$exec_fn__3656__auto____9771$fn__9786.invoke(nimbus.clj:2452)\n\tat org.apache.storm.timer$schedule_recurring$this__2188.invoke(timer.clj:105)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:50)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:114)\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:76)\n\t... 8 more\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:252)\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:111)\n\t... 9 more\nCaused by: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:349)\n\tat org.apache.storm.blobstore.BlobStoreUtils.createStateInZookeeper(BlobStoreUtils.java:217)\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:249)\n\t... 10 more\nCaused by: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:376)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:453)\n\tat org.apache.storm.thrift.transport.TSaslTransport.read(TSaslTransport.java:435)\n\tat org.apache.storm.thrift.transport.TSaslClientTransport.readAll(TSaslClientTransport.java:37)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_createStateInZookeeper(Nimbus.java:1000)\n\tat org.apache.storm.generated.Nimbus$Client.createStateInZookeeper(Nimbus.java:987)\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:346)\n\t... 12 more\n\njava.lang.RuntimeException: (\"Error when processing an event\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$nimbus_data$fn__8579.invoke(nimbus.clj:212)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:71)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "bug_report": {
            "title": "IllegalStateException: This consumer has already been closed",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm application with Kafka integration.",
                    "2. Ensure that the Kafka consumer is properly configured and running.",
                    "3. Trigger a scenario that leads to the consumer being closed unexpectedly."
                ],
                "actualBehavior": "The application throws a RuntimeException indicating that the Kafka consumer has already been closed, leading to a failure in processing messages.",
                "possibleCause": "The Kafka consumer may be closed prematurely due to an error in the application logic or configuration, causing subsequent attempts to access it to fail."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]\nat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\nat java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]\nCaused by: java.lang.IllegalStateException: This consumer has already been closed.\nat org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]\nat org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]\nat org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]\nat clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\nat clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]\nat clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]\nat clojure.core$filter$fn__4580.invoke(core.clj:2679) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\nat clojure.lang.Cons.next(Cons.java:39) ~[clojure-1.7.0.jar:?]\nat clojure.lang.RT.next(RT.java:674) ~[clojure-1.7.0.jar:?]\nat clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6478$G__6473__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]\nat clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]\nat clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]\nat clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]\nat org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]"
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "bug_report": {
            "title": "KeyNotFoundException when accessing topology credentials",
            "description": {
                "stepsToReproduce": [
                    "Deploy a topology with the name 'wc-topology-test-1-1529509694'.",
                    "Attempt to access the blob store for the deployed topology.",
                    "Observe the logs for any exceptions or errors."
                ],
                "actualBehavior": "The system throws a KeyNotFoundException indicating that the required credentials for the topology cannot be found.",
                "possibleCause": "The credentials for the topology may not have been set correctly, or the necessary ACLs may not be in place for the path '/storms'."
            },
            "stackTrace": "org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\njava.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormcode.ser\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:420) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1517) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.getClusterInfoImpl(Nimbus.java:2675) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.sendClusterMetricsToExecutors(Nimbus.java:2686) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2819) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:468) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:488) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) [storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.Error: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:603) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:582) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.utils.Utils$5.uncaughtException(Utils.java:931) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1057) [?:1.8.0_131]\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052) [?:1.8.0_131]\n        at java.lang.Thread.dispatchUncaughtException(Thread.currentThread, Thread.java:1959) [?:1.8.0_131]\nCaused by: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\n        at org.apache.storm.zookeeper.AclEnforcement.getTopoAcl(AclEnforcement.java:194) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithTopoChildren(AclEnforcement.java:250) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildren(AclEnforcement.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.AclEnforcement.verifyAcls(AclEnforcement.java:136) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1155) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1162)"
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "bug_report": {
            "title": "ClosedChannelException in HDFS Writer during Storm Execution",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Storm cluster with HDFS integration.",
                    "2. Deploy a topology that writes data to HDFS using HDFSWriter.",
                    "3. Trigger the topology to process data and observe the logs."
                ],
                "actualBehavior": "The application throws a ClosedChannelException when attempting to write to HDFS, causing the topology to fail.",
                "possibleCause": "The HDFS output stream may have been closed prematurely, possibly due to network issues or improper handling of the output stream lifecycle."
            },
            "stackTrace": "java.nio.channels.ClosedChannelException: null\n    at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?]\n    at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?]\n    at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?]\n    at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?]\n    at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161]\n    at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161]\n    at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?]\n    at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?]\n    at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) [stormjar.jar:?]\n    at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013]\n    at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n    at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161]"
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "bug_report": {
            "title": "NotSerializableException for ConsList in Storm Trident",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Storm Trident topology that uses ConsList as part of the data processing.",
                    "2. Execute the topology with a sample dataset.",
                    "3. Monitor the logs for any serialization errors."
                ],
                "actualBehavior": "The application throws a NotSerializableException for org.apache.storm.trident.tuple.ConsList during execution.",
                "possibleCause": "The ConsList class does not implement the Serializable interface, which is required for objects being serialized in Storm."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]\nCaused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]\n\tat org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus during event processing",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Submit a topology that triggers event processing.",
                    "3. Monitor the Nimbus logs for errors."
                ],
                "actualBehavior": "The process halts with a RuntimeException due to a NullPointerException in the Nimbus class.",
                "possibleCause": "The NullPointerException may be caused by an uninitialized variable or an unexpected null value in the Nimbus transition method."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)\n        ... 1 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)"
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "bug_report": {
            "title": "NoAuthException when deleting Zookeeper node in Storm",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Storm topology with backpressure enabled.",
                    "2. Trigger a condition that requires the deletion of a Zookeeper node.",
                    "3. Observe the logs for any exceptions thrown during the deletion process."
                ],
                "actualBehavior": "A NoAuthException is thrown indicating that the operation is not authorized for the specified Zookeeper node.",
                "possibleCause": "The application may not have the necessary authentication credentials to perform delete operations on the specified Zookeeper node."
            },
            "stackTrace": "java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\n\tat backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat org.apache.storm.pacemaker.pacemaker_state_factory$_mkState$reify__4254.delete_node(pacemaker_state_factory.clj:174) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor859.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat sun.reflect.GeneratedMethodAccessor857.invoke(Unknown Source) ~[?:?]\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\n\tat backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.disruptor$worker_backpressure_handler$reify__6432.onEvent(disruptor.clj:57) [storm-core-0.10.2.y.jar:0.10.2.y]\n\tat backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:113) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.2.y.jar:0.10.2.y]\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.2.y.jar:0.10.2.y]"
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "bug_report": {
            "title": "ArrayIndexOutOfBoundsException in Nimbus.getComponentPageInfo",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Access the Nimbus UI and navigate to the component page.",
                    "3. Trigger the request to fetch component page information."
                ],
                "actualBehavior": "The application throws an ArrayIndexOutOfBoundsException when attempting to retrieve component page information.",
                "possibleCause": "The issue may be caused by an invalid index being accessed in the ArrayList, possibly due to an empty or improperly initialized list."
            },
            "stackTrace": "java.lang.ArrayIndexOutOfBoundsException: -2\n        at java.util.ArrayList.elementData(ArrayList.java:418)\n        at java.util.ArrayList.get(ArrayList.java:431)\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:3606)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4097)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4081)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "bug_report": {
            "title": "KeyNotFoundException in LocalFsBlobStore during topology cleanup",
            "description": {
                "stepsToReproduce": [
                    "Deploy a topology using Apache Storm.",
                    "Trigger the cleanup process for the deployed topology.",
                    "Observe the logs for any exceptions thrown during the cleanup."
                ],
                "actualBehavior": "A KeyNotFoundException is thrown, indicating that a required blob metadata could not be found in the LocalFsBlobStore.",
                "possibleCause": "The blob metadata may not have been properly stored or could have been deleted before the cleanup process was initiated."
            },
            "stackTrace": "org.apache.storm.generated.KeyNotFoundException: null\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "bug_report": {
            "title": "WrappedKeyNotFoundException when accessing topology blobs",
            "description": {
                "stepsToReproduce": [
                    "Deploy a topology named 'testHardCoreFaultTolerance'.",
                    "Attempt to access the topology's stored blobs (e.g., stormcode.ser and stormjar.jar).",
                    "Observe the logs for any exceptions thrown during the blob retrieval process."
                ],
                "actualBehavior": "The system throws a WrappedKeyNotFoundException indicating that the specified topology blobs cannot be found.",
                "possibleCause": "The blobs may not have been properly stored in the local file system blob store, or they may have been deleted or corrupted."
            },
            "stackTrace": "org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]\n\norg.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]"
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "bug_report": {
            "title": "NullPointerException in DisruptorQueue during Tuple Deserialization",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Storm application with a configured topology.",
                    "2. Ensure that the topology is processing tuples.",
                    "3. Monitor the logs for any exceptions or errors."
                ],
                "actualBehavior": "The application throws a NullPointerException during tuple deserialization, causing the worker to die.",
                "possibleCause": "The NullPointerException may be caused by an uninitialized buffer in the Kryo serialization process, leading to failure in deserializing tuples."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n\njava.lang.RuntimeException: (\"Worker died\")\n        at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.RestFn.invoke(RestFn.java:423) [storm-core-0.10.0.jar:?]\n        at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "bug_report": {
            "title": "AuthorizationException when accessing blob resource",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to run a Storm job with user 'ethan'.",
                    "2. Ensure that the job requires access to the resource identified by 'key1'.",
                    "3. Observe the logs for any authorization errors during blob localization."
                ],
                "actualBehavior": "The process halts with an AuthorizationException indicating that 'ethan does not have READ access to key1'.",
                "possibleCause": "The user 'ethan' may not have the necessary permissions to access the specified resource 'key1'."
            },
            "stackTrace": "java.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]\n        at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]\n        at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: org.apache.storm.generated.AuthorizationException\n        at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:437) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:823) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "bug_report": {
            "title": "TTransportException Occurs When Accessing Topology Page Info",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Access the Storm UI in a web browser.",
                    "3. Navigate to the topology page for a specific topology."
                ],
                "actualBehavior": "An error occurs, and the topology page fails to load, displaying a TTransportException.",
                "possibleCause": "The issue may be caused by a network connectivity problem between the Storm UI and the Nimbus server, or the Nimbus server may not be responding correctly."
            },
            "stackTrace": "org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)\n\tat org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)\n\tat org.apache.storm.ui.core$topology_page.invoke(core.clj:638)\n\tat org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)\n\tat org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)\n\tat org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)\n\tat org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "bug_report": {
            "title": "NullPointerException in BlobStoreAclHandler during Blob Creation",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to create a blob using the LocalFsBlobStore.",
                    "2. Ensure that the necessary ACLs are set for the user.",
                    "3. Execute the blob creation process."
                ],
                "actualBehavior": "A NullPointerException is thrown, causing the blob creation process to fail.",
                "possibleCause": "It is possible that a required object or parameter is not being initialized or passed correctly, leading to a null reference in the fixACLsForUser method."
            },
            "stackTrace": "java.lang.NullPointerException: null\n        at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]\n        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]"
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "bug_report": {
            "title": "PacemakerConnectionException leading to RuntimeException in Nimbus",
            "description": {
                "stepsToReproduce": [
                    "Start the Apache Storm Nimbus server.",
                    "Attempt to submit a topology to the Nimbus server.",
                    "Observe the logs for any connection issues with the Pacemaker."
                ],
                "actualBehavior": "The Nimbus server throws a RuntimeException due to a failure to connect to any Pacemaker, halting the process.",
                "possibleCause": "The Pacemaker service may not be running, or there could be network issues preventing the Nimbus from connecting to the Pacemaker."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\nCaused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:199) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:470) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:490) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:253) [storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.IllegalStateException: instance must be started before calling this method\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [java.base/jdk.internal.misc.Unsafe.park(Native Method)]"
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "bug_report": {
            "title": "DirectoryNotEmptyException during blob deletion in LocalFsBlobStore",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm nimbus service.",
                    "2. Attempt to delete a blob stored in the local file system.",
                    "3. Observe the logs for any exceptions thrown during the deletion process."
                ],
                "actualBehavior": "The service throws a DirectoryNotEmptyException indicating that the directory '/opt/storm/storm-local/blobs/955/some_big_file' is not empty, preventing the deletion of the blob.",
                "possibleCause": "The directory may contain files or subdirectories that are not being deleted before the attempt to delete the blob itself."
            },
            "stackTrace": "java.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)\n\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat clojure.core$apply.invoke(core.clj:630)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\nCaused by: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n\tat sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)\n\tat java.nio.file.Files.deleteIfExists(Files.java:1165)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.delete(FileBlobStoreImpl.java:239)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey(FileBlobStoreImpl.java:178)\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:226)\n\t... 19 more\n\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "bug_report": {
            "title": "IllegalArgumentException when checking position for unassigned partitions in KafkaConsumer",
            "description": {
                "stepsToReproduce": [
                    "1. Set up a Kafka consumer using the KafkaSpout in Apache Storm.",
                    "2. Attempt to commit offsets for tuples that are not assigned to the consumer.",
                    "3. Observe the exception thrown during the offset commit process."
                ],
                "actualBehavior": "An IllegalArgumentException is thrown with the message 'You can only check the position for partitions assigned to this consumer.'",
                "possibleCause": "The KafkaSpout is trying to commit offsets for partitions that are not currently assigned to the consumer, leading to the exception."
            },
            "stackTrace": "java.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. \nat org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) \nat org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)"
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "bug_report": {
            "title": "NodeExistsException and NoNodeException in ZooKeeper Operations",
            "description": {
                "stepsToReproduce": [
                    "1. Attempt to create a node at /ignoreStoredMetadata in ZooKeeper.",
                    "2. Ensure that the node already exists before the creation attempt.",
                    "3. Attempt to delete a node at /rainbowHdfsPath that does not exist."
                ],
                "actualBehavior": "The application throws a NodeExistsException when trying to create an existing node and a NoNodeException when trying to delete a non-existing node.",
                "possibleCause": "The application logic does not handle the existence of nodes properly before attempting to create or delete them."
            },
            "stackTrace": "Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 9 more\n\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]"
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus when killing topology",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm cluster.",
                    "2. Deploy a topology to the cluster.",
                    "3. Attempt to kill the deployed topology using the Nimbus interface."
                ],
                "actualBehavior": "A NullPointerException is thrown, causing the topology kill operation to fail.",
                "possibleCause": "The issue may be caused by a null reference being passed to the getTopoId method in IStormClusterState, possibly due to an uninitialized or improperly configured topology."
            },
            "stackTrace": "java.lang.NullPointerException: null\n\tat org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n\tat org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer$FrameBuffer.java:518) ~[libthrift-0.10.0.jar:0.10.0]\n\tat org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[libthrift-0.10.0.jar:0.10.0]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]"
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "bug_report": {
            "title": "NullPointerException in AbstractAutoCreds.addTokensToUGI",
            "description": {
                "stepsToReproduce": [
                    "1. Initialize the Storm application with the necessary configurations.",
                    "2. Trigger the authentication process that involves adding tokens to the UserGroupInformation (UGI).",
                    "3. Observe the logs or console output for any exceptions."
                ],
                "actualBehavior": "The application throws a NullPointerException when attempting to add tokens to the UGI.",
                "possibleCause": "It is possible that a required object or token is not initialized or is null when the method addTokensToUGI is called."
            },
            "stackTrace": "Caused by: java.lang.NullPointerException\n            at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\n            at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\n            at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]"
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "bug_report": {
            "title": "Blob Download Failure in AsyncLocalizer",
            "description": {
                "stepsToReproduce": [
                    "1. Deploy a topology that requires downloading blobs.",
                    "2. Start the topology using the Storm cluster.",
                    "3. Monitor the logs for any blob download issues."
                ],
                "actualBehavior": "The topology fails to download required blobs, resulting in a RuntimeException.",
                "possibleCause": "The blob metadata may not exist in the Nimbus server, leading to a KeyNotFoundException."
            },
            "stackTrace": "java.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...\n\n        at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]\n\n        at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]\n\n        at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n\nCaused by: java.lang.RuntimeException: Could not download...\n\n        at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_131]\n\n        ... 3 more\n\nCaused by: org.apache.storm.generated.KeyNotFoundException\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\n        at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_131]"
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "bug_report": {
            "title": "NullPointerException in LogCleaner.selectDirsForCleanup",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm application.",
                    "2. Trigger the log cleanup process.",
                    "3. Monitor the application for exceptions."
                ],
                "actualBehavior": "The application throws a NullPointerException during the log cleanup process.",
                "possibleCause": "The LogCleaner may be attempting to process a null reference when selecting directories for cleanup."
            },
            "stackTrace": "java.lang.NullPointerException: null\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "bug_report": {
            "title": "GSS Initiate Failure in Thrift Transport",
            "description": {
                "stepsToReproduce": [
                    "1. Configure the Storm application to use Kerberos authentication.",
                    "2. Attempt to connect to the Nimbus server using the configured settings.",
                    "3. Observe the logs for any errors during the connection process."
                ],
                "actualBehavior": "The application fails to connect to the Nimbus server, throwing a GSS initiate failure exception.",
                "possibleCause": "The issue may be related to incorrect Kerberos configuration or missing credentials required for the GSSAPI authentication process."
            },
            "stackTrace": "org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\n\tat org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]\n\tat javax.security.auth.Subject.doAs(Subject.java:415) [?:1.7.0_60]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]"
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "bug_report": {
            "title": "SaslException: GSS initiate failed due to BAD TGS SERVER NAME",
            "description": {
                "stepsToReproduce": [
                    "1. Configure the application to use Kerberos authentication.",
                    "2. Attempt to connect to the service that requires Kerberos authentication.",
                    "3. Observe the logs for any authentication errors."
                ],
                "actualBehavior": "The application throws a SaslException indicating that the GSS initiate failed due to invalid credentials, specifically a BAD TGS SERVER NAME error.",
                "possibleCause": "The Kerberos ticket may not be valid for the requested service, possibly due to misconfiguration of the service principal name or the Kerberos realm."
            },
            "stackTrace": "javax.security.sasl.SaslException: GSS initiate failed\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]\n        at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]\n        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_40]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]\nCaused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:770) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.serviceCreds:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.acquireServiceCreds:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.acquireServiceCreds:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.initSecContext:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.evaluateChallenge:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)\n        at sun.security.krb5.internal.KDCRep.init(KDCRep.init:140) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.init(TGSRep.init:65) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.<init>(TGSRep.<init>:60) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.<init>:55) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.getReply:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.sendAndGetCreds:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.serviceCreds:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.acquireServiceCreds:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.acquireServiceCreds:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.initSecContext:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.initSecContext:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.evaluateChallenge:192) ~[?:1.8.0_40]"
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "bug_report": {
            "title": "RuntimeException when converting null to int in SQL evaluation",
            "description": {
                "stepsToReproduce": [
                    "1. Execute a SQL query that attempts to convert a null value to an integer.",
                    "2. Ensure that the query is processed by the Apache Storm framework.",
                    "3. Observe the logs for any exceptions thrown during execution."
                ],
                "actualBehavior": "A RuntimeException is thrown indicating that null cannot be converted to an int.",
                "possibleCause": "The SQL function is not handling null values properly, leading to a failure when attempting to convert a null to an integer."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n        at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]\n        at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]\nCaused by: java.lang.RuntimeException: Cannot convert null to int\n        at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at SC.eval0(Unknown Source) ~[?:?]"
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "bug_report": {
            "title": "NoNodeException when accessing leader lock in Zookeeper",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Storm application that utilizes Zookeeper for leader election.",
                    "2. Attempt to access the leader lock node in Zookeeper at the path '/storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002'.",
                    "3. Observe the application behavior when trying to retrieve data from the specified node."
                ],
                "actualBehavior": "The application throws a NoNodeException indicating that the specified node does not exist.",
                "possibleCause": "The leader lock node may have been deleted or not created properly during the leader election process."
            },
            "stackTrace": "org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)\nat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)"
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus during server launch",
            "description": {
                "stepsToReproduce": [
                    "Start the Apache Storm Nimbus server.",
                    "Trigger the event processing that requires reading supervisor details.",
                    "Observe the server logs for any exceptions."
                ],
                "actualBehavior": "The Nimbus server fails to launch properly and throws a NullPointerException, leading to a RuntimeException and halting the process.",
                "possibleCause": "The NullPointerException may be caused by an uninitialized variable or a missing configuration related to supervisor details."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.NullPointerException\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n\tat org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\t... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n\tat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]"
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "bug_report": {
            "title": "IndexOutOfBoundsException in Netty Encoder during Storm Topology Submission",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Storm cluster.",
                    "2. Submit a topology that requires a large amount of data to be processed.",
                    "3. Monitor the logs for any exceptions during the submission process."
                ],
                "actualBehavior": "An IndexOutOfBoundsException is thrown, indicating that the writer index exceeds the maximum capacity of the buffer.",
                "possibleCause": "The buffer used in the Netty encoder may not have enough capacity to handle the data being written, leading to an attempt to write beyond its limits."
            },
            "stackTrace": "org.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelInboundHandlerAdapter.java:64) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline$HeadContext.channelActive(DefaultChannelPipeline.java:1422) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.fireChannelActive(DefaultChannelPipeline.java:941) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:311) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:341) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:635) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        ... 26 more\n\njava.lang.IllegalStateException: instance must be started before calling this method\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3009) [storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]"
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "bug_report": {
            "title": "OutOfMemoryError: Java heap space in Thrift Server",
            "description": {
                "stepsToReproduce": [
                    "Start the Thrift server with a large number of concurrent requests.",
                    "Send a high volume of data to the server.",
                    "Monitor the server's memory usage during the operation."
                ],
                "actualBehavior": "The server throws a java.lang.OutOfMemoryError: Java heap space, causing it to crash.",
                "possibleCause": "The server may not be handling memory allocation efficiently, leading to excessive memory consumption under high load."
            },
            "stackTrace": "java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]"
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "bug_report": {
            "title": "NullPointerException in Localizer.updateBlobs",
            "description": {
                "stepsToReproduce": [
                    "1. Start the Apache Storm supervisor.",
                    "2. Deploy a topology that requires blob updates.",
                    "3. Monitor the logs for errors during blob updates."
                ],
                "actualBehavior": "The process halts with a NullPointerException when attempting to update blobs.",
                "possibleCause": "It is possible that a required object or resource is not initialized or is missing, leading to a NullPointerException when accessed in the ConcurrentHashMap."
            },
            "stackTrace": "java.lang.NullPointerException: null\n        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]\n        at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]\n\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "bug_report": {
            "title": "NullPointerException in Nimbus during topology submission",
            "description": {
                "stepsToReproduce": [
                    "Start the Apache Storm cluster.",
                    "Attempt to submit a topology to the Nimbus server.",
                    "Observe the logs for any errors."
                ],
                "actualBehavior": "The topology submission fails with a NullPointerException and a RuntimeException indicating that the current node is not the leader.",
                "possibleCause": "The Nimbus server may be trying to access a supervisor detail that is not initialized or is null, leading to a NullPointerException."
            },
            "stackTrace": "java.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        ... 2 more\n\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n\njava.lang.RuntimeException: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2961) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\nCaused by: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]"
        }
    }
]