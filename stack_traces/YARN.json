[
    {
        "filename": "YARN-5918.json",
        "creation_time": "2016-11-20T14:19:00.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNode(OpportunisticContainerAllocatorAMService.java:420)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.convertToRemoteNodes(OpportunisticContainerAllocatorAMService.java:412)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.getLeastLoadedNodes(OpportunisticContainerAllocatorAMService.java:402)\n        at org.apache.hadoop.yarn.server.resourcemanager.OpportunisticContainerAllocatorAMService.allocate(OpportunisticContainerAllocatorAMService.java:236)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:467)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:990)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:846)\n        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:789)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1857)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2539)\n```"
    },
    {
        "filename": "YARN-8629.json",
        "creation_time": "2018-08-07T00:14:14.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: /sys/fs/cgroup/cpu,cpuacct/hadoop-yarn-tmp-cxx/container_e02_1533336898541_0010_20_000002/tasks (No such file or directory)\n        at java.io.FileInputStream.open0(Native Method)\n        at java.io.FileInputStream.open(FileInputStream.java:195)\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\n        at java.io.FileInputStream.<init>(FileInputStream.java:93)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.checkAndDeleteCgroup(CGroupsHandlerImpl.java:507)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsHandlerImpl.deleteCGroup(CGroupsHandlerImpl.java:542)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.CGroupsCpuResourceHandlerImpl.postComplete(CGroupsCpuResourceHandlerImpl.java:238)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.postComplete(ResourceHandlerChain.java:111)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.postComplete(LinuxContainerExecutor.java:964)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.reapContainer(LinuxContainerExecutor.java:787)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:821)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:161)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:57)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-4431.json",
        "creation_time": "2015-12-07T18:31:36.000+0000",
        "stack_trace": "```\njava.net.ConnectException: Call From jduMBP.local/10.200.10.53 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n        at sun.reflect.GeneratedConstructorAccessor30.newInstance(Unknown Source)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:408)\n        at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1452)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1385)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)\n        at com.sun.proxy.$Proxy74.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.unRegisterNodeManager(ResourceTrackerPBClientImpl.java:98)\n        at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:483)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:255)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy75.unRegisterNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.unRegisterNM(NodeStatusUpdaterImpl.java:267)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStop(NodeStatusUpdaterImpl.java:245)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:377)\n```"
    },
    {
        "filename": "YARN-2273.json",
        "creation_time": "2014-07-10T18:38:53.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1044)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$NodeAvailableResourceComparator.compare(FairScheduler.java:1040)\n\tat java.util.TimSort.countRunAndMakeAscending(TimSort.java:329)\n\tat java.util.TimSort.sort(TimSort.java:203)\n\tat java.util.TimSort.sort(TimSort.java:173)\n\tat java.util.Arrays.sort(Arrays.java:659)\n\tat java.util.Collections.sort(Collections.java:217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousScheduling(FairScheduler.java:1012)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.access$600(FairScheduler.java:124)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$2.run(FairScheduler.java:1306)\n\tat java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-2834.json",
        "creation_time": "2014-11-09T06:07:01.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:734)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1089)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1041)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1005)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:821)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:101)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:843)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:701)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:413)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1207)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:590)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1014)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1051)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1047)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1047)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1091)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1226)\n```"
    },
    {
        "filename": "YARN-370.json",
        "creation_time": "2013-02-01T04:02:58.000+0000",
        "stack_trace": "```\nError launching appattempt_1359688216672_0001_000001. Got exception: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: RemoteTrace: at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unauthorized request to start container. Expected resource <memory:2048, vCores:1> but found <memory:1536, vCores:1> at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39) at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeRequest(ContainerManagerImpl.java:383) at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.startContainer(ContainerManagerImpl.java:400) at org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagerPBServiceImpl.startContainer(ContainerManagerPBServiceImpl.java:68) at org.apache.hadoop.yarn.proto.ContainerManager$ContainerManagerService$2.callBlockingMethod(ContainerManager.java:83) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1735) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1731) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1441) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1729) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(Native Method) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:525) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57) at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:123) at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:109) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:111) at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:255) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) at java.lang.Thread.run(Thread.java:722)\n```"
    },
    {
        "filename": "YARN-3675.json",
        "creation_time": "2015-05-18T22:38:39.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.unreserve(FSAppAttempt.java:469)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:815)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:763)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1217)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-4763.json",
        "creation_time": "2016-03-04T10:03:56.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppsBlock.renderData(RMAppsBlock.java:100)\n        at org.apache.hadoop.yarn.server.webapp.AppsBlock.render(AppsBlock.java:140)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock$Block.subView(HtmlBlock.java:43)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet._(Hamlet.java:30354)\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlockWithMetrics.render(AppsBlockWithMetrics.java:30)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:848)\n        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\n        at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.render(Dispatcher.java:197)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:156)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n```"
    },
    {
        "filename": "YARN-8202.json",
        "creation_time": "2018-04-24T15:52:00.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested resource type=[resource1] < 0 or greater than maximum allowed allocation. Requested resource=<memory:200, vCores:1, resource1: 500M>, maximum allowed allocation=<memory:6144, vCores:8, resource1: 5G>, please note that maximum allowed allocation is calculated by scheduler based on maximum resource of registered NodeManagers, which might be less than configured maximum allocation=<memory:8192, vCores:8192, resource1: 9223372036854775807G>\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:286)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndValidateRequest(SchedulerUtils.java:242)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeAndvalidateRequest(SchedulerUtils.java:258)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.normalizeAndValidateRequests(RMServerUtils.java:249)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor.allocate(DefaultAMSProcessor.java:230)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor.allocate(DisabledPlacementProcessor.java:75)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.AMSProcessingChain.allocate(AMSProcessingChain.java:92)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:433)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)\n\u00a0 \u00a0 \u00a0 \u00a0 at java.security.AccessController.doPrivileged(Native Method)\n\u00a0 \u00a0 \u00a0 \u00a0 at javax.security.auth.Subject.doAs(Subject.java:422)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)\n```"
    },
    {
        "filename": "YARN-7118.json",
        "creation_time": "2017-08-29T12:04:01.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.webapp.WebServices.getApps(WebServices.java:191)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices.getApps(AHSWebServices.java:96)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n```"
    },
    {
        "filename": "YARN-4743.json",
        "creation_time": "2016-02-27T09:12:28.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n         at java.util.TimSort.mergeHi(TimSort.java:868)\n         at java.util.TimSort.mergeAt(TimSort.java:485)\n         at java.util.TimSort.mergeCollapse(TimSort.java:410)\n         at java.util.TimSort.sort(TimSort.java:214)\n         at java.util.TimSort.sort(TimSort.java:173)\n         at java.util.Arrays.sort(Arrays.java:659)\n         at java.util.Collections.sort(Collections.java:217)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:316)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:240)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1091)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:989)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1185)\n         at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n         at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n         at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-2414.json",
        "creation_time": "2014-08-12T23:48:48.000+0000",
        "stack_trace": "```\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:153)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n\tat com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)\n\tat com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:84)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:460)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1191)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.AppBlock.render(AppBlock.java:116)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:67)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:77)\n\tat org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n\tat org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)\n\tat org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:845)\n\tat org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:56)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n\tat org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:55)\n\t... 44 more\n```"
    },
    {
        "filename": "YARN-3878.json",
        "creation_time": "2015-07-02T00:20:59.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.updateApplicationAttemptState(RMStateStore.java:652)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.rememberTargetTransitionsAndStoreState(RMAppAttemptImpl.java:1173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.access$3300(RMAppAttemptImpl.java:109)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1650)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$ContainerFinishedTransition.transition(RMAppAttemptImpl.java:1619)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:786)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:108)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:838)\n\n\"AsyncDispatcher event handler\" prio=10 tid=0x00007fb980222800 nid=0x4b1e waiting on condition [0x00007fb9654e9000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000700b79250> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:113)\n        at java.lang.Thread.run(Thread.java:744)\n\n\"main\" prio=10 tid=0x00007fb98000a800 nid=0x49c3 in Object.wait() [0x00007fb989851000]\n   java.lang.Thread.State: TIMED_WAITING (on object monitor)\n\tat java.lang.Object.wait(Native Method)\n\t- waiting on <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:156)\n\t- locked <0x0000000700b79430> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79420> (a java.lang.Object)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.serviceStop(RMStateStore.java:515)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\t- locked <0x0000000700b79630> (a java.lang.Object)\n\tat org.apache.hadoop.service.AbstractService.close(AbstractService.java:250)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:599)\n```"
    },
    {
        "filename": "YARN-6683.json",
        "creation_time": "2017-06-02T00:29:13.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: COLLECTOR_UPDATE at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:903)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:118)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:904)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:888)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:201)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:127)\n```"
    },
    {
        "filename": "YARN-2910.json",
        "creation_time": "2014-11-27T06:19:00.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException: java.util.ConcurrentModificationException\nat java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859)\nat java.util.ArrayList$Itr.next(ArrayList.java:831)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.getResourceUsage(FSLeafQueue.java:147)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.getHeadroom(FSAppAttempt.java:180)\nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocate(FairScheduler.java:923)\nat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:516)\n```"
    },
    {
        "filename": "YARN-192.json",
        "creation_time": "2012-11-01T05:00:41.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerApp.unreserve(FSSchedulerApp.java:356)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.unreserve(AppSchedulable.java:214)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:266)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:330)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSQueueSchedulable.assignContainer(FSQueueSchedulable.java:161)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:759)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:836)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:329)\n        at java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-4581.json",
        "creation_time": "2016-01-12T03:37:40.000+0000",
        "stack_trace": "```\njava.io.IOException: Output file not at zero offset.\n        at org.apache.hadoop.io.file.tfile.BCFile$Writer.<init>(BCFile.java:288)\n        at org.apache.hadoop.io.file.tfile.TFile$Writer.<init>(TFile.java:288)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:728)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n\njava.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:714)\n        at org.apache.hadoop.hdfs.DFSOutputStream.start(DFSOutputStream.java:2033)\n        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForAppend(DFSOutputStream.java:1652)\n        at org.apache.hadoop.hdfs.DFSClient.callAppend(DFSClient.java:1573)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1603)\n        at org.apache.hadoop.hdfs.DFSClient.append(DFSClient.java:1591)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.append(DistributedFileSystem.java:324)\n        at org.apache.hadoop.fs.FileSystem.append(FileSystem.java:1161)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore$HistoryFileWriter.<init>(FileSystemApplicationHistoryStore.java:723)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.FileSystemApplicationHistoryStore.applicationStarted(FileSystemApplicationHistoryStore.java:418)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.handleWritingApplicationHistoryEvent(RMApplicationHistoryWriter.java:140)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$ForwardingEventHandler.handle(RMApplicationHistoryWriter.java:292)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:191)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:124)\n        at java.lang.Thread.run(Thread.java:745)\n\njava.lang.Thread.State: TIMED_WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:502)\n        - locked <0x0000000745f88b98> (a java.util.LinkedList)\n```"
    },
    {
        "filename": "YARN-7786.json",
        "creation_time": "2018-01-22T14:29:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.setupTokens(AMLauncher.java:205)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.createAMContainerLaunchContext(AMLauncher.java:193)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:112)\n at org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:304)\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-8035.json",
        "creation_time": "2018-03-16T12:02:04.000+0000",
        "stack_trace": "```\norg.apache.hadoop.metrics2.MetricsException: Tag ContainerPid already exists!\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.checkTagName(MetricsRegistry.java:433)\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:394)\nat org.apache.hadoop.metrics2.lib.MetricsRegistry.tag(MetricsRegistry.java:400)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerMetrics.recordProcessId(ContainerMetrics.java:277)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.initializeProcessTrees(ContainersMonitorImpl.java:559)\nat org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run(ContainersMonitorImpl.java:448)\n```"
    },
    {
        "filename": "YARN-4152.json",
        "creation_time": "2015-09-12T15:02:22.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopContainer(LogAggregationService.java:422)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:456)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:68)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-3697.json",
        "creation_time": "2015-05-21T18:05:38.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:249)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:467)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl$ContainerStartedTransition.transition(RMContainerImpl.java:462)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:387)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.handle(RMContainerImpl.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.allocate(FSAppAttempt.java:357)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:516)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:649)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:803)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:334)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:173)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1082)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:1014)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:285)\n\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:244)\n\t... 17 more\n```"
    },
    {
        "filename": "YARN-2340.json",
        "creation_time": "2014-07-23T15:18:38.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:568)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:916)\n at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:101)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:602)\n at java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-8022.json",
        "creation_time": "2018-03-10T19:29:27.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:283)\n at org.apache.hadoop.yarn.server.webapp.AppBlock$3.run(AppBlock.java:280)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)\n at org.apache.hadoop.yarn.server.webapp.AppBlock.render(AppBlock.java:279)\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMAppBlock.render(RMAppBlock.java:71)\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)\n at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)\n at org.apache.hadoop.yarn.webapp.View.render(View.java:235)\n at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)\n at org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl$EImp._v(HamletImpl.java:117)\n at org.apache.hadoop.yarn.webapp.hamlet2.Hamlet$TD.__(Hamlet.java:848)\n at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)\n at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)\n at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)\n at org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:54)\n```"
    },
    {
        "filename": "YARN-3793.json",
        "creation_time": "2015-06-10T20:52:38.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.fs.FileContext.fixRelativePart(FileContext.java:274)\n        at org.apache.hadoop.fs.FileContext.delete(FileContext.java:755)\n        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.deleteAsUser(DefaultContainerExecutor.java:458)\n        at org.apache.hadoop.yarn.server.nodemanager.DeletionService$FileDeletionTask.run(DeletionService.java:293)\n```"
    },
    {
        "filename": "YARN-6102.json",
        "creation_time": "2017-01-17T09:36:29.000+0000",
        "stack_trace": "```\njava.lang.Exception: No handler for registered for class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:196)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:120)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-8409.json",
        "creation_time": "2018-06-08T20:36:32.000+0000",
        "stack_trace": "```\njava.net.ConnectException: Connection refused\n\nat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\nat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\nat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)\n\nat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1125)\n\njava.lang.NullPointerException\n\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1033)\n\nat org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1030)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1087)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1030)\n\nat org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:347)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.serviceInit(ActiveStandbyElectorBasedElectorService.java:110)\n\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\nat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:336)\n\nat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1479)\n```"
    },
    {
        "filename": "YARN-8223.json",
        "creation_time": "2018-04-27T11:49:02.000+0000",
        "stack_trace": "```\njava.lang.ClassNotFoundException: org.apache.auxtest.AuxServiceFromLocal\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:189)\n\tat org.apache.hadoop.util.ApplicationClassLoader.loadClass(ApplicationClassLoader.java:157)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:348)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxiliaryServiceWithCustomClassLoader.getInstance(AuxiliaryServiceWithCustomClassLoader.java:169)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:249)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:472)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:918)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:979)\n```"
    },
    {
        "filename": "YARN-8331.json",
        "creation_time": "2018-05-21T05:19:35.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: CONTAINER_LAUNCHED at DONE\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:487)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:2104)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:104)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1525)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1518)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n\tat java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-2931.json",
        "creation_time": "2014-12-08T21:09:13.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: File /data/yarn/nm/filecache does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:524)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:737)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:514)\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:1051)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:162)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:197)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:724)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:720)\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:720)\n\tat org.apache.hadoop.yarn.util.FSDownload.createDir(FSDownload.java:104)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:351)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:60)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-6837.json",
        "creation_time": "2017-07-18T11:17:55.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.addResources(ResourceSet.java:84)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:868)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(ContainerImpl.java:819)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1684)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:96)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1418)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1411)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-4762.json",
        "creation_time": "2016-03-04T02:24:47.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)\n        ... 3 more\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:240)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:539)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:587)\nCaused by: java.io.IOException: Failed to initialize linux container runtime(s)!\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:207)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:238)\n        ... 3 more\n```"
    },
    {
        "filename": "YARN-2823.json",
        "creation_time": "2014-11-06T21:38:47.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.transferStateFromPreviousAttempt(SchedulerApplicationAttempt.java:530)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:678)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1015)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:603)\n        at java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-5098.json",
        "creation_time": "2016-05-17T00:43:08.000+0000",
        "stack_trace": "```\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 171 for hrt_qa) can't be found in cache\n        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:375)\n        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:583)\n        at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:398)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:752)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:748)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1719)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:747)\n        at org.apache.hadoop.ipc.Client$Connection.access$3100(Client.java:398)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1597)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1439)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:240)\n        at com.sun.proxy.$Proxy83.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getServerDefaults(ClientNamenodeProtocolTranslatorPB.java:282)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n        at com.sun.proxy.$Proxy84.getServerDefaults(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSClient.getServerDefaults(DFSClient.java:1018)\n        at org.apache.hadoop.fs.Hdfs.getServerDefaults(Hdfs.java:156)\n        at org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:550)\n        at org.apache.hadoop.fs.FileContext$3.next(FileContext.java:687)\n```"
    },
    {
        "filename": "YARN-3971.json",
        "creation_time": "2015-07-24T10:17:05.000+0000",
        "stack_trace": "```\njava.io.IOException: Cannot remove label=x, because queue=a1 is using this label. Please remove label on queue before remove the label\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.checkRemoveFromClusterNodeLabelsOfQueue(RMNodeLabelsManager.java:104)\n        at org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager.removeFromClusterNodeLabels(RMNodeLabelsManager.java:118)\n        at org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore.recover(FileSystemNodeLabelsStore.java:221)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.initNodeLabelStore(CommonNodeLabelsManager.java:232)\n        at org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager.serviceStart(CommonNodeLabelsManager.java:245)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:964)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1005)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1001)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1666)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1001)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:312)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:832)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:422)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n```"
    },
    {
        "filename": "YARN-6948.json",
        "creation_time": "2017-08-04T08:23:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_ADDED at FINAL_SAVING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:757)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:834)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:815)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-1409.json",
        "creation_time": "2013-11-13T11:25:56.000+0000",
        "stack_trace": "```\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@d51df63 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7a20e369[Shutting down, pool size = 4, active threads = 0, queued tasks = 7, completed tasks = 0]\n        at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\n        at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:325)\n        at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:530)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:121)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(NonAggregatingLogHandler.java:49)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:159)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:95)\n        at java.lang.Thread.run(Thread.java:724)\n```"
    },
    {
        "filename": "YARN-5545.json",
        "creation_time": "2016-08-21T12:57:35.000+0000",
        "stack_trace": "```\njava.io.IOException: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:316)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:255)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n...\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: Failed to submit application_1471670113386_0001 to YARN : org.apache.hadoop.security.AccessControlException: Queue root.default already has 0 applications, cannot accept submission of application: application_1471670113386_0001\n\tat org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:286)\n\tat org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:296)\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n\t... 25 more\n```"
    },
    {
        "filename": "YARN-301.json",
        "creation_time": "2013-01-01T05:40:18.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)\n        at java.util.TreeMap$KeyIterator.next(TreeMap.java:1154)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.assignContainer(AppSchedulable.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:181)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:780)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:842)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:340)\n        at java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-7942.json",
        "creation_time": "2018-02-16T19:09:39.000+0000",
        "stack_trace": "```\norg.apache.hadoop.registry.client.exceptions.NoPathPermissionsException: `/registry/users/hbase/services/yarn-service/hbase-app-test': Not authorized to access path; ACLs: [null ACL]: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:412)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.operationFailure(CuratorService.java:390)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:722)\n        at org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService.delete(RegistryOperationsService.java:162)\n        at org.apache.hadoop.yarn.service.client.ServiceClient.actionDestroy(ServiceClient.java:462)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:253)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$4.run(ApiServer.java:243)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.stopService(ApiServer.java:243)\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.deleteService(ApiServer.java:223)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:89)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:941)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)\n        at org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppFilter.doFilter(RMWebAppFilter.java:178)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)\n        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)\n        at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter$Context.java:203)\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:57)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.AuthenticationWithProxyUserFilter.doFilter(AuthenticationWithProxyUserFilter.java:101)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1617)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /registry/users/hbase/services/yarn-service/hbase-app-test\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n        at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:250)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:244)\n        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:241)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:225)\n        at org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:35)\n        at org.apache.hadoop.registry.client.impl.zk.CuratorService.zkDelete(CuratorService.java:718)\n        ... 75 more\n```"
    },
    {
        "filename": "YARN-7692.json",
        "creation_time": "2017-12-29T06:00:34.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.checkAndGetApplicationPriority(CapacityScheduler.java:2348)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:396)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:358)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:567)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1390)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1143)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1183)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1179)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1179)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:611)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:510)\nCaused by: org.apache.hadoop.security.AccessControlException: User hrt_qa (auth:SIMPLE) does not have permission to submit/update application_1514268754125_0001 for 0\n        ... 20 more\n```"
    },
    {
        "filename": "YARN-3917.json",
        "creation_time": "2015-07-11T00:41:28.000+0000",
        "stack_trace": "```\njava.lang.UnsupportedOperationException: Could not determine OS\n        at org.apache.hadoop.util.SysInfo.newInstance(SysInfo.java:43)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.<init>(ResourceCalculatorPlugin.java:37)\n        at org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.getResourceCalculatorPlugin(ResourceCalculatorPlugin.java:160)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.serviceInit(ContainersMonitorImpl.java:108)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:249)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:312)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:547)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:595)\n```"
    },
    {
        "filename": "YARN-3537.json",
        "creation_time": "2015-04-23T11:34:23.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stopRecoveryStore(NodeManager.java:181)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStop(NodeManager.java:326)\n\tat org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n\tat org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.tearDown(TestNodeManagerShutdown.java:106)\n```"
    },
    {
        "filename": "YARN-7962.json",
        "creation_time": "2018-02-22T22:32:20.000+0000",
        "stack_trace": "```\njava.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable@39bddaf2 rejected from java.util.concurrent.ThreadPoolExecutor@5f71637b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15487]\n\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)\n\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)\n\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.processDelegationTokenRenewerEvent(DelegationTokenRenewer.java:196)\n\tat org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.applicationFinished(DelegationTokenRenewer.java:734)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication(RMAppManager.java:199)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:424)\n\tat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:65)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:177)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-8357.json",
        "creation_time": "2018-05-24T16:46:57.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\n        at org.apache.hadoop.yarn.service.client.ServiceClient.actionStart(ServiceClient.java:974)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:650)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer$7.run(ApiServer.java:644)\n\n        at java.security.AccessController.doPrivileged(Native Method)\n\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1687)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.startService(ApiServer.java:644)\n\n        at org.apache.hadoop.yarn.service.webapp.ApiServer.updateService(ApiServer.java:449)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\n        at java.lang.reflect.Method.invoke(Method.java:498)\n\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\n\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n```"
    },
    {
        "filename": "YARN-6534.json",
        "creation_time": "2017-04-26T21:43:52.000+0000",
        "stack_trace": "```\norg.apache.hadoop.service.ServiceStateException: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.serviceInit(TimelineClientImpl.java:131)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher.serviceInit(AbstractSystemMetricsPublisher.java:59)\n        at org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.serviceInit(TimelineServiceV1Publisher.java:67)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:344)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1453)\nCaused by: java.io.FileNotFoundException: /etc/security/clientKeys/all.jks (No such file or directory)\n        at java.io.FileInputStream.open0(Native Method)\n        at java.io.FileInputStream.open(FileInputStream.java:195)\n        at java.io.FileInputStream.<init>(FileInputStream.java:138)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.loadTrustManager(ReloadingX509TrustManager.java:168)\n        at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.<init>(ReloadingX509TrustManager.java:86)\n        at org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.init(FileBasedKeyStoresFactory.java:219)\n        at org.apache.hadoop.security.ssl.SSLFactory.init(SSLFactory.java:179)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.getSSLFactory(TimelineConnector.java:176)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineConnector.serviceInit(TimelineConnector.java:106)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        ... 11 more\n```"
    },
    {
        "filename": "YARN-4227.json",
        "creation_time": "2015-10-06T04:59:10.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.completedContainer(FairScheduler.java:849)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1273)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:122)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:585)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-2649.json",
        "creation_time": "2014-10-06T22:57:46.000+0000",
        "stack_trace": "```\njunit.framework.AssertionFailedError: AppAttempt state is not correct (timedout) expected:<ALLOCATED> but was:<SCHEDULED>\n\tat junit.framework.Assert.fail(Assert.java:50)\n\tat junit.framework.Assert.failNotEquals(Assert.java:287)\n\tat junit.framework.Assert.assertEquals(Assert.java:67)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockAM.waitForState(MockAM.java:82)\n\tat org.apache.hadoop.yarn.server.resourcemanager.MockRM.sendAMLaunched(MockRM.java:382)\n\tat org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates.testAMRMUnusableNodes(TestAMRMRPCNodeUpdates.java:125)\n\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from NEW to SUBMITTED\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.EventType: STATUS_UPDATE\nrmnode.RMNodeImpl (RMNodeImpl.java:handle(384)) - Processing 127.0.0.1:1234 of type STATUS_UPDATE\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent.EventType: APP_ATTEMPT_ADDED\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent.EventType: NODE_UPDATE\nevent.AsyncDispatcher (AsyncDispatcher.java:dispatch(164)) - Dispatching the event org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEvent.EventType: ATTEMPT_ADDED\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(658)) - Processing event for appattempt_1412569506932_0001_000001 of type ATTEMPT_ADDED\nattempt.RMAppAttemptImpl (RMAppAttemptImpl.java:handle(670)) - appattempt_1412569506932_0001_000001 State change from SUBMITTED to SCHEDULED\n```"
    },
    {
        "filename": "YARN-4288.json",
        "creation_time": "2015-10-22T12:30:16.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:223)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager$2.run(NodeManager.java:304)\nCaused by: java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: \"ebdp-ch2-172.27.62.28\"; destination host is: \"172.27.62.57\":8025;\n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1473)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1400)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)\n        at com.sun.proxy.$Proxy36.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy37.registerNodeManager(Unknown Source)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:257)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.rebootNodeStatusUpdaterAndRegisterWithRM(NodeStatusUpdaterImpl.java:215)\n        ... 1 more\nCaused by: java.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:197)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)\n        at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)\n        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at java.io.FilterInputStream.read(FilterInputStream.java:133)\n        at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:514)\n        at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:254)\n        at java.io.DataInputStream.readInt(DataInputStream.java:387)\n        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1072)\n        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:967)\n```"
    },
    {
        "filename": "YARN-1032.json",
        "creation_time": "2013-08-05T21:10:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:99)\n\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:92)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignMapsWithLocality(RMContainerAllocator.java:1039)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignContainers(RMContainerAllocator.java:925)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:861)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$400(RMContainerAllocator.java:681)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:219)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:243)\n\tat java.lang.Thread.run(Thread.java:722)\n```"
    },
    {
        "filename": "YARN-5837.json",
        "creation_time": "2016-11-04T16:06:59.000+0000",
        "stack_trace": "```\nException in thread \"main\" java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus(NodeCLI.java:296)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.run(NodeCLI.java:116)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)\n\tat org.apache.hadoop.yarn.client.cli.NodeCLI.main(NodeCLI.java:63)\n```"
    },
    {
        "filename": "YARN-6827.json",
        "creation_time": "2017-07-15T05:14:25.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:178)\n\tat org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher.putEntity(TimelineServiceV1Publisher.java:368)\n```"
    },
    {
        "filename": "YARN-3832.json",
        "creation_time": "2015-06-19T13:31:18.000+0000",
        "stack_trace": "```\njava.io.IOException: Rename cannot overwrite non empty destination directory /opt/hdfsdata/HA/nmlocal/usercache/root/filecache/39\nat org.apache.hadoop.fs.AbstractFileSystem.renameInternal(AbstractFileSystem.java:735)\nat org.apache.hadoop.fs.FilterFs.renameInternal(FilterFs.java:244)\nat org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:678)\nat org.apache.hadoop.fs.FileContext.rename(FileContext.java:958)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:366)\nat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:62)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-2409.json",
        "creation_time": "2014-08-12T10:53:06.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at LAUNCHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:697)\n\tat org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:105)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:779)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:760)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-8116.json",
        "creation_time": "2018-04-04T15:30:52.000+0000",
        "stack_trace": "```\njava.lang.NumberFormatException: For input string: \"\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Long.parseLong(Long.java:601)\n\tat java.lang.Long.parseLong(Long.java:631)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\n\njava.lang.NumberFormatException: For input string: \"\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n\tat java.lang.Long.parseLong(Long.java:601)\n\tat java.lang.Long.parseLong(Long.java:631)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainerState(NMLeveldbStateStoreService.java:350)\n\tat org.apache.hadoop.yarn.server.nodemanager.recovery.NMLeveldbStateStoreService.loadContainersState(NMLeveldbStateStoreService.java:253)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.recover(ContainerManagerImpl.java:365)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:316)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:464)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:899)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:960)\n```"
    },
    {
        "filename": "YARN-8403.json",
        "creation_time": "2018-06-06T22:34:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: Download and unpack failed\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:306)\n        at org.apache.hadoop.yarn.util.FSDownload.verifyAndCopy(FSDownload.java:283)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:409)\n        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:66)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: /grid/0/hadoop/yarn/local/filecache/28_tmp/InputDir/input1.txt (Permission denied)\n        at java.io.FileOutputStream.open0(Native Method)\n        at java.io.FileOutputStream.open(FileOutputStream.java:270)\n        at java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:236)\n        at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)\n        at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)\n        at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)\n        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)\n        at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1149)\n        at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1038)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:408)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:399)\n        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:381)\n        at org.apache.hadoop.yarn.util.FSDownload.downloadAndUnpack(FSDownload.java:298)\n        ... 9 more\n\njava.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\n        ... 5 more\n\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        ... 2 more\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\n        ... 5 more\n\njava.io.IOException: Application application_1528246317583_0048 initialization failed (exitCode=-1) with output: null\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:411)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1229)\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:183)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:402)\n        ... 1 more\nCaused by: java.io.InterruptedIOException: java.lang.InterruptedException\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1012)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        ... 2 more\nCaused by: java.lang.InterruptedException\n        at java.lang.Object.wait(Native Method)\n        at java.lang.Object.wait(Object.java:502)\n        at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1002)\n        ... 5 more\n```"
    },
    {
        "filename": "YARN-1458.json",
        "creation_time": "2013-11-29T03:31:39.000+0000",
        "stack_trace": "```\njava.lang.Thread.State: BLOCKED (on object monitor)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplication(FairScheduler.java:671)\n        - waiting to lock <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1023)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:112)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:440)\n        at java.lang.Thread.run(Thread.java:744)\n\njava.lang.Thread.State: RUNNABLE\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.getAppWeight(FairScheduler.java:545)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.getWeights(AppSchedulable.java:129)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShare(ComputeFairShares.java:143)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.resourceUsedWithWeightToResourceRatio(ComputeFairShares.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.ComputeFairShares.computeShares(ComputeFairShares.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.policies.FairSharePolicy.computeShares(FairSharePolicy.java:119)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.recomputeShares(FSLeafQueue.java:100)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.recomputeShares(FSParentQueue.java:62)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:282)\n        - locked <0x000000070026b6e0> (a org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:255)\n        at java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-8209.json",
        "creation_time": "2018-04-26T00:22:23.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerClient.writeCommandToTempFile(DockerClient.java:109)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeDockerCommand(DockerCommandExecutor.java:85)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.executeStatusCommand(DockerCommandExecutor.java:192)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.docker.DockerCommandExecutor.getContainerStatus(DockerCommandExecutor.java:128)\n\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.removeDockerContainer(LinuxContainerExecutor.java:935)\n\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.deletion.task.DockerContainerDeletionTask.run(DockerContainerDeletionTask.java:61)\n\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-3804.json",
        "creation_time": "2015-06-15T08:54:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:645)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:518)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Can not execute refreshAdminAcls\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:297)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.yarn.exceptions.YarnException: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:230)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAdminAcls(AdminService.java:465)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:295)\n        ... 5 more\nCaused by: org.apache.hadoop.security.AccessControlException: User yarn doesn't have permission to call 'refreshAdminAcls'\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:182)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.verifyAdminAccess(RMServerUtils.java:148)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAccess(AdminService.java:223)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.checkAcls(AdminService.java:228)\n        ... 7 more\n```"
    },
    {
        "filename": "YARN-1839.json",
        "creation_time": "2014-03-14T23:52:29.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.token.SecretManager$InvalidToken: No NMToken sent for <host>:45454\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.newProxy(ContainerManagementProtocolProxy.java:206)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy$ContainerManagementProtocolProxyData.<init>(ContainerManagementProtocolProxy.java:196)\n\tat org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(ContainerManagementProtocolProxy.java:117)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:403)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:138)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:369)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:722)\n```"
    },
    {
        "filename": "YARN-6714.json",
        "creation_time": "2017-06-15T09:56:15.000+0000",
        "stack_trace": "```\njava.lang.IllegalStateException: Trying to unreserve  for application appattempt_1495188831758_0121_000002 when currently reserved  for application application_1495188831758_0121 on node host: node1:45454 #containers=2 available=... used=...\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.unreserveResource(FiCaSchedulerNode.java:123)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.unreserve(FiCaSchedulerApp.java:845)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1787)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1957)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:586)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplicationAttempt(CapacityScheduler.java:966)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1740)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:152)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:822)\n        at java.lang.Thread.run(Thread.java:834)\n```"
    },
    {
        "filename": "YARN-3351.json",
        "creation_time": "2015-03-16T14:19:59.000+0000",
        "stack_trace": "```\njava.net.BindException: Cannot assign requested address\n\tat java.net.PlainSocketImpl.socketBind(Native Method)\n\tat java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)\n\tat java.net.Socket.bind(Socket.java:631)\n\tat java.net.Socket.<init>(Socket.java:423)\n\tat java.net.Socket.<init>(Socket.java:280)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)\n\tat org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:122)\n\tat org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:707)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)\n\tat org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)\n\tat org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:346)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:188)\n\tat org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:345)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)\n```"
    },
    {
        "filename": "YARN-2813.json",
        "creation_time": "2014-11-05T22:29:46.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:356)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n        at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:96)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:572)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:269)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:542)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1204)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:326)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n        at org.mortbay.jetty.security.SslSocketConnector$SslConnection.run(SslSocketConnector.java:713)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore.getDomains(MemoryTimelineStore.java:244)\n        at org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getDomains(TimelineDataManager.java:383)\n        at org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getDomains(TimelineWebServices.java:353)\n        ... 54 more\n```"
    },
    {
        "filename": "YARN-1550.json",
        "creation_time": "2013-12-30T03:58:32.000+0000",
        "stack_trace": "```\njava.lang.reflect.InvocationTargetException\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        ....\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render(FairSchedulerAppsBlock.java:96)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:66)\n\tat org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:76)\n```"
    },
    {
        "filename": "YARN-5006.json",
        "creation_time": "2016-04-28T08:26:38.000+0000",
        "stack_trace": "```\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n```"
    },
    {
        "filename": "YARN-5728.json",
        "creation_time": "2016-10-13T05:16:28.000+0000",
        "stack_trace": "```\njava.lang.Exception: test timed out after 60000 milliseconds\n\tat java.lang.Thread.sleep(Native Method)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:130)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335)\n\tat com.sun.proxy.$Proxy85.nodeHeartbeat(Unknown Source)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:113)\n```"
    },
    {
        "filename": "YARN-2805.json",
        "creation_time": "2014-11-04T20:37:09.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to login\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:211)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1229)\nCaused by: java.io.IOException: Login failure for rm/IP@EXAMPLE.COM from keytab /etc/security/keytabs/rm.service.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user\n\n\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:935)\n```"
    },
    {
        "filename": "YARN-4744.json",
        "creation_time": "2016-02-29T10:08:57.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=9:\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:173)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.signalContainer(DefaultLinuxContainerRuntime.java:132)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.signalContainer(DelegatingLinuxContainerRuntime.java:109)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.signalContainer(LinuxContainerExecutor.java:513)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.cleanupContainer(ContainerLaunch.java:520)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:139)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncher.java:55)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: ExitCodeException exitCode=9:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:927)\n        at org.apache.hadoop.util.Shell.run(Shell.java:838)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:150)\n        ... 9 more\n```"
    },
    {
        "filename": "YARN-1752.json",
        "creation_time": "2014-02-22T05:51:42.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: UNREGISTERED at LAUNCHED\n  at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n  at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n  at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:647)\n  at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:103)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n  at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:714)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n  at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n  at java.lang.Thread.run(Thread.java:695)\n```"
    },
    {
        "filename": "YARN-6629.json",
        "creation_time": "2017-05-22T08:31:16.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:446)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.apply(FiCaSchedulerApp.java:516)\n        at org.apache.hadoop.yarn.client.TestNegativePendingResource$1.answer(TestNegativePendingResource.java:225)\n        at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)\n        at org.mockito.internal.MockHandler.handle(MockHandler.java:97)\n        at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp$$EnhancerByMockitoWithCGLIB$$29eb8afc.apply(<generated>)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.tryCommit(CapacityScheduler.java:2396)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.submitResourceCommitRequest(CapacityScheduler.java:2281)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1247)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1236)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1325)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1112)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:987)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1367)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:143)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-3493.json",
        "creation_time": "2015-04-15T22:03:19.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n\norg.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested memory < 0, or requested memory > max configured, requestedMemory=3072, maxMemory=2048\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:204)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.validateAndCreateResourceRequest(RMAppManager.java:385)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:317)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:422)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1187)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:574)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.serviceStop(AsyncDispatcher.java:142)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStop(ResourceManager.java:601)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:203)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:994)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1035)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1031)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1031)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:1071)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:1208)\n```"
    },
    {
        "filename": "YARN-7645.json",
        "creation_time": "2017-12-12T21:19:53.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: Attempt state is not correct (timeout). expected:<ALLOCATED> but was:<SCHEDULED>\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.amRestartTests(TestContainerResourceUsage.java:275)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestContainerResourceUsage.testUsageAfterAMRestartWithMultipleContainers(TestContainerResourceUsage.java:254)\n```"
    },
    {
        "filename": "YARN-6054.json",
        "creation_time": "2017-01-04T20:58:59.000+0000",
        "stack_trace": "```\norg.apache.hadoop.service.ServiceStateException: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)\n        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.serviceInit(ApplicationHistoryServer.java:104)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.launchAppHistoryServer(ApplicationHistoryServer.java:172)\n        at org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryServer.main(ApplicationHistoryServer.java:182)\nCaused by: org.fusesource.leveldbjni.internal.NativeDB$DBException: Corruption: 9 missing files; e.g.: <levelDbStorePath>/timelineserver/leveldb-timeline-store.ldb/127897.sst\n        at org.fusesource.leveldbjni.internal.NativeDB.checkStatus(NativeDB.java:200)\n        at org.fusesource.leveldbjni.internal.NativeDB.open(NativeDB.java:218)\n        at org.fusesource.leveldbjni.JniDBFactory.open(JniDBFactory.java:168)\n        at org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore.serviceInit(LeveldbTimelineStore.java:229)\n        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n        ... 5 more\n```"
    },
    {
        "filename": "YARN-196.json",
        "creation_time": "2012-01-16T09:52:45.000+0000",
        "stack_trace": "```\norg.apache.avro.AvroRuntimeException: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:149)\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:167)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:242)\nCaused by: java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:66)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:182)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:145)\n\t... 3 more\nCaused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:131)\n\tat $Proxy23.registerNodeManager(Unknown Source)\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)\n\t... 5 more\nCaused by: java.net.ConnectException: Call From HOST-10-18-52-230/10.18.52.230 to HOST-10-18-52-250:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:857)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1141)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1100)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:128)\n\t... 7 more\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:659)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:469)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:563)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:211)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1247)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1117)\n\t... 9 more\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:358)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:76)\n\tat java.lang.Thread.run(Thread.java:619)\n```"
    },
    {
        "filename": "YARN-8508.json",
        "creation_time": "2018-07-09T23:37:49.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\njava.io.IOException: ResourceHandlerChain.preStart() failed!\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:551)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:479)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:494)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:306)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:103)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerException: Failed to find enough GPUs, requestor=container_e20_1530854311763_0007_01_000002, #RequestedGPUs=2, #availableGpus=1\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.internalAssignGpus(GpuResourceAllocator.java:225)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceAllocator.assignGpus(GpuResourceAllocator.java:173)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.gpu.GpuResourceHandlerImpl.preStart(GpuResourceHandlerImpl.java:98)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.ResourceHandlerChain.preStart(ResourceHandlerChain.java:75)\n\tat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.handleLaunchForLaunchType(LinuxContainerExecutor.java:509)\n\t... 8 more\n```"
    },
    {
        "filename": "YARN-2308.json",
        "creation_time": "2014-07-17T10:01:57.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:566)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:922)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:98)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:594)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:654)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:698)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:682)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-933.json",
        "creation_time": "2013-07-17T12:29:28.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: LAUNCH_FAILED at FAILED\n at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:630)\n at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:99)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:495)\n at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:476)\n at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)\n at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n at java.lang.Thread.run(Thread.java:662)\n\nCaused by: org.apache.hadoop.net.ConnectTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=host-10-18-40-15/10.18.40.59:8020]\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:573)\n at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:534)\n```"
    },
    {
        "filename": "YARN-1374.json",
        "creation_time": "2013-10-30T11:49:49.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n\njava.util.ConcurrentModificationException\n\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n\tat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:187)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:944)\n```"
    },
    {
        "filename": "YARN-174.json",
        "creation_time": "2012-10-19T17:25:40.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.YarnException: ${yarn.log.dir}/userlogs is not a valid path. Path should be with file scheme or without scheme\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.validatePaths(LocalDirsHandlerService.java:321)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService$MonitoringTimerTask.<init>(LocalDirsHandlerService.java:95)\n        at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.init(LocalDirsHandlerService.java:123)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeHealthCheckerService.init(NodeHealthCheckerService.java:48)\n        at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:165)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:274)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stateChanged(NodeManager.java:256)\n        at org.apache.hadoop.yarn.service.AbstractService.changeState(AbstractService.java:163)\n        at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:112)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.reboot(NodeStatusUpdaterImpl.java:157)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.access$900(NodeStatusUpdaterImpl.java:63)\n        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run(NodeStatusUpdaterImpl.java:357)\n```"
    },
    {
        "filename": "YARN-6448.json",
        "creation_time": "2017-04-05T18:39:49.000+0000",
        "stack_trace": "```\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n        at java.util.TimSort.mergeHi(TimSort.java:899)\n        at java.util.TimSort.mergeAt(TimSort.java:516)\n        at java.util.TimSort.mergeForceCollapse(TimSort.java:457)\n        at java.util.TimSort.sort(TimSort.java:254)\n        at java.util.Arrays.sort(Arrays.java:1512)\n        at java.util.ArrayList.sort(ArrayList.java:1454)\n        at java.util.Collections.sort(Collections.java:175)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.ClusterNodeTracker.sortedNodeList(ClusterNodeTracker.java:306)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingAttempt(FairScheduler.java:884)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$ContinuousSchedulingThread.run(FairScheduler.java:316)\n```"
    },
    {
        "filename": "YARN-4530.json",
        "creation_time": "2015-12-30T15:19:19.000+0000",
        "stack_trace": "```\njava.io.IOException: Resource hdfs://ns3/user/username/projects/user_insight/lookalike/oozie/workflow/lib/unilever_support_udf-0.0.1-SNAPSHOT.jar changed on src filesystem (expected 1451380519452, was 1451380611793\n\tat org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:176)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:276)\n\tat org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:50)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$PublicLocalizer.run(ResourceLocalizationService.java:712)\n```"
    },
    {
        "filename": "YARN-7737.json",
        "creation_time": "2018-01-11T19:35:01.000+0000",
        "stack_trace": "```\njava.io.FileNotFoundException: File /grid/b/tmp/userlogs/application_1515190594800_1766/container_e39_1515190594800_1766_01_000002/prelaunch.err does not exist\n        at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:641)\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:930)\n        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitWithFailure(ContainerLaunch.java:545)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.handleContainerExitCode(ContainerLaunch.java:511)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:319)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:93)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-5136.json",
        "creation_time": "2016-05-24T15:34:28.000+0000",
        "stack_trace": "```\njava.lang.IllegalStateException: Given app to remove org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt@ea94c3b does not exist in queue [root.bdp_xx.bdp_mart_xx_formal, demand=<memory:28672000, vCores:14000>, running=<memory:28647424, vCores:13422>, share=<memory:28672000, vCores:0>, w=<memory weight=1.0, cpu weight=1.0>]\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.removeApp(FSLeafQueue.java:119)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.removeApplicationAttempt(FairScheduler.java:779)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1231)\n    at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:114)\n    at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:680)\n    at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-8211.json",
        "creation_time": "2018-04-26T02:13:22.000+0000",
        "stack_trace": "```\njava.nio.BufferUnderflowException\n\n        at java.nio.Buffer.nextGetIndex(Buffer.java:500)\n\n        at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:135)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS.getMessgeLength(RegistryDNS.java:820)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS.nioTCPClient(RegistryDNS.java:767)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:846)\n\n        at org.apache.hadoop.registry.server.dns.RegistryDNS$3.call(RegistryDNS.java:843)\n\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-2124.json",
        "creation_time": "2014-06-05T07:44:27.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.util.resource.Resources.greaterThan(Resources.java:225)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.computeIdealResourceDistribution(ProportionalCapacityPreemptionPolicy.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.recursivelyComputeIdealAssignment(ProportionalCapacityPreemptionPolicy.java:261)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill(ProportionalCapacityPreemptionPolicy.java:198)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.editSchedule(ProportionalCapacityPreemptionPolicy.java:174)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor.invokePolicy(SchedulingMonitor.java:72)\n        at org.apache.hadoop.yarn.server.resourcemanager.monitor.SchedulingMonitor$PreemptionChecker.run(SchedulingMonitor.java:82)\n        at java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-7849.json",
        "creation_time": "2018-01-29T23:49:33.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: Containers Utillization not propagated to RMNode expected:<<pmem:1024, vmem:2048, vCores:11.0>> but was:<null>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.verifySimulatedUtilization(TestMiniYarnClusterNodeUtilization.java:227)\n\tat org.apache.hadoop.yarn.server.TestMiniYarnClusterNodeUtilization.testUpdateNodeUtilization(TestMiniYarnClusterNodeUtilization.java:116)\n```"
    },
    {
        "filename": "YARN-8591.json",
        "creation_time": "2018-07-27T05:56:26.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.handleException(TimelineReaderWebServices.java:196)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:624)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:474)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)\n        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)\n        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n        at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.security.TimelineReaderWhitelistAuthorizationFilter.doFilter(TimelineReaderWhitelistAuthorizationFilter.java:85)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)\n        at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:98)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1604)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccess(TimelineReaderWebServices.java:3536)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.checkAccessForGenericEntities(TimelineReaderWebServices.java:3513)\n        at org.apache.hadoop.yarn.server.timelineservice.reader.TimelineReaderWebServices.getEntities(TimelineReaderWebServices.java:622)\n```"
    },
    {
        "filename": "YARN-6649.json",
        "creation_time": "2017-05-25T20:36:08.000+0000",
        "stack_trace": "```\njavax.ws.rs.WebApplicationException: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:164)\n\tat sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n\tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:636)\n\tat org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:294)\n\tat org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:588)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.security.http.CrossOriginFilter.doFilter(CrossOriginFilter.java:95)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1352)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.util.FSTUtil.rethrow(FSTUtil.java:122)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:879)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:478)\n\tat org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore.getEntity(RollingLevelDBTimelineStore.java:414)\n\tat org.apache.hadoop.yarn.server.timeline.EntityFileTimelineStore.getEntity(EntityFileTimelineStore.java:911)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.doGetEntity(TimelineDataManager.java:215)\n\tat org.apache.hadoop.yarn.server.timeline.TimelineDataManager.getEntity(TimelineDataManager.java:202)\n\tat org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices.getEntity(TimelineWebServices.java:155)\n\t... 52 more\nCaused by: java.io.IOException: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:240)\n\tat org.nustaq.serialization.FSTConfiguration.asObject(FSTConfiguration.java:877)\n\t... 58 more\nCaused by: java.lang.RuntimeException: unable to encodeValue class from code 1000\n\tat org.nustaq.serialization.FSTClazzNameRegistry.decodeClass(FSTClazzNameRegistry.java:173)\n\tat org.nustaq.serialization.coders.FSTStreamDecoder.readClass(FSTStreamDecoder.java:431)\n\tat org.nustaq.serialization.FSTObjectInput.readClass(FSTObjectInput.java:853)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:338)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.serializers.FSTArrayListSerializer.instantiate(FSTArrayListSerializer.java:63)\n\tat org.nustaq.serialization.FSTObjectInput.instantiateAndReadWithSer(FSTObjectInput.java:459)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:354)\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:323)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:304)\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:238)\n\t... 59 more\n```"
    },
    {
        "filename": "YARN-3742.json",
        "creation_time": "2015-05-29T06:00:38.000+0000",
        "stack_trace": "```\njava.io.IOException: Wait for ZKClient creation timed out\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1066)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1090)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.existsWithRetries(ZKRMStateStore.java:996)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.updateApplicationStateInternal(ZKRMStateStore.java:643)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:162)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$UpdateAppTransition.transition(RMStateStore.java:147)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:879)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:874)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-4984.json",
        "creation_time": "2016-04-21T19:16:03.000+0000",
        "stack_trace": "```\nException is:\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (HDFS_DELEGATION_TOKEN token 1380589 for hdfswrite) can't be found in cache\n    at org.apache.hadoop.ipc.Client.call(Client.java:1427)\n    at org.apache.hadoop.ipc.Client.call(Client.java:1358)\n    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n    at com.sun.proxy.$Proxy13.getFileInfo(Unknown Source)\n    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:771)\n    at sun.reflect.GeneratedMethodAccessor76.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:252)\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)\n    at com.sun.proxy.$Proxy14.getFileInfo(Unknown Source)\n    at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:2116)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1315)\n    at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1311)\n    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n    at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1311)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.checkExists(LogAggregationService.java:248)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.access$100(LogAggregationService.java:67)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:276)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at javax.security.auth.Subject.doAs(Subject.java:415)\n    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.createAppDir(LogAggregationService.java:261)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initAppAggregator(LogAggregationService.java:367)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.initApp(LogAggregationService.java:320)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:447)\n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogAggregationService.java:67)\n```"
    },
    {
        "filename": "YARN-4584.json",
        "creation_time": "2016-01-12T09:08:31.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.recover(RMAppAttemptImpl.java:887)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recover(RMAppImpl.java:826)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:953)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:946)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:786)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:328)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:464)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1232)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:594)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1022)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1062)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1058)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1705)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1058)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:323)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:127)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:877)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n```"
    },
    {
        "filename": "YARN-2846.json",
        "creation_time": "2014-11-11T15:30:08.000+0000",
        "stack_trace": "```\njava.io.IOException: Interrupted while waiting for process 20001 to exit\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:180)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:82)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.RecoveredContainerLaunch.call(RecoveredContainerLaunch.java:46)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.InterruptedException: sleep interrupted\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.reacquireContainer(ContainerExecutor.java:177)\n        ... 6 more\n```"
    },
    {
        "filename": "YARN-7890.json",
        "creation_time": "2018-02-03T21:10:43.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at java.util.Collections$UnmodifiableCollection.<init>(Collections.java:1026)\n        at java.util.Collections$UnmodifiableList.<init>(Collections.java:1302)\n        at java.util.Collections.unmodifiableList(Collections.java:1287)\n        at org.apache.hadoop.yarn.server.nodemanager.executor.ContainerStartContext.getFilecacheDirs(ContainerStartContext.java:200)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.buildContainerRuntimeContext(LinuxContainerExecutor.java:651)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:546)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:107)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerRelaunch.call(ContainerRelaunch.java:49)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-139.json",
        "creation_time": "2012-10-01T19:51:20.000+0000",
        "stack_trace": "```\njava.lang.InterruptedException\n\tat java.lang.Object.wait(Native Method)\n\tat java.lang.Thread.join(Thread.java:1143)\n\tat java.lang.Thread.join(Thread.java:1196)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.stop(AsyncDispatcher.java:105)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:437)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:402)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:619)\n```"
    },
    {
        "filename": "YARN-42.json",
        "creation_time": "2012-05-14T11:38:55.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.YarnException: Failed to initialize LocalizationService\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:202)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.init(ContainerManagerImpl.java:183)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.init(NodeManager.java:166)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:268)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:284)\nCaused by: java.io.IOException: mkdir of /mrv2/tmp/nm-local-dir/usercache failed\n\tat org.apache.hadoop.fs.FileSystem.primitiveMkdir(FileSystem.java:907)\n\tat org.apache.hadoop.fs.DelegateToFileSystem.mkdir(DelegateToFileSystem.java:143)\n\tat org.apache.hadoop.fs.FilterFs.mkdir(FilterFs.java:189)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:706)\n\tat org.apache.hadoop.fs.FileContext$4.next(FileContext.java:703)\n\tat org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2325)\n\tat org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:703)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(ResourceLocalizationService.java:188)\n\t... 6 more\n\njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.stop(NonAggregatingLogHandler.java:82)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stop(ContainerManagerImpl.java:266)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:99)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:89)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:182)\n\tat org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:122)\n\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)\n```"
    },
    {
        "filename": "YARN-7453.json",
        "creation_time": "2017-11-07T09:46:28.000+0000",
        "stack_trace": "```\norg.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:113)\n\tat org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:1006)\n\tat org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:910)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.doOperation(CuratorTransactionImpl.java:159)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.access$200(CuratorTransactionImpl.java:44)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:129)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl$2.call(CuratorTransactionImpl.java:125)\n\tat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:109)\n\tat org.apache.curator.framework.imps.CuratorTransactionImpl.commit(CuratorTransactionImpl.java:122)\n\tat org.apache.hadoop.util.curator.ZKCuratorManager$SafeTransaction.commit(ZKCuratorManager.java:403)\n\tat org.apache.hadoop.util.curator.ZKCuratorManager.safeSetData(ZKCuratorManager.java:372)\n\tat org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.getAndIncrementEpoch(ZKRMStateStore.java:493)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:771)\n\tat org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1162)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1202)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1198)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.transitionToActive(ResourceManager.java:1198)\n\tat org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:320)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:894)\n\tat org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:473)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:607)\n\tat org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:505)\n```"
    },
    {
        "filename": "YARN-3369.json",
        "creation_time": "2015-03-18T23:29:06.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.checkForDeactivation(AppSchedulingInfo.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.decrementOutstanding(AppSchedulingInfo.java:375)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateOffSwitch(AppSchedulingInfo.java:360)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:270)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:142)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignOffSwitchContainers(LeafQueue.java:1384)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1263)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:816)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:588)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:449)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1017)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1059)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:114)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:739)\n        at java.lang.Thread.run(Thread.java:722)\n```"
    },
    {
        "filename": "YARN-945.json",
        "creation_time": "2013-07-19T22:59:06.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN]\n   at org.apache.hadoop.ipc.Server$Connection.initializeAuthContext(Server.java:1531)\n   at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1482)\n   at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:788)\n   at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:587)\n   at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:562)\n```"
    },
    {
        "filename": "YARN-6072.json",
        "creation_time": "2017-01-08T09:21:12.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:569)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshServiceAcls(AdminService.java:552)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:707)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\norg.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:144)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:888)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:467)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\n\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error on refreshAll during transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:311)\n        at org.apache.hadoop.yarn.server.resourcemanager.ActiveStandbyElectorBasedElectorService.becomeActive(ActiveStandbyElectorBasedElectorService.java:142)\n        ... 4 more\n\nCaused by: org.apache.hadoop.ha.ServiceFailedException\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:712)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:302)\n        ... 5 more\n```"
    },
    {
        "filename": "YARN-7663.json",
        "creation_time": "2017-12-15T01:52:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: START at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:805)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:116)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:901)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:885)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-5873.json",
        "creation_time": "2016-11-12T09:54:20.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.WritingContainerStartEvent.hashCode(WritingContainerStartEvent.java:38)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter$MultiThreadedDispatcher$CompositEventHandler.handle(RMApplicationHistoryWriter.java:354)\n        at org.apache.hadoop.yarn.server.resourcemanager.ahs.RMApplicationHistoryWriter.containerStarted(RMApplicationHistoryWriter.java:278)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:251)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl.<init>(RMContainerImpl.java:210)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.allocate(FiCaSchedulerApp.java:227)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.handleNewContainerAllocation(RegularContainerAllocator.java:704)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.doAllocation(RegularContainerAllocator.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.allocate(RegularContainerAllocator.java:832)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.allocator.RegularContainerAllocator.assignContainers(RegularContainerAllocator.java:865)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp.assignContainers(FiCaSchedulerApp.java:931)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:1044)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:690)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:508)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateOrReserveNewContainers(CapacityScheduler.java:1475)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainerOnSingleNode(CapacityScheduler.java:1470)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1559)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocateContainersToNode(CapacityScheduler.java:1346)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:1221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1601)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:149)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-3227.json",
        "creation_time": "2015-02-19T16:58:01.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed to renew token: Kind: TIMELINE_DELEGATION_TOKEN,\nService: timelineserver.example.com:4080, Ident: (owner=user,\nrenewer=rmuser, realUser=oozie, issueDate=1423248845528,\nmaxDate=1423853645528, sequenceNumber=9716, masterKeyId=9)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.handleAppSubmitEvent(DelegationTokenRenewer.java:443)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.access$800(DelegationTokenRenewer.java:77)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.handleDTRenewerAppSubmitEvent(DelegationTokenRenewer.java:808)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable.run(DelegationTokenRenewer.java:789)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: HTTP status [401], message [Unauthorized]\n        at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:169)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.doDelegationTokenOperation(DelegationTokenAuthenticator.java:286)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator.renewDelegationToken(DelegationTokenAuthenticator.java:211)\n        at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.renewDelegationToken(DelegationTokenAuthenticatedURL.java:414)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:374)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$2.run(TimelineClientImpl.java:360)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$4.run(TimelineClientImpl.java:429)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl$TimelineClientConnectionRetry.retryOn(TimelineClientImpl.java:161)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.operateDelegationToken(TimelineClientImpl.java:444)\n        at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.renewDelegationToken(TimelineClientImpl.java:378)\n        at org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier$Renewer.renew(TimelineDelegationTokenIdentifier.java:81)\n        at org.apache.hadoop.security.token.Token.renew(Token.java:377)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:532)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:529)\n```"
    },
    {
        "filename": "YARN-4235.json",
        "creation_time": "2015-10-07T19:26:24.000+0000",
        "stack_trace": "```\njava.lang.IndexOutOfBoundsException: Index: 0\n\tat java.util.Collections$EmptyList.get(Collections.java:3212)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule$PrimaryGroup.getQueueForApp(QueuePlacementRule.java:149)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementRule.assignAppToQueue(QueuePlacementRule.java:74)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.QueuePlacementPolicy.assignAppToQueue(QueuePlacementPolicy.java:167)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignToQueue(FairScheduler.java:689)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.addApplication(FairScheduler.java:595)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1180)\n\tat org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:111)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:684)\n\tat java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-4833.json",
        "creation_time": "2016-03-17T13:22:23.000+0000",
        "stack_trace": "```\norg.apache.hadoop.security.AccessControlException: User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.submitApplication:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateIOException(RPCUtil.java:80)\n        at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:119)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:272)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.java:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.java:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.java:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:136)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): User hdfs does not have permission to submit application_1458273884145_0001 to queue default\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.createAndPopulateNewRMApp(RMAppManager.java:380)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.submitApplication:618)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:252)\n        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2360)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2356)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2356)\n\n        at org.apache.hadoop.ipc.Client.call(Client.java:1449)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine$Invoker.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        ... 35 more\n\njava.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.connect:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1425)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1386)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine$Invoker.java:230)\n        at com.sun.proxy.$Proxy22.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.submitApplication(ApplicationClientProtocolPBClientImpl.java:269)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:257)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)\n        at com.sun.proxy.$Proxy23.submitApplication(Unknown Source)\n        at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(YarnClientImpl.submitApplication:261)\n        at org.apache.hadoop.mapred.ResourceMgrDelegate.submitApplication(ResourceMgrDelegate.submitApplication:295)\n        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.submitJob:301)\n        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.submitJobInternal:244)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)\n        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.run(ToolRunner.java:76)\n        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.main:74)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(Native Method)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at org.apache.hadoop.util.RunJar.run(RunJar.run:222)\n        at org.apache.hadoop.util.RunJar.main(RunJar.main:136)\nCaused by: java.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.connect:206)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)\n        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)\n        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:634)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:733)\n        at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:378)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1510)\n        ... 39 more\n```"
    },
    {
        "filename": "YARN-1689.json",
        "creation_time": "2014-02-05T19:16:00.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:48)\n        at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:278)\n        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.registerApplicationMaster(ApplicationMasterProtocolPBServiceImpl.java:90)\n        at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:95)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: ATTEMPT_REGISTERED at KILLED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:624)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:81)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:656)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher.handle(ResourceManager.java:640)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-5594.json",
        "creation_time": "2016-08-30T15:14:19.000+0000",
        "stack_trace": "```\ncom.google.protobuf.InvalidProtocolBufferException: Protocol message contained\nan invalid tag (zero).\nat com.google.protobuf.InvalidProtocolBufferException.invalidTag(InvalidProtocolBufferException.java:89)\nat com.google.protobuf.CodedInputStream.readTag(CodedInputStream.java:108)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4680)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto.<init>(YarnServerResourceManagerRecoveryProtos.java:4644)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4740)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$1.parsePartialFrom(YarnServerResourceManagerRecoveryProtos.java:4735)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:5075)\nat org.apache.hadoop.yarn.proto.YarnServerResourceManagerRecoveryProtos$RMDelegationTokenIdentifierDataProto$Builder.mergeFrom(YarnServerResourceManagerRecoveryProtos.java:4955)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:337)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:267)\nat com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:210)\nat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:904)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.records.RMDelegationTokenIdentifierData.readFields(RMDelegationTokenIdentifierData.java:43)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadRMDTSecretManagerState(FileSystemRMStateStore.java:355)\nat org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.loadState(FileSystemRMStateStore.java:199)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:587)\nat org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1007)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1048)\nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1044)\n```"
    },
    {
        "filename": "YARN-7511.json",
        "creation_time": "2017-11-16T11:41:43.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at java.util.concurrent.ConcurrentHashMap.replaceNode(ConcurrentHashMap.java:1106)\n        at java.util.concurrent.ConcurrentHashMap.remove(ConcurrentHashMap.java:1097)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceSet.resourceLocalizationFailed(ResourceSet.java:151)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:821)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$ResourceLocalizationFailedWhileRunningTransition.transition(ContainerImpl.java:813)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1335)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:95)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1372)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1365)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:834)\n```"
    },
    {
        "filename": "YARN-3790.json",
        "creation_time": "2015-06-10T04:53:40.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: expected:<6144> but was:<8192>\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.failNotEquals(Assert.java:743)\n\tat org.junit.Assert.assertEquals(Assert.java:118)\n\tat org.junit.Assert.assertEquals(Assert.java:555)\n\tat org.junit.Assert.assertEquals(Assert.java:542)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.assertMetrics(TestWorkPreservingRMRestart.java:853)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.checkFSQueue(TestWorkPreservingRMRestart.java:342)\n\tat org.apache.hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart.testSchedulerRecovery(TestWorkPreservingRMRestart.java:241)\n```"
    },
    {
        "filename": "YARN-6068.json",
        "creation_time": "2017-01-07T03:16:07.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FAILED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:459)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:64)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1084)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:1076)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\n        at java.lang.Thread.run(Thread.java:745)\n```"
    },
    {
        "filename": "YARN-903.json",
        "creation_time": "2013-07-07T08:35:30.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000002 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n\norg.apache.hadoop.yarn.exceptions.YarnException: Container container_1373184544832_0001_01_000001 is not handled by this NodeManager\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:45)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.authorizeGetAndStopContainerRequest(ContainerManagerImpl.java:614)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.stopContainer(ContainerManagerImpl.java:538)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagementProtocolPBServiceImpl.stopContainer(ContainerManagementProtocolPBServiceImpl.java:88)\n\tat org.apache.hadoop.yarn.proto.ContainerManagementProtocol$ContainerManagementProtocolService$2.callBlockingMethod(ContainerManagementProtocol.java:85)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:605)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1033)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1868)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1864)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1862)\n\njava.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1934)\n\tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)\n\tat org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$CallbackHandlerThread.run(AMRMClientAsyncImpl.java:281)\n```"
    },
    {
        "filename": "YARN-8236.json",
        "creation_time": "2018-04-29T16:28:11.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\nat org.apache.hadoop.yarn.service.client.ServiceClient.addKeytabResourceIfSecure(ServiceClient.java:994)\nat org.apache.hadoop.yarn.service.client.ServiceClient.submitApp(ServiceClient.java:685)\nat org.apache.hadoop.yarn.service.client.ServiceClient.actionCreate(ServiceClient.java:269)\n```"
    },
    {
        "filename": "YARN-2857.json",
        "creation_time": "2014-10-24T20:47:51.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n\tat java.util.LinkedList$ListItr.checkForComodification(LinkedList.java:966)\n\tat java.util.LinkedList$ListItr.next(LinkedList.java:888)\n\tat org.apache.hadoop.yarn.ContainerLogAppender.close(ContainerLogAppender.java:94)\n\tat org.apache.log4j.helpers.AppenderAttachableImpl.removeAllAppenders(AppenderAttachableImpl.java:141)\n\tat org.apache.log4j.Category.removeAllAppenders(Category.java:891)\n\tat org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:759)\n\tat org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648)\n\tat org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514)\n\tat org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440)\n\tat org.apache.pig.Main.configureLog4J(Main.java:740)\n\tat org.apache.pig.Main.run(Main.java:384)\n\tat org.apache.pig.PigRunner.run(PigRunner.java:49)\n\tat org.apache.oozie.action.hadoop.PigMain.runPigJob(PigMain.java:283)\n\tat org.apache.oozie.action.hadoop.PigMain.run(PigMain.java:223)\n\tat org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:37)\n\tat org.apache.oozie.action.hadoop.PigMain.main(PigMain.java:76)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:226)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n```"
    },
    {
        "filename": "YARN-2416.json",
        "creation_time": "2014-08-13T22:36:31.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: REGISTERED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: STATUS_UPDATE at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_ALLOCATED at ALLOCATED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:652)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:752)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher.handle(ResourceManager.java:733)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:744)\n```"
    },
    {
        "filename": "YARN-345.json",
        "creation_time": "2013-01-17T12:57:46.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at APPLICATION_RESOURCES_CLEANINGUP\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: FINISH_APPLICATION at FINISHING_CONTAINERS_WAIT\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_CONTAINER_FINISHED at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: INIT_CONTAINER at FINISHED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:398)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:520)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:512)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-3894.json",
        "creation_time": "2015-07-08T07:00:51.000+0000",
        "stack_trace": "```\njava.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:383)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues(AdminService.java:376)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:605)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: java.lang.IllegalArgumentException: Illegal capacity of 0.5 for children of queue root for label=node2\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setChildQueues(ParentQueue.java:159)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:639)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitializeQueues(CapacityScheduler.java:503)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:379)\n        ... 8 more\n\norg.apache.hadoop.ha.ServiceFailedException: RM could not transition to Active\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:128)\n        at org.apache.hadoop.ha.ActiveStandbyElector.becomeActive(ActiveStandbyElector.java:824)\n        at org.apache.hadoop.ha.ActiveStandbyElector.processResult(ActiveStandbyElector.java:420)\n        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)\n        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)\nCaused by: org.apache.hadoop.ha.ServiceFailedException: Error when transitioning to Active mode\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:321)\n        at org.apache.hadoop.yarn.server.resourcemanager.EmbeddedElectorService.becomeActive(EmbeddedElectorService.java:126)\n        ... 4 more\nCaused by: org.apache.hadoop.ha.ServiceFailedException: java.io.IOException: Failed to re-init queues\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshAll(AdminService.java:617)\n        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.transitionToActive(AdminService.java:314)\n        ... 5 more\n```"
    },
    {
        "filename": "YARN-1903.json",
        "creation_time": "2014-04-04T20:51:24.000+0000",
        "stack_trace": "```\njava.lang.AssertionError: 4: \n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testGetContainerStatus(TestNMClient.java:382)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testContainerManagement(TestNMClient.java:346)\n\tat org.apache.hadoop.yarn.client.api.impl.TestNMClient.testNMClient(TestNMClient.java:226)\n```"
    },
    {
        "filename": "YARN-4347.json",
        "creation_time": "2015-11-11T22:32:59.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addApplicationAttempt(CapacityScheduler.java:746)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1155)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:116)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1037)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl$AttemptRecoveredTransition.transition(RMAppAttemptImpl.java:1001)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:755)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.handle(RMAppAttemptImpl.java:106)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.recoverAppAttempts(RMAppImpl.java:839)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.access$1900(RMAppImpl.java:102)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:854)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$RMAppRecoveredTransition.transition(RMAppImpl.java:844)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.handle(RMAppImpl.java:719)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recoverApplication(RMAppManager.java:313)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:411)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:1219)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceStart(ResourceManager.java:593)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startActiveServices(ResourceManager.java:1026)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1067)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$1.run(ResourceManager.java:1063)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n```"
    },
    {
        "filename": "YARN-1692.json",
        "creation_time": "2014-02-07T02:01:17.000+0000",
        "stack_trace": "```\njava.util.ConcurrentModificationException\n        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)\n        at java.util.HashMap$ValueIterator.next(HashMap.java:954)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AppSchedulable.updateDemand(AppSchedulable.java:85)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.updateDemand(FSLeafQueue.java:125)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.updateDemand(FSParentQueue.java:82)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.update(FairScheduler.java:217)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler$UpdateThread.run(FairScheduler.java:195)\n        at java.lang.Thread.run(Thread.java:724)\n```"
    },
    {
        "filename": "YARN-7697.json",
        "creation_time": "2018-01-03T19:28:50.000+0000",
        "stack_trace": "```\njava.lang.OutOfMemoryError: Java heap space\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:823)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.loadIndexedLogsMeta(LogAggregationIndexedFileController.java:840)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriterInRolling(LogAggregationIndexedFileController.java:293)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.access$600(LogAggregationIndexedFileController.java:98)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController$1.run(LogAggregationIndexedFileController.java:216)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)\n        at org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.initializeWriter(LogAggregationIndexedFileController.java:197)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.uploadLogsForContainers(AppLogAggregatorImpl.java:205)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation(AppLogAggregatorImpl.java:312)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.run(AppLogAggregatorImpl.java:284)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService$1.run(LogAggregationService.java:262)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-7382.json",
        "creation_time": "2017-10-23T23:36:59.000+0000",
        "stack_trace": "```\njava.util.NoSuchElementException\n        at java.util.concurrent.ConcurrentSkipListMap.firstKey(ConcurrentSkipListMap.java:2036)\n        at java.util.concurrent.ConcurrentSkipListSet.first(ConcurrentSkipListSet.java:396)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.getNextPendingAsk(AppSchedulingInfo.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.isOverAMShareLimit(FSAppAttempt.java:901)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSAppAttempt.assignContainer(FSAppAttempt.java:1326)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSLeafQueue.assignContainer(FSLeafQueue.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSParentQueue.assignContainer(FSParentQueue.java:221)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.attemptScheduling(FairScheduler.java:1019)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.nodeUpdate(FairScheduler.java:887)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:1104)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.handle(FairScheduler.java:128)\n        at org.apache.hadoop.yarn.event.EventDispatcher$EventProcessor.run(EventDispatcher.java:66)\n        at java.lang.Thread.run(Thread.java:748)\n```"
    },
    {
        "filename": "YARN-1094.json",
        "creation_time": "2013-08-23T19:06:17.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.setTimerForTokenRenewal(DelegationTokenRenewer.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.addApplication(DelegationTokenRenewer.java:307)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)\n        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.recover(RMAppManager.java:371)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.recover(ResourceManager.java:819)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceStart(ResourceManager.java:613)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:832)\n```"
    },
    {
        "filename": "YARN-7269.json",
        "creation_time": "2017-09-28T23:56:42.000+0000",
        "stack_trace": "```\njavax.servlet.ServletException: Could not determine the proxy server for redirection\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.findRedirectUrl(AmIpFilter.java:199)\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:141)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1426)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n```"
    },
    {
        "filename": "YARN-7249.json",
        "creation_time": "2017-09-25T16:49:46.000+0000",
        "stack_trace": "```\njava.lang.NullPointerException \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.completedContainer(LeafQueue.java:1308) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.completedContainerInternal(CapacityScheduler.java:1469) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.completedContainer(AbstractYarnScheduler.java:497) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.killReservedContainer(CapacityScheduler.java:1505) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:1341) \nat org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:127) \nat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:705) \n```"
    },
    {
        "filename": "YARN-4598.json",
        "creation_time": "2016-01-15T06:48:48.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: RESOURCE_FAILED at CONTAINER_CLEANEDUP_AFTER_KILL                                       \n    at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)                                                                  \n    at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)                                                                     \n    at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:1127)                                           \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:83)                                             \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1078)              \n    at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:1071)              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:175)                                                                              \n    at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:108)                                                                                 \n    at java.lang.Thread.run(Thread.java:744)                                                                                                                        \n```"
    },
    {
        "filename": "YARN-1149.json",
        "creation_time": "2013-09-04T21:46:58.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: APPLICATION_LOG_HANDLING_FINISHED at RUNNING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305) \n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:425)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:59)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:697)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:689)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:134)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:81)   \n        at java.lang.Thread.run(Thread.java:662)\n```"
    },
    {
        "filename": "YARN-7818.json",
        "creation_time": "2018-01-25T18:42:55.000+0000",
        "stack_trace": "```\norg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=143:\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:180)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DefaultLinuxContainerRuntime.launchContainer(DefaultLinuxContainerRuntime.java:124)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.DelegatingLinuxContainerRuntime.launchContainer(DelegatingLinuxContainerRuntime.java:152)\n        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:549)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:465)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:285)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:95)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n        at java.lang.Thread.run(Thread.java:748)\nCaused by: ExitCodeException exitCode=143:\n        at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009)\n        at org.apache.hadoop.util.Shell.run(Shell.java:902)\n        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:152)\n        ... 10 more\n```"
    }
]