[
    {
        "filename": "MAPREDUCE-6633.json",
        "creation_time": "2016-02-10T21:12:09.000+0000",
        "bug_report": {
            "Title": "AM should retry map attempts if the reduce task encounters commpression related errors.",
            "Description": "When reduce task encounters compression related errors, AM  doesn't retry the corresponding map task.\nIn one of the case we encountered, here is the stack trace.\n{noformat}\n2016-01-27 13:44:28,915 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#29\n\tat org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)\n\tat org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.lang.ArrayIndexOutOfBoundsException\n\tat com.hadoop.compression.lzo.LzoDecompressor.setInput(LzoDecompressor.java:196)\n\tat org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:104)\n\tat org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)\n\tat org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:192)\n\tat org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)\n\tat org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:537)\n\tat org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)\n\tat org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)\n{noformat}\nIn this case, the node on which the map task ran had a bad drive.\nIf the AM had retried running that map task somewhere else, the job definitely would have succeeded."
        }
    },
    {
        "filename": "MAPREDUCE-6577.json",
        "creation_time": "2015-12-17T06:46:30.000+0000",
        "bug_report": {
            "Title": "MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set",
            "Description": "If yarn.app.mapreduce.am.admin.user.env (or yarn.app.mapreduce.am.env) is not configured to set LD_LIBRARY_PATH, MR AM will fail to load the native library:\n\n{noformat}\n2015-12-15 21:29:22,473 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n{noformat}\n\nAs a result, any code that needs the hadoop native library in the MR AM will fail. For example, an uber-AM with lz4 compression for the mapper task will fail:\n{noformat}\n2015-12-15 21:30:17,575 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.lang.RuntimeException: native lz4 library not available\n\tat org.apache.hadoop.io.compress.Lz4Codec.getCompressorType(Lz4Codec.java:125)\n\tat org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:148)\n\tat org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:163)\n\tat org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)\n\tat org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1602)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:457)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n\tat org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:391)\n\tat org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:309)\n\tat org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:195)\n\tat org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:238)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-5137.json",
        "creation_time": "2013-04-09T15:14:34.000+0000",
        "bug_report": {
            "Title": "AM web UI: clicking on Map Task results in 500 error",
            "Description": "Go to a running mapreduce app master web UI. Click on the job, then click on the MAP task type to bring up the list of maps, then try to click on a particular map task.  It fails with a 500 error.  Note this doesn't exist in 0.23.6.\n\n\nException in the log looks like:\n\n2013-04-09 13:53:01,587 DEBUG [1088374@qtp-13877033-2 - /mapreduce/task/task_1365457322543_0004_m_000000] org.apache.hadoop.yarn.webapp.GenericExceptionHandler: GOT EXCEPITION\ncom.sun.jersey.api.NotFoundException: null for uri: http://host.com:38158/mapreduce/task/task_1365457322543_0004_m_000000\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1470)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:123)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1069)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n...\n...\n..."
        }
    },
    {
        "filename": "MAPREDUCE-4008.json",
        "creation_time": "2012-03-14T10:08:39.000+0000",
        "bug_report": {
            "Title": "ResourceManager throws MetricsException on start up saying QueueMetrics MBean already exists",
            "Description": "{code:xml}\n2012-03-14 15:22:23,089 WARN org.apache.hadoop.metrics2.util.MBeans: Error creating MBean object name: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default\norg.apache.hadoop.metrics2.MetricsException: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default already exists!\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:117)\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newMBeanName(DefaultMetricsSystem.java:102)\n\tat org.apache.hadoop.metrics2.util.MBeans.getMBeanName(MBeans.java:91)\n\tat org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:55)\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:218)\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:93)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:243)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$1.postStart(MetricsSystemImpl.java:227)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$3.invoke(MetricsSystemImpl.java:288)\n\tat $Proxy6.postStart(Unknown Source)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:183)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:155)\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:54)\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.start(ResourceManager.java:454)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:588)\nCaused by: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default already exists!\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:113)\n\t... 19 more\n2012-03-14 15:22:23,090 WARN org.apache.hadoop.metrics2.util.MBeans: Failed to register MBean \"null\"\njavax.management.RuntimeOperationsException: Exception occurred trying to register the MBean\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:969)\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)\n\tat com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)\n\tat org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:57)\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:218)\n\tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:93)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:243)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$1.postStart(MetricsSystemImpl.java:227)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl$3.invoke(MetricsSystemImpl.java:288)\n\tat $Proxy6.postStart(Unknown Source)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:183)\n\tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:155)\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:54)\n\tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.start(ResourceManager.java:454)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:588)\nCaused by: java.lang.IllegalArgumentException: No object name specified\n\tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:967)\n\t... 20 more\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-6259.json",
        "creation_time": "2015-02-13T03:20:41.000+0000",
        "bug_report": {
            "Title": "IllegalArgumentException due to missing job submit time",
            "Description": "-1 job submit time cause IllegalArgumentException when parse the Job history file name and JOB_INIT_FAILED cause -1 job submit time in JobIndexInfo.\nWe found the following job history file name which cause IllegalArgumentException when parse the job status in the job history file name.\n{code}\njob_1418398645407_115853--1-worun-kafka%2Dto%2Dhdfs%5Btwo%5D%5B15+topic%28s%29%5D-1423572836007-0-0-FAILED-root.journaling-1423572836007.jhist\n{code}\nThe stack trace for the IllegalArgumentException is\n{code}\n2015-02-10 04:54:01,863 WARN org.apache.hadoop.mapreduce.v2.hs.PartialJob: Exception while parsing job state. Defaulting to KILLED\njava.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.v2.api.records.JobState.0\n\tat java.lang.Enum.valueOf(Enum.java:236)\n\tat org.apache.hadoop.mapreduce.v2.api.records.JobState.valueOf(JobState.java:21)\n\tat org.apache.hadoop.mapreduce.v2.hs.PartialJob.getState(PartialJob.java:82)\n\tat org.apache.hadoop.mapreduce.v2.hs.PartialJob.<init>(PartialJob.java:59)\n\tat org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getAllPartialJobs(CachedHistoryStorage.java:159)\n\tat org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getPartialJobs(CachedHistoryStorage.java:173)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistory.getPartialJobs(JobHistory.java:284)\n\tat org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobs(HsWebServices.java:212)\n\tat sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n\tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)\n\tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n\tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n\tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n\tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n\tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n\tat com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n\tat com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\tat com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)\n\tat com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1223)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:767)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n{code}\n\n\nwhen IOException happened in JobImpl#setup, the Job submit time in JobHistoryEventHandler#MetaInfo#JobIndexInfo will not be changed and the Job submit time will be its [initial value -1|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#L1185].\n{code}\n      this.jobIndexInfo =\n          new JobIndexInfo(-1, -1, user, jobName, jobId, -1, -1, null,\n                           queueName);\n{code}\n\nThe following is the sequences to get -1 job submit time:\n1. \na job is created at MRAppMaster#serviceStart and  the new job is at state JobStateInternal.NEW after created\n{code}\n    job = createJob(getConfig(), forcedState, shutDownMessage);\n{code}\n\n2.\nJobEventType.JOB_INIT is sent to JobImpl from MRAppMaster#serviceStart\n{code}\n      JobEvent initJobEvent = new JobEvent(job.getID(), JobEventType.JOB_INIT);\n      // Send init to the job (this does NOT trigger job execution)\n      // This is a synchronous call, not an event through dispatcher. We want\n      // job-init to be done completely here.\n      jobEventDispatcher.handle(initJobEvent);\n{code}\n\n3.\nafter JobImpl received JobEventType.JOB_INIT, it call InitTransition#transition\n{code}\n          .addTransition\n              (JobStateInternal.NEW,\n              EnumSet.of(JobStateInternal.INITED, JobStateInternal.NEW),\n              JobEventType.JOB_INIT,\n              new InitTransition())\n{code}\n\n4.\nthen the exception happen from setup(job) in InitTransition#transition before JobSubmittedEvent is handled.\nJobSubmittedEvent will update the job submit time. Due to the exception, the submit time is still the initial value -1.\nThis is the code InitTransition#transition\n{code}\npublic JobStateInternal transition(JobImpl job, JobEvent event) {\n      job.metrics.submittedJob(job);\n      job.metrics.preparingJob(job);\n      if (job.newApiCommitter) {\n        job.jobContext = new JobContextImpl(job.conf, job.oldJobId);\n      } else {\n        job.jobContext = new org.apache.hadoop.mapred.JobContextImpl(job.conf, job.oldJobId);\n      }\n      try {\n        setup(job);\n        job.fs = job.getFileSystem(job.conf);\n        //log to job history\n        JobSubmittedEvent jse = new JobSubmittedEvent(job.oldJobId,\n              job.conf.get(MRJobConfig.JOB_NAME, \"test\"), \n            job.conf.get(MRJobConfig.USER_NAME, \"mapred\"),\n            job.appSubmitTime,\n            job.remoteJobConfFile.toString(),\n            job.jobACLs, job.queueName,\n            job.conf.get(MRJobConfig.WORKFLOW_ID, \"\"),\n            job.conf.get(MRJobConfig.WORKFLOW_NAME, \"\"),\n            job.conf.get(MRJobConfig.WORKFLOW_NODE_NAME, \"\"),\n            getWorkflowAdjacencies(job.conf),\n            job.conf.get(MRJobConfig.WORKFLOW_TAGS, \"\"));\n        job.eventHandler.handle(new JobHistoryEvent(job.jobId, jse));\n        //TODO JH Verify jobACLs, UserName via UGI?\n\n        TaskSplitMetaInfo[] taskSplitMetaInfo = createSplits(job, job.jobId);\n        job.numMapTasks = taskSplitMetaInfo.length;\n        job.numReduceTasks = job.conf.getInt(MRJobConfig.NUM_REDUCES, 0);\n\n        if (job.numMapTasks == 0 && job.numReduceTasks == 0) {\n          job.addDiagnostic(\"No of maps and reduces are 0 \" + job.jobId);\n        } else if (job.numMapTasks == 0) {\n          job.reduceWeight = 0.9f;\n        } else if (job.numReduceTasks == 0) {\n          job.mapWeight = 0.9f;\n        } else {\n          job.mapWeight = job.reduceWeight = 0.45f;\n        }\n\n        checkTaskLimits();\n\n        long inputLength = 0;\n        for (int i = 0; i < job.numMapTasks; ++i) {\n          inputLength += taskSplitMetaInfo[i].getInputDataLength();\n        }\n\n        job.makeUberDecision(inputLength);\n        \n        job.taskAttemptCompletionEvents =\n            new ArrayList<TaskAttemptCompletionEvent>(\n                job.numMapTasks + job.numReduceTasks + 10);\n        job.mapAttemptCompletionEvents =\n            new ArrayList<TaskCompletionEvent>(job.numMapTasks + 10);\n        job.taskCompletionIdxToMapCompletionIdx = new ArrayList<Integer>(\n            job.numMapTasks + job.numReduceTasks + 10);\n\n        job.allowedMapFailuresPercent =\n            job.conf.getInt(MRJobConfig.MAP_FAILURES_MAX_PERCENT, 0);\n        job.allowedReduceFailuresPercent =\n            job.conf.getInt(MRJobConfig.REDUCE_FAILURES_MAXPERCENT, 0);\n\n        // create the Tasks but don't start them yet\n        createMapTasks(job, inputLength, taskSplitMetaInfo);\n        createReduceTasks(job);\n\n        job.metrics.endPreparingJob(job);\n        return JobStateInternal.INITED;\n      } catch (Exception e) {\n        LOG.warn(\"Job init failed\", e);\n        job.metrics.endPreparingJob(job);\n        job.addDiagnostic(\"Job init failed : \"\n            + StringUtils.stringifyException(e));\n        // Leave job in the NEW state. The MR AM will detect that the state is\n        // not INITED and send a JOB_INIT_FAILED event.\n        return JobStateInternal.NEW;\n      }\n    }\n{code}\n\nThis is the code JobImpl#setup\n{code}\n    protected void setup(JobImpl job) throws IOException {\n\n      String oldJobIDString = job.oldJobId.toString();\n      String user = \n        UserGroupInformation.getCurrentUser().getShortUserName();\n      Path path = MRApps.getStagingAreaDir(job.conf, user);\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"startJobs: parent=\" + path + \" child=\" + oldJobIDString);\n      }\n\n      job.remoteJobSubmitDir =\n          FileSystem.get(job.conf).makeQualified(\n              new Path(path, oldJobIDString));\n      job.remoteJobConfFile =\n          new Path(job.remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n      // Prepare the TaskAttemptListener server for authentication of Containers\n      // TaskAttemptListener gets the information via jobTokenSecretManager.\n      JobTokenIdentifier identifier =\n          new JobTokenIdentifier(new Text(oldJobIDString));\n      job.jobToken =\n          new Token<JobTokenIdentifier>(identifier, job.jobTokenSecretManager);\n      job.jobToken.setService(identifier.getJobId());\n      // Add it to the jobTokenSecretManager so that TaskAttemptListener server\n      // can authenticate containers(tasks)\n      job.jobTokenSecretManager.addTokenForJob(oldJobIDString, job.jobToken);\n      LOG.info(\"Adding job token for \" + oldJobIDString\n          + \" to jobTokenSecretManager\");\n\n      // If the job client did not setup the shuffle secret then reuse\n      // the job token secret for the shuffle.\n      if (TokenCache.getShuffleSecretKey(job.jobCredentials) == null) {\n        LOG.warn(\"Shuffle secret key missing from job credentials.\"\n            + \" Using job token secret as shuffle secret.\");\n        TokenCache.setShuffleSecretKey(job.jobToken.getPassword(),\n            job.jobCredentials);\n      }\n    }\n{code}\n\n5.\nDue to the IOException from  JobImpl#setup, the new job is still at state JobStateInternal.NEW\n{code}\n      } catch (Exception e) {\n        LOG.warn(\"Job init failed\", e);\n        job.metrics.endPreparingJob(job);\n        job.addDiagnostic(\"Job init failed : \"\n            + StringUtils.stringifyException(e));\n        // Leave job in the NEW state. The MR AM will detect that the state is\n        // not INITED and send a JOB_INIT_FAILED event.\n        return JobStateInternal.NEW;\n      }\n{code}\nAt the following code of MRAppMaster#serviceStart, The MR AM detect the state is not INITED and send a JOB_INIT_FAILED event.\n{code}\n      // If job is still not initialized, an error happened during\n      // initialization. Must complete starting all of the services so failure\n      // events can be processed.\n      initFailed = (((JobImpl)job).getInternalState() != JobStateInternal.INITED);\n    if (initFailed) {\n      JobEvent initFailedEvent = new JobEvent(job.getID(), JobEventType.JOB_INIT_FAILED);\n      jobEventDispatcher.handle(initFailedEvent);\n    } else {\n      // All components have started, start the job.\n      startJobs();\n    }\n{code}\n\n6.\nAfter JobImpl receives the JOB_INIT_FAILED, it will call InitFailedTransition#transition and enter state JobStateInternal.FAIL_ABORT\n{code}\n          .addTransition(JobStateInternal.NEW, JobStateInternal.FAIL_ABORT,\n              JobEventType.JOB_INIT_FAILED,\n              new InitFailedTransition())\n{code}\n\n7.\nJobImpl will send CommitterJobAbortEvent in  InitFailedTransition#transition \n{code}\n    public void transition(JobImpl job, JobEvent event) {\n        job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,\n                job.jobContext,\n                org.apache.hadoop.mapreduce.JobStatus.State.FAILED));\n    }\n{code}\n\n8.\nCommitterJobAbortEvent will be handled by CommitterEventHandler#handleJobAbort which will send JobAbortCompletedEvent(JobEventType.JOB_ABORT_COMPLETED)\n{code}\n    protected void handleJobAbort(CommitterJobAbortEvent event) {\n      cancelJobCommit();\n      try {\n        committer.abortJob(event.getJobContext(), event.getFinalState());\n      } catch (Exception e) {\n        LOG.warn(\"Could not abort job\", e);\n      }\n      context.getEventHandler().handle(new JobAbortCompletedEvent(\n          event.getJobID(), event.getFinalState()));\n    }\n{code}\n\n9.\nAfter JobImpl receives the JOB_ABORT_COMPLETED, it will call JobAbortCompletedTransition#transition and enter state JobStateInternal.FAILED\n{code}\n          .addTransition(JobStateInternal.FAIL_ABORT, JobStateInternal.FAILED,\n              JobEventType.JOB_ABORT_COMPLETED,\n              new JobAbortCompletedTransition())\n{code}\n\n10.\nJobAbortCompletedTransition#transition will call JobImpl#unsuccessfulFinish which will send JobUnsuccessfulCompletionEvent with finish time.\n{code}\n    public void transition(JobImpl job, JobEvent event) {\n      JobStateInternal finalState = JobStateInternal.valueOf(\n          ((JobAbortCompletedEvent) event).getFinalState().name());\n      job.unsuccessfulFinish(finalState);\n    }\n  private void unsuccessfulFinish(JobStateInternal finalState) {\n      if (finishTime == 0) setFinishTime();\n      cleanupProgress = 1.0f;\n      JobUnsuccessfulCompletionEvent unsuccessfulJobEvent =\n          new JobUnsuccessfulCompletionEvent(oldJobId,\n              finishTime,\n              succeededMapTaskCount,\n              succeededReduceTaskCount,\n              finalState.toString(),\n              diagnostics);\n      eventHandler.handle(new JobHistoryEvent(jobId,\n          unsuccessfulJobEvent));\n      finished(finalState);\n  }\n{code}\n\n11.\nJobUnsuccessfulCompletionEvent will be handled by JobHistoryEventHandler#handleEvent with type EventType.JOB_FAILED\nBased on the following code, you can see the JobIndexInfo#finishTime is set correctly but JobIndexInfo#submitTime and  JobIndexInfo#jobStartTime are still -1.\n{code}\n      if (event.getHistoryEvent().getEventType() == EventType.JOB_FAILED\n          || event.getHistoryEvent().getEventType() == EventType.JOB_KILLED) {\n        try {\n          JobUnsuccessfulCompletionEvent jucEvent = \n              (JobUnsuccessfulCompletionEvent) event\n              .getHistoryEvent();\n          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());\n          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());\n          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());\n          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());\n          closeEventWriter(event.getJobID());\n          processDoneFiles(event.getJobID());\n        } catch (IOException e) {\n          throw new YarnRuntimeException(e);\n        }\n      }\n{code}\n\nThe error job history file name in our log is \"job_1418398645407_115853--1-worun-kafka%2Dto%2Dhdfs%5Btwo%5D%5B15+topic%28s%29%5D-1423572836007-0-0-FAILED-root.journaling-1423572836007.jhist\"\nBased on the filename, you can see submitTime is -1, finishTime is 1423572836007 and jobStartTime is 1423572836007.\nThe jobStartTime is not -1, and  jobStartTime is the same as  finishTime.\nIt is because jobStartTime is handled specially in FileNameIndexUtils#getDoneFileName:\n{code}\n    //JobStartTime\n    if (indexInfo.getJobStartTime() >= 0) {\n      sb.append(indexInfo.getJobStartTime());\n    } else {\n      sb.append(indexInfo.getFinishTime());\n    }\n{code}\n\n"
        }
    },
    {
        "filename": "MAPREDUCE-3333.json",
        "creation_time": "2011-11-02T14:00:54.000+0000",
        "bug_report": {
            "Title": "MR AM for sort-job going out of memory",
            "Description": "[~Karams] just found this. The usual sort job on a 350 node cluster hung due to OutOfMemory and eventually failed after an hour instead of the usual odd 20 minutes.\n{code}\n2011-11-02 11:40:36,438 ERROR [ContainerLauncher #258] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container launch failed for container_1320233407485_0002\n_01_001434 : java.lang.reflect.UndeclaredThrowableException\n        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:88)\n        at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:290)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: com.google.protobuf.ServiceException: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: \"gsbl91281.blue.ygrid.yahoo.com/98.137.101.189\"; destination host is: \"\"gsbl91525.blue.ygrid.yahoo.com\":45450; \n        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)\n        at $Proxy20.startContainer(Unknown Source)\n        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:81)\n        ... 4 more\nCaused by: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: \"gsbl91281.blue.ygrid.yahoo.com/98.137.101.189\"; destination host is: \"\"gsbl91525.blue.ygrid.yahoo.com\":45450; \n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:655)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1089)\n        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)\n        ... 6 more\nCaused by: java.io.IOException: Couldn't set up IO streams\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:621)\n        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:205)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1195)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1065)\n        ... 7 more\nCaused by: java.lang.OutOfMemoryError: unable to create new native thread\n        at java.lang.Thread.start0(Native Method)\n        at java.lang.Thread.start(Thread.java:597)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:614)\n        ... 10 more\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-7059.json",
        "creation_time": "2018-02-26T09:38:39.000+0000",
        "bug_report": {
            "Title": "Downward Compatibility issue: MR job fails because of unknown setErasureCodingPolicy method from 3.x client to HDFS 2.x cluster",
            "Description": "Running teragen failed in the version of hadoop-3.1, and hdfs server is 2.8.\r\n{code:java}\r\nbin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0-SNAPSHOT.jar \u00a0teragen \u00a0100000 /teragen\r\n{code}\r\n\r\nThe reason of failing is 2.8 HDFS does not have setErasureCodingPolicy.\r\n\r\none  solution is parsing RemoteException in JobResourceUploader#disableErasure like this:\r\n{code:java}\r\nprivate void disableErasureCodingForPath(FileSystem fs, Path path)\r\n      throws IOException {\r\n    try {\r\n      if (jtFs instanceof DistributedFileSystem) {\r\n        LOG.info(\"Disabling Erasure Coding for path: \" + path);\r\n        DistributedFileSystem dfs = (DistributedFileSystem) jtFs;\r\n        dfs.setErasureCodingPolicy(path,\r\n            SystemErasureCodingPolicies.getReplicationPolicy().getName());\r\n      }\r\n    } catch (RemoteException e) {\r\n      if (!e.getClassName().equals(RpcNoSuchMethodException.class.getName())) {\r\n        throw e;\r\n      } else {\r\n        LOG.warn(\r\n            \"hdfs server does not have method disableErasureCodingForPath,\" \r\n                + \" and skip disableErasureCodingForPath\", e);\r\n      }\r\n    }\r\n  }\r\n{code}\r\n\r\nDoes anyone have better solution?\r\n\r\nThe detailed exception trace is:\r\n{code:java}\r\n2018-02-26 11:22:53,178 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/hadoop/.staging/job_1518615699369_0006\r\norg.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcNoSuchMethodException): Unknown method setErasureCodingPolicy called on org.apache.hadoop.hdfs.protocol.ClientProtocol protocol.\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:436)\r\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\r\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:846)\r\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:789)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1804)\r\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2457)\r\n\r\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1491)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1437)\r\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1347)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)\r\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\r\n\tat com.sun.proxy.$Proxy11.setErasureCodingPolicy(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setErasureCodingPolicy(ClientNamenodeProtocolTranslatorPB.java:1583)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\r\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\r\n\tat com.sun.proxy.$Proxy12.setErasureCodingPolicy(Unknown Source)\r\n\tat org.apache.hadoop.hdfs.DFSClient.setErasureCodingPolicy(DFSClient.java:2678)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$63.doCall(DistributedFileSystem.java:2665)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$63.doCall(DistributedFileSystem.java:2662)\r\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\r\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.setErasureCodingPolicy(DistributedFileSystem.java:2680)\r\n\tat org.apache.hadoop.mapreduce.JobResourceUploader.disableErasureCodingForPath(JobResourceUploader.java:882)\r\n\tat org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)\r\n\tat org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:131)\r\n\tat org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102)\r\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)\r\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)\r\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)\r\n\tat java.security.AccessController.doPrivileged(Native Method)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\r\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)\r\n\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)\r\n\tat org.apache.hadoop.examples.terasort.TeraGen.run(TeraGen.java:304)\r\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\r\n\tat org.apache.hadoop.examples.terasort.TeraGen.main(TeraGen.java:308)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\r\n\tat org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\r\n\tat org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:304)\r\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:218)\r\n{code}\r\n"
        }
    },
    {
        "filename": "MAPREDUCE-4843.json",
        "creation_time": "2012-12-04T13:39:40.000+0000",
        "bug_report": {
            "Title": "When using DefaultTaskController, JobLocalizer not thread safe",
            "Description": "In our cluster, some times job will failed due to below exception:\n2012-12-03 23:11:54,811 WARN org.apache.hadoop.mapred.TaskTracker: Error initializing attempt_201212031626_1115_r_000023_0:\norg.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/$username/jobcache/job_201212031626_1115/job.xml in any of the configured local directories\n\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:424)\n\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:160)\n\tat org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1175)\n\tat org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1058)\n\tat org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2213)\n\nThe root cause is JobLocalizer is not thread safe.\nIn DefaultTaskController.initializeJob method:\n     JobLocalizer localizer = new JobLocalizer((JobConf)getConf(), user, jobid);\nbut in JobLocalizer, it just simply keep the reference of the conf.\nWhen two TaskLauncher threads(mapLauncher and reduceLauncher) try to initializeJob at same time, it will have two JobLocalizer, but only one conf instance.\nSo some times ttConf.setStrings(JOB_LOCAL_CTXT, localDirs) will reset previous job's conf.\nThen it will cause the previous job's job.xml stored at another user's dir."
        }
    },
    {
        "filename": "MAPREDUCE-5028.json",
        "creation_time": "2013-02-26T03:54:25.000+0000",
        "bug_report": {
            "Title": "Maps fail when io.sort.mb is set to high value",
            "Description": "Verified the problem exists on branch-1 with the following configuration:\n\nPseudo-dist mode: 2 maps/ 1 reduce, mapred.child.java.opts=-Xmx2048m, io.sort.mb=1280, dfs.block.size=2147483648\n\nRun teragen to generate 4 GB data\nMaps fail when you run wordcount on this configuration with the following error: \n{noformat}\njava.io.IOException: Spill failed\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1031)\n\tat org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:692)\n\tat org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\n\tat org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:45)\n\tat org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:34)\n\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1149)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:249)\nCaused by: java.io.EOFException\n\tat java.io.DataInputStream.readInt(DataInputStream.java:375)\n\tat org.apache.hadoop.io.IntWritable.readFields(IntWritable.java:38)\n\tat org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)\n\tat org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)\n\tat org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:116)\n\tat org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:92)\n\tat org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:175)\n\tat org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1505)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1438)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$1800(MapTask.java:855)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1346)\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-4300.json",
        "creation_time": "2012-05-31T20:44:00.000+0000",
        "bug_report": {
            "Title": "OOM in AM can turn it into a zombie.",
            "Description": "It looks like 4 threads in the AM died with OOM but not the one pinging the RM.\n\nstderr for this AM\n{noformat}\nWARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.\nMay 30, 2012 4:49:55 AM com.google.inject.servlet.InternalServletModule$BackwardsCompatibleServletContextProvider get\nWARNING: You are attempting to use a deprecated API (specifically, attempting to @Inject ServletContext inside an eagerly created singleton. While we allow this for backwards compatibility, be warned that this MAY have unexpected behavior if you have more than one injector (with ServletModule) running in the same JVM. Please consult the Guice documentation at http://code.google.com/p/google-guice/wiki/Servlets for more information.\nMay 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\nINFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class\nMay 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\nINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\nMay 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\nINFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class\nMay 30, 2012 4:49:55 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\nINFO: Initiating Jersey application, version 'Jersey: 1.8 06/24/2011 12:17 PM'\nMay 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\nINFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\nMay 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\nINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\nMay 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\nINFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope \"PerRequest\"\nException in thread \"ResponseProcessor for block BP-1114822160-<IP>-1322528669066:blk_-6528896407411719649_34227308\" java.lang.OutOfMemoryError: Java heap space\n\tat com.google.protobuf.CodedInputStream.(CodedInputStream.java:538)\n\tat com.google.protobuf.CodedInputStream.newInstance(CodedInputStream.java:55)\n\tat com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:201)\n\tat com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:738)\n\tat org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.parseFrom(DataTransferProtos.java:7287)\n\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:95)\n\tat org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:656)\nException in thread \"DefaultSpeculator background processing\" java.lang.OutOfMemoryError: Java heap space\n\tat java.util.HashMap.resize(HashMap.java:462)\n\tat java.util.HashMap.addEntry(HashMap.java:755)\n\tat java.util.HashMap.put(HashMap.java:385)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTasks(JobImpl.java:632)\n\tat org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleASpeculation(DefaultSpeculator.java:465)\n\tat org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleAMapSpeculation(DefaultSpeculator.java:433)\n\tat org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.computeSpeculations(DefaultSpeculator.java:509)\n\tat org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.access$100(DefaultSpeculator.java:56)\n\tat org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$1.run(DefaultSpeculator.java:176)\n\tat java.lang.Thread.run(Thread.java:619)\nException in thread \"Timer for 'MRAppMaster' metrics system\" java.lang.OutOfMemoryError: Java heap space\nException in thread \"Socket Reader #4 for port 50500\" java.lang.OutOfMemoryError: Java heap space\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-3241.json",
        "creation_time": "2011-10-21T16:25:33.000+0000",
        "bug_report": {
            "Title": "(Rumen)TraceBuilder throws IllegalArgumentException",
            "Description": "When we run the TraceBuilder, we get this exception. Output of the TraceBuilder doesn't contain the map and reduce task information.\n\n{code}\n2011-10-21 22:07:17,268 WARN  rumen.TraceBuilder (TraceBuilder.java:run(272)) - TraceBuilder got an error while processing the [possibly virtual] file job_1319214405771_0002-1319214846458-root-word+count-1319214871038-1-1-SUCCEEDED.jhist within Path hdfs://10.18.52.57:9000/user/root/null/history/done_intermediate/root/job_1319214405771_0002-1319214846458-root-word+count-1319214871038-1-1-SUCCEEDED.jhist\njava.lang.IllegalArgumentException: JobBuilder.process(HistoryEvent): unknown event type\n        at org.apache.hadoop.tools.rumen.JobBuilder.process(JobBuilder.java:165)\n        at org.apache.hadoop.tools.rumen.TraceBuilder.processJobHistory(TraceBuilder.java:304)\n        at org.apache.hadoop.tools.rumen.TraceBuilder.run(TraceBuilder.java:258)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)\n        at org.apache.hadoop.tools.rumen.TraceBuilder.main(TraceBuilder.java:185)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)\n\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-6002.json",
        "creation_time": "2014-07-24T02:49:25.000+0000",
        "bug_report": {
            "Title": "MR task should prevent report error to AM when process is shutting down",
            "Description": "With MAPREDUCE-5900, preempted MR task should not be treat as failed. \nBut it is still possible a MR task fail and report to AM when preemption take effect and the AM hasn't received completed container from RM yet. It will cause the task attempt marked failed instead of preempted.\n\nAn example is FileSystem has shutdown hook, it will close all FileSystem instance, if at the same time, the FileSystem is in-use (like reading split details from HDFS), MR task will fail and report the fatal error to MR AM. An exception will be raised:\n{code}\n2014-07-22 01:46:19,613 FATAL [IPC Server handler 10 on 56903] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1405985051088_0018_m_000025_0 - exited : java.io.IOException: Filesystem closed\n\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:707)\n\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:776)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:837)\n\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:645)\n\tat java.io.DataInputStream.readByte(DataInputStream.java:265)\n\tat org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)\n\tat org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)\n\tat org.apache.hadoop.io.Text.readString(Text.java:464)\n\tat org.apache.hadoop.io.Text.readString(Text.java:457)\n\tat org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:357)\n\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:731)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)\n{code}\n\nWe should prevent this, because it is possible other exceptions happen when shutting down, we shouldn't report any of such exceptions to AM."
        }
    },
    {
        "filename": "MAPREDUCE-6452.json",
        "creation_time": "2015-08-14T12:22:27.000+0000",
        "bug_report": {
            "Title": "NPE when intermediate encrypt enabled for LocalRunner",
            "Description": "Enable the below properties try running mapreduce job\n\nmapreduce.framework.name=local\nmapreduce.job.encrypted-intermediate-data=true\n\n{code}\n2015-08-14 16:27:25,248 WARN  [Thread-21] mapred.LocalJobRunner (LocalJobRunner.java:run(561)) - job_local473843898_0001\njava.lang.Exception: java.lang.NullPointerException\n        at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:463)\n        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:523)\nCaused by: java.lang.NullPointerException\n        at org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:92)\n        at org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:31)\n        at org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:112)\n        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1611)\n        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1492)\n        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)\n        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)\n        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)\n        at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:244)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n\n{code}\n\nJobs are failing always"
        }
    },
    {
        "filename": "MAPREDUCE-6649.json",
        "creation_time": "2016-03-07T16:37:13.000+0000",
        "bug_report": {
            "Title": "getFailureInfo not returning any failure info",
            "Description": "The following command does not produce any failure info as to why the job failed. \n\n{noformat}\n$HADOOP_PREFIX/bin/hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-${HADOOP_VERSION}-tests.jar sleep -Dmapreduce.jobtracker.split.metainfo.maxsize=10 -Dmapreduce.job.queuename=default -m 1 -r 1 -mt 1 -rt 1\n{noformat}\n\n{noformat}\n2016-03-07 10:34:58,112 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1431)) - Job job_1457364518683_0004 failed with state FAILED due to: \n{noformat}\n\nTo contrast, here is a command and associated command line output to show a failed job that gives the correct failiure info. \n\n{noformat}\n$HADOOP_PREFIX/bin/hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-${HADOOP_VERSION}-tests.jar sleep -Dyarn.app.mapreduce.am.command-opts=-goober -Dmapreduce.job.queuename=default -m 20 -r 0 -mt 30000\n{noformat}\n\n{noformat}\n2016-03-07 10:30:13,103 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1431)) - Job job_1457364518683_0003 failed with state FAILED due to: Application application_1457364518683_0003 failed 3 times due to AM Container for appattempt_1457364518683_0003_000003 exited with  exitCode: 1\nFailing this attempt.Diagnostics: Exception from container-launch.\nContainer id: container_1457364518683_0003_03_000001\nExit code: 1\nStack trace: ExitCodeException exitCode=1: \n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:927)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:838)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:227)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:319)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:88)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-4048.json",
        "creation_time": "2012-03-21T10:01:09.000+0000",
        "bug_report": {
            "Title": "NullPointerException exception while accessing the Application Master UI",
            "Description": "{code:xml}\n2012-03-21 10:21:31,838 ERROR [2145015588@qtp-957250718-801] org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /mapreduce/attempts/job_1332261815858_2_8/m/KILLED\njava.lang.reflect.InvocationTargetException\n        at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:150)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)\n        at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)\n        at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)\n        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n        .......\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.lang.NullPointerException\n        at com.google.common.base.Joiner.toString(Joiner.java:317)\n        at com.google.common.base.Joiner.appendTo(Joiner.java:97)\n        at com.google.common.base.Joiner.appendTo(Joiner.java:127)\n        at com.google.common.base.Joiner.join(Joiner.java:158)\n        at com.google.common.base.Joiner.join(Joiner.java:166)\n        at org.apache.hadoop.yarn.util.StringHelper.join(StringHelper.java:102)\n        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.badRequest(AppController.java:319)\n        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.attempts(AppController.java:286)\n        ... 36 more\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-5198.json",
        "creation_time": "2013-04-30T22:22:33.000+0000",
        "bug_report": {
            "Title": "Race condition in cleanup during task tracker renint with LinuxTaskController",
            "Description": "This was noticed when job tracker would be restarted while jobs were running and would ask the task tracker to reinitialize. \n\nTasktracker would fail with an error like\n\n{code}\n013-04-27 20:19:09,627 INFO org.apache.hadoop.mapred.TaskTracker: Good mapred local directories are: /grid/0/hdp/mapred/local,/grid/1/hdp/mapred/local,/grid/2/hdp/mapred/local,/grid/3/hdp/mapred/local,/grid/4/hdp/mapred/local,/grid/5/hdp/mapred/local\n2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075 caught: java.nio.channels.ClosedChannelException\n\tat sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:133)\n\tat sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)\n\tat org.apache.hadoop.ipc.Server.channelWrite(Server.java:1717)\n\tat org.apache.hadoop.ipc.Server.access$2000(Server.java:98)\n\tat org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:744)\n\tat org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:808)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1433)\n\n2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075: exiting\n2013-04-27 20:19:10,414 ERROR org.apache.hadoop.mapred.TaskTracker: Got fatal exception while reinitializing TaskTracker: org.apache.hadoop.util.Shell$ExitCodeException: \n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:255)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:182)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)\n\tat org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:281)\n\tat org.apache.hadoop.mapred.TaskTracker.deleteUserDirectories(TaskTracker.java:779)\n\tat org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:816)\n\tat org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2704)\n\tat org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3934)\n{code} "
        }
    },
    {
        "filename": "MAPREDUCE-7028.json",
        "creation_time": "2017-12-20T15:33:20.000+0000",
        "bug_report": {
            "Title": "Concurrent task progress updates causing NPE in Application Master",
            "Description": "Concurrent task progress updates can cause a NullPointerException in the Application Master (stack trace is with code at current trunk):\r\n\r\n{quote}\r\n2017-12-20 06:49:42,369 INFO [IPC Server handler 9 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883\r\n2017-12-20 06:49:42,369 INFO [IPC Server handler 13 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883\r\n2017-12-20 06:49:42,383 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\r\njava.lang.NullPointerException\r\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:2450)\r\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:2433)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:487)\r\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1362)\r\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:154)\r\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1543)\r\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1535)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)\r\n        at java.lang.Thread.run(Thread.java:748)\r\n2017-12-20 06:49:42,385 INFO [IPC Server handler 13 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883\r\n2017-12-20 06:49:42,386 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..\r\n{quote}\r\n\r\nThis happened naturally in several big wordcount runs, and I could reproduce this reliably by artificially making task updates more frequent."
        }
    },
    {
        "filename": "MAPREDUCE-3790.json",
        "creation_time": "2012-02-02T18:04:23.000+0000",
        "bug_report": {
            "Title": "Broken pipe on streaming job can lead to truncated output for a successful job",
            "Description": "If a streaming job doesn't consume all of its input then the job can be marked successful even though the job's output is truncated.\n\nHere's a simple setup that can exhibit the problem.  Note that the job output will most likely be truncated compared to the same job run with a zero-length input file.\n\n{code}\n$ hdfs dfs -cat in\nfoo\n$ yarn jar ./share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -Dmapred.map.tasks=1 -Dmapred.reduce.tasks=1 -mapper /bin/env -reducer NONE -input in -output out\n{code}\n\nExamining the map task log shows this:\n\n{code:title=Excerpt from map task stdout log}\n2012-02-02 11:27:25,054 WARN [main] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Broken pipe\n2012-02-02 11:27:25,054 INFO [main] org.apache.hadoop.streaming.PipeMapRed: mapRedFinished\n2012-02-02 11:27:25,056 WARN [Thread-12] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Bad file descriptor\n2012-02-02 11:27:25,124 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1328203555769_0001_m_000000_0 is done. And is in the process of commiting\n2012-02-02 11:27:25,127 WARN [Thread-11] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: DFSOutputStream is closed\n2012-02-02 11:27:25,199 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1328203555769_0001_m_000000_0 is allowed to commit now\n2012-02-02 11:27:25,225 INFO [main] org.apache.hadoop.mapred.FileOutputCommitter: Saved output of task 'attempt_1328203555769_0001_m_000000_0' to hdfs://localhost:9000/user/somebody/out/_temporary/1\n2012-02-02 11:27:27,834 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1328203555769_0001_m_000000_0' done.\n{code}\n\nIn PipeMapRed.mapRedFinished() we can see it will eat IOExceptions and return without waiting for the output threads or throwing a runtime exception to fail the job.  Net result is that the DFS streams could be shutdown too early if the output threads are still busy and we could lose job output.\n\nFixing this brings up the bigger question of what *should* happen when a streaming job doesn't consume all of its input.  Should we have grabbed all of the output from the job and still marked it successful or should we have failed the job?  If the former then we need to fix some other places in the code as well, since feeding a much larger input file (e.g.: 600K) to the same sample streaming job results in the job failing with the exception below.  It wouldn't be consistent to fail the job that doesn't consume a lot of input but pass the job that leaves just a few leftovers.\n\n{code}\n2012-02-02 10:29:37,220 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1270)) - Running job: job_1328200108174_0001\n2012-02-02 10:29:44,354 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1291)) - Job job_1328200108174_0001 running in uber mode : false\n2012-02-02 10:29:44,355 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1298)) -  map 0% reduce 0%\n2012-02-02 10:29:46,394 INFO  mapreduce.Job (Job.java:printTaskEvents(1386)) - Task Id : attempt_1328200108174_0001_m_000000_0, Status : FAILED\nError: java.io.IOException: Broken pipe\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:282)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)\n\tat java.io.DataOutputStream.write(DataOutputStream.java:90)\n\tat org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)\n\tat org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)\n\tat org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)\n\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:394)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:329)\n\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)\n{code}\n\nAssuming the job returns a successful exit code, I think we should allow the job to complete successfully even though it doesn't consume all of its inputs.  Part of the reasoning is that there's already this comment in PipeMapper.java that implies we desire that behavior:\n\n{code:title=PipeMapper.java}\n        // terminate with success:\n        // swallow input records although the stream processor failed/closed\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-6357.json",
        "creation_time": "2015-05-05T18:11:38.000+0000",
        "bug_report": {
            "Title": "MultipleOutputs.write() API should document that output committing is not utilized when input path is absolute",
            "Description": "After spending the afternoon debugging a user job where reduce tasks were failing on retry with the below exception, I think it would be worthwhile to add a note in the MultipleOutputs.write() documentation, saying that absolute paths may cause improper execution of tasks on retry or when MR speculative execution is enabled. \n\n{code}\n2015-04-28 23:13:10,452 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: File already exists:wasb://full20150320@bgtstoragefull.blob.core.windows.net/user/hadoop/some/path/block-r-00299.bz2\n       at org.apache.hadoop.fs.azure.NativeAzureFileSystem.create(NativeAzureFileSystem.java:1354)\n       at org.apache.hadoop.fs.azure.NativeAzureFileSystem.create(NativeAzureFileSystem.java:1195)\n       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908)\n       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889)\n       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786)\n       at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:135)\n       at org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.getRecordWriter(MultipleOutputs.java:475)\n       at org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write(MultipleOutputs.java:433)\n       at com.ancestry.bigtree.hadoop.LevelReducer.processValue(LevelReducer.java:91)\n       at com.ancestry.bigtree.hadoop.LevelReducer.reduce(LevelReducer.java:69)\n       at com.ancestry.bigtree.hadoop.LevelReducer.reduce(LevelReducer.java:14)\n       at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)\n       at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)\n       at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)\n       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:415)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n{code}\n\nAs discussed in MAPREDUCE-3772, when the baseOutputPath passed to MultipleOutputs.write() is an absolute path (or more precisely a path that resolves outside of the job output-dir), the concept of output committing is not utilized. \n\nIn this case, the user read thru the MultipleOutputs docs and was assuming that everything will be working fine, as there are blog posts saying that MultipleOutputs does handle output commit. "
        }
    },
    {
        "filename": "MAPREDUCE-6091.json",
        "creation_time": "2014-09-16T01:19:58.000+0000",
        "bug_report": {
            "Title": "YARNRunner.getJobStatus() fails with ApplicationNotFoundException if the job rolled off the RM view",
            "Description": "If you query the job status of a job that rolled off the RM view via YARNRunner.getJobStatus(), it fails with an ApplicationNotFoundException. For example,\n\n{noformat}\n2014-09-15 07:09:51,084 ERROR org.apache.pig.tools.grunt.Grunt: ERROR 6017: JobID: job_1410289045532_90542 Reason: java.io.IOException: org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException: Application with id 'application_1410289045532_90542' doesn't exist in RM.\n\tat org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getApplicationReport(ClientRMService.java:288)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.getApplicationReport(ApplicationClientProtocolPBServiceImpl.java:150)\n\tat org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:337)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2058)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2054)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1547)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2052)\n\n\tat org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:348)\n\tat org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:419)\n\tat org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:559)\n\tat org.apache.hadoop.mapreduce.Job$1.run(Job.java:314)\n\tat org.apache.hadoop.mapreduce.Job$1.run(Job.java:311)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1547)\n\tat org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:311)\n\tat org.apache.hadoop.mapreduce.Job.isComplete(Job.java:599)\n\tat org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.checkRunningState(ControlledJob.java:257)\n\tat org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.checkState(ControlledJob.java:282)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.pig.backend.hadoop23.PigJobControl.checkState(PigJobControl.java:120)\n\tat org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:180)\n\tat java.lang.Thread.run(Thread.java:662)\n\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:279)\n{noformat}\n\nPrior to 2.1.0, it used to be able to fall back onto the job history server and get the status.\n\nThis appears to be introduced by YARN-873. YARN-873 changed ClientRMService to throw an ApplicationNotFoundException on an unknown app id (from returning null). But MR's ClientServiceDelegate was never modified to change its behavior."
        }
    },
    {
        "filename": "MAPREDUCE-4825.json",
        "creation_time": "2012-11-27T19:01:45.000+0000",
        "bug_report": {
            "Title": "JobImpl.finished doesn't expect ERROR as a final job state",
            "Description": "TestMRApp.testJobError is causing AsyncDispatcher to exit with System.exit due to an exception being thrown.  From the console output from testJobError:\n\n{noformat}\n2012-11-27 18:46:15,240 ERROR [AsyncDispatcher event handler] impl.TaskImpl (TaskImpl.java:internalError(665)) - Invalid event T_SCHEDULE on Task task_0_0000_m_000000\n2012-11-27 18:46:15,242 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(132)) - Error in dispatcher thread\njava.lang.IllegalArgumentException: Illegal job state: ERROR\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.finished(JobImpl.java:838)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InternalErrorTransition.transition(JobImpl.java:1622)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InternalErrorTransition.transition(JobImpl.java:1)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:359)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:299)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:287)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:723)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:974)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n\tat java.lang.Thread.run(Thread.java:662)\n2012-11-27 18:46:15,242 INFO  [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(135)) - Exiting, bbye..\n{noformat}\n"
        }
    },
    {
        "filename": "MAPREDUCE-3319.json",
        "creation_time": "2011-10-31T21:41:36.000+0000",
        "bug_report": {
            "Title": "multifilewc from hadoop examples seems to be broken in 0.20.205.0",
            "Description": "{noformat}\n/usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop/hadoop-examples-0.20.205.0.22.jar multifilewc  examples/text examples-output/multifilewc\n11/10/31 16:50:26 INFO mapred.FileInputFormat: Total input paths to process : 2\n11/10/31 16:50:26 INFO mapred.JobClient: Running job: job_201110311350_0220\n11/10/31 16:50:27 INFO mapred.JobClient:  map 0% reduce 0%\n11/10/31 16:50:42 INFO mapred.JobClient: Task Id : attempt_201110311350_0220_m_000000_0, Status : FAILED\njava.lang.ClassCastException: org.apache.hadoop.io.IntWritable cannot be cast to org.apache.hadoop.io.LongWritable\n\tat org.apache.hadoop.mapred.lib.LongSumReducer.reduce(LongSumReducer.java:44)\n\tat org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1431)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1436)\n\tat org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1298)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:437)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:249)\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-6361.json",
        "creation_time": "2015-05-11T15:36:10.000+0000",
        "bug_report": {
            "Title": "NPE issue in shuffle caused by concurrent issue between copySucceeded() in one thread and copyFailed() in another thread on the same host",
            "Description": "The failure in log:\n2015-05-08 21:00:00,513 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#25\n         at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)\n         at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)\n         at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)\n         at java.security.AccessController.doPrivileged(Native Method)\n         at javax.security.auth.Subject.doAs(Subject.java:415)\n         at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\n         at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\nCaused by: java.lang.NullPointerException\n         at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:267)\n         at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:308)\n         at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)"
        }
    },
    {
        "filename": "MAPREDUCE-4848.json",
        "creation_time": "2012-12-05T04:01:47.000+0000",
        "bug_report": {
            "Title": "TaskAttemptContext cast error during AM recovery",
            "Description": "Recently saw an AM that failed and tried to recover, but the subsequent attempt quickly exited with its own failure during recovery:\n\n{noformat}\n2012-12-05 02:33:36,752 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\njava.lang.ClassCastException: org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl cannot be cast to org.apache.hadoop.mapred.TaskAttemptContext\n\tat org.apache.hadoop.mapred.OutputCommitter.recoverTask(OutputCommitter.java:284)\n\tat org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.handle(RecoveryService.java:361)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1211)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1177)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:958)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:926)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:918)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n\tat org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.realDispatch(RecoveryService.java:285)\n\tat org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:281)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n\tat java.lang.Thread.run(Thread.java:619)\n2012-12-05 02:33:36,752 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..\n{noformat}\n\nThe RM then launched a third AM attempt which succeeded. The third attempt saw basically no progress after parsing the history file from the second attempt and ran the job again from scratch."
        }
    },
    {
        "filename": "MAPREDUCE-3226.json",
        "creation_time": "2011-10-20T06:38:04.000+0000",
        "bug_report": {
            "Title": "Few reduce tasks hanging in a gridmix-run",
            "Description": "In a gridmix run with ~1000 jobs, one job is getting stuck because of 2-3 hanging reducers. All of the them are stuck after downloading all map outputs and have the following thread dump.\n\n{code}\n\"EventFetcher for fetching Map Completion Events\" daemon prio=10 tid=0xa325fc00 nid=0x1ca4 waiting on condition [0xa315c000]\n   java.lang.Thread.State: TIMED_WAITING (sleeping)\n        at java.lang.Thread.sleep(Native Method)\n        at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:71)\n\n\"main\" prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]\n   java.lang.Thread.State: WAITING (on object monitor)\n        at java.lang.Object.wait(Native Method)\n        - waiting on <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)\n        at java.lang.Thread.join(Thread.java:1143)\n        - locked <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)\n        at java.lang.Thread.join(Thread.java:1196)\n        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:135)\n        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:367)\n        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)\n{code}\n\nThanks to [~karams] for helping track this down."
        }
    },
    {
        "filename": "MAPREDUCE-3070.json",
        "creation_time": "2011-09-22T14:33:58.000+0000",
        "bug_report": {
            "Title": "NM not able to register with RM after NM restart",
            "Description": "After stopping NM gracefully then starting NM, NM registration fails with RM with Duplicate registration from the node! error.\n\n\n{noformat} \n2011-09-23 01:50:46,705 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager\norg.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)\nCaused by: org.apache.avro.AvroRuntimeException: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)\n\t... 2 more\nCaused by: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:142)\n\tat $Proxy13.registerNodeManager(Unknown Source)\n\tat org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:175)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)\n\t... 3 more\n{noformat} \n"
        }
    },
    {
        "filename": "MAPREDUCE-3932.json",
        "creation_time": "2012-02-27T22:39:43.000+0000",
        "bug_report": {
            "Title": "MR tasks failing and crashing the AM when available-resources/headRoom becomes zero",
            "Description": "[~karams] reported this offline. One reduce task gets preempted because of zero headRoom and crashes the AM.\n{code}\n2012-02-23 11:30:15,956 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544\n2012-02-23 11:30:16,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544\n2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0\n2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0\n2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 3\n2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000006 to attempt_1329995034628_0983_r_000000_0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000007 to attempt_1329995034628_0983_r_000001_0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000008 to attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:20 AssignedMaps:0 AssignedReduces:3 completedMaps:4 completedReduces:0 containersAllocated:7 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:20\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 2\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000001_0\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule...\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.4 totalMemLimit:4608 finalMapMemLimit:2765 finalReduceMemLimit:1843 netScheduledMapMem:9216 netScheduledReduceMem:4608\n2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down 0\n2012-02-23 11:30:16,968 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host6 to /$rack6\n2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host1 to /$rack1\n2012-02-23 11:30:16,977 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n2012-02-23 11:30:16,981 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host9 to /$rack9\n2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP\n2012-02-23 11:30:16,983 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP\n2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000000_0\n2012-02-23 11:30:16,983 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000000_0\n2012-02-23 11:30:16,984 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:16,984 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:16,984 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000001_0\n2012-02-23 11:30:16,987 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000001_0\n2012-02-23 11:30:16,988 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000001_0\n2012-02-23 11:30:16,988 ERROR [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container was killed before it was launched\n2012-02-23 11:30:17,061 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000000_0 : 53990\n2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP\n2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1329995034628_0983_r_000001_0: Container was killed before it was launched\n2012-02-23 11:30:17,078 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1329995034628_0983_r_000001_0\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILL_TASK_CLEANUP\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:926)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:870)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:862)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)\n\tat java.lang.Thread.run(Thread.java:619)\n2012-02-23 11:30:17,080 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1329995034628_0983_r_000000_0] using containerId: [container_1329995034628_0983_01_000006 on NM: [$host6:51529]\n2012-02-23 11:30:17,081 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING\n2012-02-23 11:30:17,207 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000002_0 : 47960\n2012-02-23 11:30:17,207 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1329995034628_0983_r_000002_0\n2012-02-23 11:30:17,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1329995034628_0983Job Transitioned from RUNNING to ERROR\n2012-02-23 11:30:17,216 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_COUNTER_UPDATE at ERROR\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:657)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:111)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:848)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:844)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)\n\tat java.lang.Thread.run(Thread.java:619)\n\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-4062.json",
        "creation_time": "2012-03-23T21:42:23.000+0000",
        "bug_report": {
            "Title": "AM Launcher thread can hang forever",
            "Description": "We saw an instance where the RM stopped launch Application masters.  We found that the launcher thread was hung because something weird/bad happened to the NM node. Currently there is only 1 launcher thread (jira 4061 to fix that). We need this to not happen.  Even once we increase the number of threads  to > 1 if that many nodes go bad the RM would be stuck.  Note that this was stuck like this for approximately 9 hours.\n\nStack trace on hung AM launcher:\n\n\"pool-1-thread-1\" prio=10 tid=0x000000004343e800 nid=0x3a4c in Object.wait()\n[0x000000004fad2000]\n   java.lang.Thread.State: WAITING (on object monitor)\n    at java.lang.Object.wait(Native Method)\n    at java.lang.Object.wait(Object.java:485)\n    at org.apache.hadoop.ipc.Client.call(Client.java:1076)\n    - locked <0x00002aab05a4f3f0> (a org.apache.hadoop.ipc.Client$Call)\n    at\norg.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:135)\n    at $Proxy76.startContainer(Unknown Source)\n    at\norg.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:87)\n    at\norg.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:118)\n    at\norg.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:265)\n    at\njava.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n    at\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n    at java.lang.Thread.run(Thread.java:619)"
        }
    },
    {
        "filename": "MAPREDUCE-3066.json",
        "creation_time": "2011-09-21T22:42:00.000+0000",
        "bug_report": {
            "Title": "YARN NM fails to start",
            "Description": "Please check conf.get() calls. Every time I svn up, I get one of these.\n\n\n2011-09-21 15:36:33,534 INFO  service.AbstractService (AbstractService.java:stop(71)) - Service:org.apache.hadoop.yarn.server.nodemanager.DeletionService is stopped.\n2011-09-21 15:36:33,534 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager\norg.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)\nCaused by: org.apache.avro.AvroRuntimeException: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)\n\tat org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)\n\t... 2 more\nCaused by: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getRMClient(NodeStatusUpdaterImpl.java:154)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:164)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)\n\t... 3 more\n2011-09-21 15:36:33,535 INFO  service.CompositeService (CompositeService.java:stop(97)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl\njava.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED\n\tat org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)\n\tat org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:95)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:85)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)\n\tat org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)\n2011-09-21 15:36:33,535 INFO  nodemanager.NodeManager (StringUtils.java:run(605)) - SHUTDOWN_MSG: \n/************************************************************\nSHUTDOWN_MSG: Shutting down NodeManager at criccomi-ld/127.0.0.1\n************************************************************/\n2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 45454\n2011-09-21 15:36:33,536 INFO  logaggregation.LogAggregationService (LogAggregationService.java:stop(116)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit\n2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 4344\n2011-09-21 15:36:33,536 INFO  service.CompositeService (CompositeService.java:run(120)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeManager\njava.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED\n\tat org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)\n\tat org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)\n\tat org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:87)\n\tat org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)\n\tat org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)\n"
        }
    },
    {
        "filename": "MAPREDUCE-3123.json",
        "creation_time": "2011-09-29T19:03:45.000+0000",
        "bug_report": {
            "Title": "Symbolic links with special chars causing container/task.sh to fail",
            "Description": "the following job throws an exception when you have the special characters in it.\n\nhadoop jar hadoop-streaming.jar -Dmapreduce.job.acl-view-job=* -Dmapreduce.job.queuename=queue1 -files file:///homes/user/hadoop/Streaming/data/streaming-980//InputDir#testlink!@$&*()-_+= -input Streaming/streaming-980/input.txt  -mapper 'xargs cat' -reducer cat -output Streaming/streaming-980/Output -jobconf mapred.job.name=streamingTest-980 -jobconf mapreduce.job.acl-view-job=*\n\nException:\n2011-09-27 20:58:48,903 INFO org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer:\n[container-executor, hadoopuser, 1, application_1317077272567_0239,\ncontainer_1317077272567 0239_01_000001,\ntmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001,\ntmp/mapred-local/nmPrivate/application_1317077272567_0239/container_1317077272567_0239_01 000001/task.sh,\ntmp/mapred-local/nmPrivate/container_1317077272567_0239_01_000001/container_1317077272567_0239_01_000001.tokens]1109221111-tests.jar:hadoop-mapreduce-p2011-09-27\n20:58:48,944 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exit code from container is : 2    \n                                                                                                           2011-09-27\n20:58:48,946 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exception from container-launch :  \n                                                                                                          \norg.apache.hadoop.util.Shell$ExitCodeException:\n/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:\nline 26: syntax error near unexpected token `-_+='       \n/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:\nline 26: `ln -sf /tmp/mapred-local/usercache/hadoopqa/filecache/-1888139433818483070/InputDir test\nink!@$&*()-_+='kson-jaxrs-1.7.1.jar:/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.7.3/jackson-mapper-asl-1.7.3.jar:.m2/repository/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar:\n\n     at org.apache.hadoop.util.Shell.runCommand(Shell.java:261)                                                        \n                                                                                                                       \n   at org.apache.hadoop.util.Shell.run(Shell.java:188)                                                                 \n                                                                                                                       \n at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:381)                                          \n                                                                                                                      \nat org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:174)   \n                                                                                                                     \nat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:197)  \n                                                                                                                     \nat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:62)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\n2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:\n2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Processing\ncontainer_1317077272567_0239_01_000001 of type UPDATE_DIAGNOSTICS_MSG\n2011-09-27 20:58:48,951 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch:\nContainer exited with a non-zero exit code 2\n\n\n"
        }
    },
    {
        "filename": "MAPREDUCE-6439.json",
        "creation_time": "2015-07-30T20:31:00.000+0000",
        "bug_report": {
            "Title": "AM may fail instead of retrying if RM shuts down during the allocate call",
            "Description": "We are seeing cases where MR AM gets a YarnRuntimeException thats thrown in RM and gets sent back to AM causing it to think that it has exhausted the number of retries. Copying the error which causes the heartbeat thread to quit.\n\n{noformat}\n2015-07-25 20:07:27,346 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n\tat org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)\n\t... 11 more\n\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n\tat org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)\n\t... 11 more\n\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)\n\tat org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:107)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n\tat com.sun.proxy.$Proxy36.allocate(Unknown Source)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:188)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:667)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:244)\n\tat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:282)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.yarn.exceptions.YarnRuntimeException): java.lang.InterruptedException\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)\n\tat org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)\n\tat org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:415)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)\nCaused by: java.lang.InterruptedException\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)\n\tat java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)\n\tat java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)\n\t... 11 more\n\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1411)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1364)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n\tat com.sun.proxy.$Proxy35.allocate(Unknown Source)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77)\n\t... 12 more\n{noformat} \n"
        }
    },
    {
        "filename": "MAPREDUCE-4490.json",
        "creation_time": "2012-07-27T01:22:21.000+0000",
        "bug_report": {
            "Title": "JVM reuse is incompatible with LinuxTaskController (and therefore incompatible with Security)",
            "Description": "When using LinuxTaskController, JVM reuse (mapred.job.reuse.jvm.num.tasks > 1) with more map tasks in a job than there are map slots in the cluster will result in immediate task failures for the second task in each JVM (and then the JVM exits). We have investigated this bug and the root cause is as follows. When using LinuxTaskController, the userlog directory for a task attempt (../userlogs/job/task-attempt) is created only on the first invocation (when the JVM is launched) because userlogs directories are created by the task-controller binary which only runs *once* per JVM. Therefore, attempting to create log.index is guaranteed to fail with ENOENT leading to immediate task failure and child JVM exit.\n\n{quote}\n2012-07-24 14:29:11,914 INFO org.apache.hadoop.mapred.TaskLog: Starting logging for a new task attempt_201207241401_0013_m_000027_0 in the same JVM as that of the first task /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_000006_0\n2012-07-24 14:29:11,915 WARN org.apache.hadoop.mapred.Child: Error running child\nENOENT: No such file or directory\n        at org.apache.hadoop.io.nativeio.NativeIO.open(Native Method)\n        at org.apache.hadoop.io.SecureIOUtils.createForWrite(SecureIOUtils.java:161)\n        at org.apache.hadoop.mapred.TaskLog.writeToIndexFile(TaskLog.java:296)\n        at org.apache.hadoop.mapred.TaskLog.syncLogs(TaskLog.java:369)\n        at org.apache.hadoop.mapred.Child.main(Child.java:229)\n{quote}\n\nThe above error occurs in a JVM which runs tasks 6 and 27.  Task6 goes smoothly. Then Task27 starts. The directory /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_0000027_0 is never created so when mapred.Child tries to write the log.index file for Task27, it fails with ENOENT because the attempt_201207241401_0013_m_0000027_0 directory does not exist. Therefore, the second task in each JVM is guaranteed to fail (and then the JVM exits) every time when using LinuxTaskController. Note that this problem does not occur when using the DefaultTaskController because the userlogs directories are created for each task (not just for each JVM as with LinuxTaskController).\n\nFor each task, the TaskRunner calls the TaskController's createLogDir method before attempting to write out an index file.\n\n* DefaultTaskController#createLogDir: creates log directory for each task\n* LinuxTaskController#createLogDir: does nothing\n** task-controller binary creates log directory [create_attempt_directories] (but only for the first task)\n\nPossible Solution: add a new command to task-controller *initialize task* to create attempt directories.  Call that command, with ShellCommandExecutor, in the LinuxTaskController#createLogDir method\n\n\n\n\n"
        }
    },
    {
        "filename": "MAPREDUCE-3744.json",
        "creation_time": "2012-01-27T20:31:19.000+0000",
        "bug_report": {
            "Title": "Unable to retrieve application logs via \"yarn logs\" or \"mapred job -logs\"",
            "Description": "Trying to retrieve application logs via the \"yarn logs\" shell command results in an error similar to this:\n\nException in thread \"main\" java.io.FileNotFoundException: File /tmp/logs/application_1327694122989_0001 does not exist.\n\tat org.apache.hadoop.fs.Hdfs$DirListingIterator.<init>(Hdfs.java:226)\n\tat org.apache.hadoop.fs.Hdfs$DirListingIterator.<init>(Hdfs.java:217)\n\tat org.apache.hadoop.fs.Hdfs$2.<init>(Hdfs.java:192)\n\tat org.apache.hadoop.fs.Hdfs.listStatusIterator(Hdfs.java:192)\n\tat org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1371)\n\tat org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1)\n\tat org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2319)\n\tat org.apache.hadoop.fs.FileContext.listStatus(FileContext.java:1373)\n\tat org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAllContainersLogs(LogDumper.java:191)\n\tat org.apache.hadoop.yarn.logaggregation.LogDumper.run(LogDumper.java:107)\n\tat org.apache.hadoop.yarn.logaggregation.LogDumper.main(LogDumper.java:226)\n\nTrying to grab the logs via the \"mapred jobs -logs\" command results in this error:\n\n2012-01-27 14:05:52,040 INFO  mapred.ClientServiceDelegate (ClientServiceDelegate.java:getProxy(246)) - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2012-01-27 14:05:52,041 WARN  mapred.ClientServiceDelegate (ClientServiceDelegate.java:checkAndGetHSProxy(257)) - Job History Server is not configured.\nUnable to get log information for job: job_1327694122989_0001\n\nEven though the historyserver process is running."
        }
    },
    {
        "filename": "MAPREDUCE-6815.json",
        "creation_time": "2016-12-02T00:30:37.000+0000",
        "bug_report": {
            "Title": "Fix flaky TestKill.testKillTask()",
            "Description": "Error Message\nJob state is not correct (timedout) expected:<SUCCEEDED> but was:<ERROR>\nStacktrace\njava.lang.AssertionError: Job state is not correct (timedout) expected:<SUCCEEDED> but was:<ERROR>\nat org.junit.Assert.fail(Assert.java:88)\nat org.junit.Assert.failNotEquals(Assert.java:743)\nat org.junit.Assert.assertEquals(Assert.java:118)\nat org.apache.hadoop.mapreduce.v2.app.MRApp.waitForState(MRApp.java:416)\nat org.apache.hadoop.mapreduce.v2.app.TestKill.testKillTask(TestKill.java:124)"
        }
    },
    {
        "filename": "MAPREDUCE-3053.json",
        "creation_time": "2011-09-20T22:32:42.000+0000",
        "bug_report": {
            "Title": "YARN Protobuf RPC Failures in RM",
            "Description": "When I try to register my ApplicationMaster with YARN's RM, it fails.\n\nIn my ApplicationMaster's logs:\n\nException in thread \"main\" java.lang.reflect.UndeclaredThrowableException\n\tat org.apache.hadoop.yarn.api.impl.pb.client.AMRMProtocolPBClientImpl.registerApplicationMaster(AMRMProtocolPBClientImpl.java:108)\n\tat kafka.yarn.util.ApplicationMasterHelper.registerWithResourceManager(YarnHelper.scala:48)\n\tat kafka.yarn.ApplicationMaster$.main(ApplicationMaster.scala:32)\n\tat kafka.yarn.ApplicationMaster.main(ApplicationMaster.scala)\nCaused by: com.google.protobuf.ServiceException: java.lang.NullPointerException: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)\n\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:130)\n\tat $Proxy6.registerApplicationMaster(Unknown Source)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.AMRMProtocolPBClientImpl.registerApplicationMaster(AMRMProtocolPBClientImpl.java:101)\n\t... 3 more\nCaused by: java.lang.NullPointerException: java.lang.NullPointerException\n\tat org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)\n\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1084)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:127)\n\t... 5 more\n\n\nIn the ResourceManager's logs:\n\n2011-09-20 15:11:20,973 INFO  ipc.Server (Server.java:run(1497)) - IPC Server handler 2 on 8040, call: org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$ProtoSpecificRequestWritable@455dd32a from 127.0.0.1:33793, error: \njava.lang.NullPointerException\n\tat org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n\tat org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)\n\nMy registration code:\n\n    val appId = args(0).toInt\n    val attemptId = args(1).toInt\n    val timestamp = args(2).toLong\n\n    // these are our application master's parameters\n    val streamerClass = args(3)\n    val tasks = args(4).toInt\n\n    // TODO log params here\n\n    // start the application master helper\n    val conf = new Configuration\n    val applicationMasterHelper = new ApplicationMasterHelper(appId, attemptId, timestamp, conf)\n      .registerWithResourceManager\n\n  .....\n\n  val rpc = YarnRPC.create(conf)\n  val appId = Records.newRecord(classOf[ApplicationId])\n  val appAttemptId = Records.newRecord(classOf[ApplicationAttemptId])\n  val rmAddress = NetUtils.createSocketAddr(conf.get(YarnConfiguration.RM_ADDRESS, YarnConfiguration.DEFAULT_RM_ADDRESS))\n  val resourceManager = rpc.getProxy(classOf[AMRMProtocol], rmAddress, conf).asInstanceOf[AMRMProtocol]\n  var requestId = 0\n\n  appId.setClusterTimestamp(lTimestamp)\n  appId.setId(iAppId)\n  appAttemptId.setApplicationId(appId)\n  appAttemptId.setAttemptId(iAppAttemptId)\n\n  def registerWithResourceManager(): ApplicationMasterHelper = {\n    val req = Records.newRecord(classOf[RegisterApplicationMasterRequest])\n    req.setApplicationAttemptId(appAttemptId)\n    // TODO not sure why these are blank- This is how spark does it\n    req.setHost(\"\")\n    req.setRpcPort(1)\n    req.setTrackingUrl(\"\")\n    resourceManager.registerApplicationMaster(req)\n    this\n  }\n\nMy params are receiving the proper app/attempt/cluster timestamps:\n\napp - 1\nattempt - 1\ntimestamp - 1316556657998\n"
        }
    },
    {
        "filename": "MAPREDUCE-5884.json",
        "creation_time": "2014-04-16T01:07:22.000+0000",
        "bug_report": {
            "Title": "History server uses short user name when canceling tokens",
            "Description": "When the owner of a token tries to explicitly cancel the token, it gets the following error/exception\n{noformat} \n2014-04-14 20:07:35,744 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:<someuser>/<machine_name>.linkedin.com@<realm>.LINKEDIN.COM (auth:KERBEROS) cause:org.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token\n2014-04-14 20:07:35,744 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 10020, call org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB.cancelDelegationToken from 172.20.158.61:49042 Call#4 Retry#0: error: org.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token\norg.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token\n        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.cancelToken(AbstractDelegationTokenSecretManager.java:429)\n        at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.cancelDelegationToken(HistoryClientService.java:400)\n        at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.cancelDelegationToken(MRClientProtocolPBServiceImpl.java:286)\n        at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:301)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)\n        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)\n        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)\n\n{noformat}\n\n\nDetails:\nAbstractDelegationTokenSecretManager.cacelToken() gets the owner as full principal name where as the canceller is the short name.\nThe potential code snippets:\n{code}\nString owner = id.getUser().getUserName(); \n    Text renewer = id.getRenewer();\n    HadoopKerberosName cancelerKrbName = new HadoopKerberosName(canceller);\n    String cancelerShortName = cancelerKrbName.getShortName();\n    if (!canceller.equals(owner)\n        && (renewer == null || renewer.toString().isEmpty() || !cancelerShortName\n            .equals(renewer.toString()))) {\n      throw new AccessControlException(canceller\n          + \" is not authorized to cancel the token\");\n    }\n{code}\n\nThe code shows 'owner' gets the full principal name. Where as the value of 'canceller' depends on who is calling it. \nIn some cases, it is the short name. REF: HistoryClientService.java\n{code}\nString user = UserGroupInformation.getCurrentUser().getShortUserName();\n        jhsDTSecretManager.cancelToken(token, user);\n{code}\n \nIn other cases, the value could be full principal name. REF: FSNamesystem.java.\n{code}\nString canceller = getRemoteUser().getUserName();\n      DelegationTokenIdentifier id = dtSecretManager\n        .cancelToken(token, canceller);\n{code}\n\nPossible resolution:\n--------------------------\nOption 1: in cancelToken() method, compare with both : short name and full principal name.\nPros: Easy. Have to change in one place.\nCons: Someone can argue that it is hacky!\n \nOption 2:\nAll the caller sends the consistent value as 'canceller' : either short name or full principal name.\n\nPros: Cleaner.\nCons: A lot of code changes and potential bug injections.\n\nI'm open for both options.\nPlease give your opinion.\n\nBtw, how it is working now in most cases?  The short name and the full principal name are usually the same for end-users.\n\n\n"
        }
    },
    {
        "filename": "MAPREDUCE-3706.json",
        "creation_time": "2012-01-21T04:01:30.000+0000",
        "bug_report": {
            "Title": "HTTP Circular redirect error on the job attempts page",
            "Description": "submitted job and tried to go to following url:\n\nhttp://rmhost.domain.com:8088/proxy/application_1326992308313_0004/mapreduce/attempts/job_1326992308313_4_4/m/NEW\n\nThis resulted in the following HTTP ERROR:\n\nHTTP ERROR 500\n\nProblem accessing /proxy/application_1326992308313_0004/mapreduce/attempts/job_1326992308313_4_4/m/NEW. Reason:\n\n    Circular redirect to 'http://amhost.domain.com:44869/mapreduce/attempts/job_1326992308313_4_4/m/NEW'\n\nCaused by:\n\norg.apache.commons.httpclient.CircularRedirectException: Circular redirect to 'http://amhost.domain.com:44869/mapreduce/attempts/job_1326992308313_4_4/m/NEW'\n        at org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse(HttpMethodDirector.java:638)\n        at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:179)\n        at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)\n        at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)\n        at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:148)        at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:269)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:66)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)\n        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)\n\n\nNote that if you first go to the proxy at: http://rmhost.domain.com:8088/proxy/application_1326992308313_0004/ and then click the links to get here you don't get the error."
        }
    },
    {
        "filename": "MAPREDUCE-5451.json",
        "creation_time": "2013-05-30T00:08:18.000+0000",
        "bug_report": {
            "Title": "MR uses LD_LIBRARY_PATH which doesn't mean anything in Windows",
            "Description": "In order to set the path for loading native libraries, MR relies on the default value of the mapreduce.admin.user.env configuration setting the LD_LIBRARY_PATH environment entry. There are two problems with this setting in Windows:\na) LD_LIBRARY_PATH doesn't mean anything in Windows.\nb) It sets it using $HADOOP_COMMON_HOME, instead of %HADOOP_COMMON_HOME%.\n\nThe default value here should be platform-dependent (use the PATH variable in Windows instead of LD_LIBRARY_PATH), or we should rely on another mechanism. The net effect is that in Windows unless this configuration is over-ridden MR jobs fail with this error:\n\n{code}\n2013-05-29 13:51:41,049 FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:393)\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:928)\n\tat org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:177)\n\tat org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:164)\n\tat org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:98)\n\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(LocalDirAllocator.java:288)\n\tat org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:431)\n\tat org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:164)\n\tat org.apache.hadoop.mapred.YarnChild.configureLocalDirs(YarnChild.java:235)\n\tat org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:294)\n\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-2463.json",
        "creation_time": "2011-05-02T06:35:07.000+0000",
        "bug_report": {
            "Title": "Job History files are not moving to done folder when job history location is hdfs location",
            "Description": "If \"mapreduce.jobtracker.jobhistory.location\" is configured as HDFS location then either during initialization of Job Tracker (while moving old job history files) or after completion of the job, history files are not moving to done and giving following exception.\n\n{code:xml} \n2011-04-29 15:27:27,813 ERROR org.apache.hadoop.mapreduce.jobhistory.JobHistory: Unable to move history file to DONE folder.\njava.lang.IllegalArgumentException: Wrong FS: hdfs://10.18.52.146:9000/history/job_201104291518_0001_root, expected: file:///\n\tat org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:402)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:58)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:419)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:294)\n\tat org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:215)\n\tat org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1516)\n\tat org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1492)\n\tat org.apache.hadoop.fs.FileSystem.moveFromLocalFile(FileSystem.java:1482)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveToDoneNow(JobHistory.java:348)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistory.access$200(JobHistory.java:61)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistory$1.run(JobHistory.java:439)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)\n\n{code} \n"
        }
    },
    {
        "filename": "MAPREDUCE-3531.json",
        "creation_time": "2011-12-12T05:42:24.000+0000",
        "bug_report": {
            "Title": "Sometimes java.lang.IllegalArgumentException: Invalid key to HMAC computation in NODE_UPDATE also causing RM to stop scheduling ",
            "Description": "Filling this Jira a bit late\nStarted 350 cluster\nsbummited large sleep job.\nFoud that job was not running as RM has not allocated resouces to it.\n{code}\n2011-12-01 11:56:25,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <NMHost>:48490 clusterResources: memory: 3225600\n2011-12-01 11:56:25,202 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event\ntype NODE_UPDATE to the scheduler\njava.lang.IllegalArgumentException: Invalid key to HMAC computation\n        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:141)\n        at org.apache.hadoop.yarn.server.security.ContainerTokenSecretManager.createPassword(ContainerTokenSecretManager.java:61)\n        atorg.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.createContainer(LeafQueue.java:1108)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer(LeafQueue.java:1091)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1137)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1001)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:973)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:760)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:583)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:513)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:569)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:611)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:77)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:294)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.security.InvalidKeyException: Secret key expected\n        at com.sun.crypto.provider.HmacCore.a(DashoA13*..)\n        at com.sun.crypto.provider.HmacSHA1.engineInit(DashoA13*..)\n        at javax.crypto.Mac.init(DashoA13*..)\n        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:139)\n        ... 14 more\n{code}\nAs this stack is from 30 Nov checkou line number may be different"
        }
    },
    {
        "filename": "MAPREDUCE-3931.json",
        "creation_time": "2012-02-27T22:30:59.000+0000",
        "bug_report": {
            "Title": "MR tasks failing due to changing timestamps on Resources to download",
            "Description": "[~karams] reported this offline. Seems that tasks are randomly failing during gridmix runs:\n{code}\n2012-02-24 21:03:34,912 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1330116323296_0140_m_003868_0: RemoteTrace:\njava.io.IOException: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875\n       at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:90)\n       at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:49)\n       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:157)\n       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:155)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:396)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)\n       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:153)\n       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:49)\n       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n       at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n       at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n       at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n       at java.lang.Thread.run(Thread.java:619)\n at LocalTrace:\n       org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875\n       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217)\n       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147)\n       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:827)\n       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:497)\n       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:222)\n       at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46)\n       at org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57)\n       at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:342)\n       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1493)\n       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)\n       at java.security.AccessController.doPrivileged(Native Method)\n       at javax.security.auth.Subject.doAs(Subject.java:396)\n       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)\n       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1487)\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-4467.json",
        "creation_time": "2012-07-20T18:20:20.000+0000",
        "bug_report": {
            "Title": "IndexCache failures due to missing synchronization",
            "Description": "TestMRJobs.testSleepJob fails randomly due to synchronization error in IndexCache:\n\n{code}\n2012-07-20 19:32:34,627 ERROR [New I/O server worker #2-1] mapred.ShuffleHandler (ShuffleHandler.java:exceptionCaught(528)) - Shuffle error: \njava.lang.IllegalMonitorStateException\n\tat java.lang.Object.wait(Native Method)\n\tat org.apache.hadoop.mapred.IndexCache.getIndexInformation(IndexCache.java:74)\n\tat org.apache.hadoop.mapred.ShuffleHandler$Shuffle.sendMapOutput(ShuffleHandler.java:471)\n\tat org.apache.hadoop.mapred.ShuffleHandler$Shuffle.messageReceived(ShuffleHandler.java:397)\n\tat org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:148)\n\tat org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:116)\n\tat org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:302)\n\tat org.jboss.netty.handler.codec.replay.ReplayingDecoder.unfoldAndfireMessageReceived(ReplayingDecoder.java:522)\n\tat org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:506)\n\tat org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443)\n\tat org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274)\n\tat org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261)\n\tat org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:349)\n\tat org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280)\n\tat org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n\nA related issue is MAPREDUCE-4384. The change introduced there removed \"synchronized\" keyword and hence \"info.wait()\" call fails. Tbis needs to be wrapped into a \"synchronized\" block."
        }
    },
    {
        "filename": "MAPREDUCE-3463.json",
        "creation_time": "2011-11-23T13:45:46.000+0000",
        "bug_report": {
            "Title": "Second AM fails to recover properly when first AM is killed with java.lang.IllegalArgumentException causing lost job",
            "Description": "Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn 4 Node cluster.\nFirst Ran Randowriter/Sort/Sort-validate successfully\nThen again sort, when job was 50% complete\nLogin node running AppMaster, and killed AppMaster with kill -9\nOn Client side failed with following:\n{code}\n11/11/23 10:57:27 INFO mapreduce.Job:  map 58% reduce 8%\n11/11/23 10:57:27 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1322040898409_0005 retrying..\n11/11/23 10:57:28 INFO mapreduce.Job:  map 0% reduce 0%\n11/11/23 10:57:37 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=UNDEFINED. Redirecting to job history server\n11/11/23 10:57:37 INFO client.ClientTokenSelector: Looking for a token with service <RM Host>:Port\n11/11/23 10:57:37 INFO client.ClientTokenSelector: Token kind is YARN_CLIENT_TOKEN and the token's service name is <New AM Host>:Port\n11/11/23 10:57:38 WARN mapred.ClientServiceDelegate: Error from remote end: Unknown job job_1322040898409_0005\nRemoteTrace: \n at Local Trace: \n\torg.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1322040898409_0005\n\tat org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151)\n\tat $Proxy10.getTaskAttemptCompletionEvents(Unknown Source)\n\tat org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:172)\n\tat sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:273)\n\tat org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:320)\n\tat org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:438)\n\tat org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:621)\n\tat org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1231)\n\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1179)\n\tat org.apache.hadoop.examples.Sort.run(Sort.java:181)\n\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)\n\tat org.apache.hadoop.examples.Sort.main(Sort.java:192)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)\n\tat org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)\n\tat org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:189)\n{code}\n\nOn lookig RM logs found second AM was also lauched, it was saying -:\n{code}\n011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1322040898409_0005_000002 State change from RUNNING to FINISHED\n2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Processing event for application_1322040898409_0005 of type ATTEMPT_FINISHED\n2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1322040898409_0005 State change from RUNNING to FINISHED\n2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1322040898409_0005_000002 is done. finalState=FINISHED\n{code}\n\nNow looking at AM logs and found Second AM was shutdown gracefully due to :-\n{code}\n2011-11-23 10:57:37,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService: Sending assigned event to attempt_1322040898409_0005_m_000000_0\n2011-11-23 10:57:37,641 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..\njava.lang.IllegalArgumentException: Invalid NodeId [<NMHostName>]. Expected host:port\n        at org.apache.hadoop.yarn.util.ConverterUtils.toNodeId(ConverterUtils.java:144)\n        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.sendAssignedEvent(RecoveryService.java:410)\n        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.handle(RecoveryService.java:314)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:1010)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:985)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:851)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:128)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:853)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:845)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)\n        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:270)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n        at java.lang.Thread.run(Thread.java:619)\n2011-11-23 10:57:37,642 INFO [CompositeServiceShutdownHook for org.apache.hadoop.mapreduce.v2.app.MRAppMaster] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-4164.json",
        "creation_time": "2012-04-17T21:30:13.000+0000",
        "bug_report": {
            "Title": "Hadoop 22 Exception thrown after task completion causes its reexecution",
            "Description": "2012-02-28 19:17:08,504 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1969310 bytes\n2012-02-28 19:17:08,694 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000094_0 is done. And is in the process of commiting\n2012-02-28 19:18:08,774 INFO org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Call to /127.0.0.1:35400 failed on local exception: java.nio.channels.ClosedByInterruptException\nat org.apache.hadoop.ipc.Client.wrapException(Client.java:1094)\nat org.apache.hadoop.ipc.Client.call(Client.java:1062)\nat org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)\nat $Proxy0.statusUpdate(Unknown Source)\nat org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:650)\nat java.lang.Thread.run(Thread.java:662)\nCaused by: java.nio.channels.ClosedByInterruptException\nat java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)\nat sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)\nat org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)\nat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\nat org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)\nat org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)\nat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)\nat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)\nat java.io.DataOutputStream.flush(DataOutputStream.java:106)\nat org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:769)\nat org.apache.hadoop.ipc.Client.call(Client.java:1040)\n... 4 more\n\n2012-02-28 19:18:08,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000094_0' done.\n\n\n================>>>>>> SHOULD be <++++++++++++++\n2012-02-28 19:17:02,214 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1974104 bytes\n2012-02-28 19:17:02,408 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000000_0 is done. And is in the process of commiting\n2012-02-28 19:17:02,519 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000000_0' done. "
        }
    },
    {
        "filename": "MAPREDUCE-5260.json",
        "creation_time": "2013-05-20T05:43:32.000+0000",
        "bug_report": {
            "Title": "Job failed because of JvmManager running into inconsistent state",
            "Description": "In our cluster, jobs failed due to randomly task initialization failed because of JvmManager running into inconsistent state and TaskTracker failed to exit:\n\njava.lang.Throwable: Child Error\n\tat org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)\n\tat org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)\n\tat org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)\n\tat org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)\n\n-------\njava.lang.Throwable: Child Error\n\tat org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)\nCaused by: java.lang.NullPointerException\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)\n\tat org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)\n\tat org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)\n\tat org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)\n\tat org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)"
        }
    },
    {
        "filename": "MAPREDUCE-4774.json",
        "creation_time": "2012-11-06T11:28:43.000+0000",
        "bug_report": {
            "Title": "JobImpl does not handle asynchronous task events in FAILED state",
            "Description": "The test org.apache.hadoop.mapred.TestClusterMRNotification.testMR frequently  fails in mapred build (e.g. see https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2988/testReport/junit/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/ , or \nhttps://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2982//testReport/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/).\n\nThe test aims to check Job status notifications received through HTTP Servlet. It runs 3 jobs: successfull, killed, and failed. \nThe test expects the servlet to receive some expected notifications in some expected order. It also tries to test the retry-on-failure notification functionality, so on each 1st notification the servlet answers \"400 forcing error\", and on each 2nd notification attempt it answers \"ok\". \nIn general, the test fails because the actual number and/or type of the notifications differs from the expected.\n\nInvestigation shows that actual root cause of the problem is an incorrect job state transition: the 3rd job mapred task fails (by intentionally thrown  RuntimeException, see UtilsForTests#runJobFail()), and the state of the task changes from RUNNING to FAILED.\nAt this point JobEventType.JOB_TASK_ATTEMPT_COMPLETED event is submitted (in  method org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handleTaskAttemptCompletion(TaskAttemptId, TaskAttemptCompletionEventStatus)), and this event gets processed in AsyncDispatcher, but this transition is impossible according to the event transition map (see org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl#stateMachineFactory). This causes the following exception to be thrown upon the event processing:\n2012-11-06 12:22:02,335 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:309)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:290)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:454)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:716)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:917)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:79)\n        at java.lang.Thread.run(Thread.java:662) \n\nSo, the job gets into state \"INTERNAL_ERROR\", the job end notification like this is sent:\nhttp://localhost:48656/notification/mapred?jobId=job_1352199715842_0002&amp;jobStatus=ERROR \n(here we can see \"ERROR\" status instead of \"FAILED\")\nAfter that the notification servlet receives either only \"ERROR\" notification, or one more notification \"ERROR\" after \"FAILED\", which finally causes the test to fail. (Some variation in the test behavior caused by racing conditions because there are many asynchronous processings there, and the test is flaky, in fact).\n\nIn any way, it looks like the root cause of the problem is the possibility of the forbidden transition \"Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED\". \nNeed an expert advice on how that should be fixed."
        }
    },
    {
        "filename": "MAPREDUCE-3005.json",
        "creation_time": "2011-09-14T04:29:08.000+0000",
        "bug_report": {
            "Title": "MR app hangs because of a NPE in ResourceManager",
            "Description": "The app hangs and it turns out to be a NPE in ResourceManager. This happened two of five times on [~karams]'s sort runs on a big cluster.\n{code}\n2011-09-12 15:02:33,715 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\njava.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:244)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:206)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:230)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1120)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:961)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:725)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:577)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:509)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:579)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:620)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:75)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:266)\n        at java.lang.Thread.run(Thread.java:619)\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-6895.json",
        "creation_time": "2017-05-25T21:07:48.000+0000",
        "bug_report": {
            "Title": "Job end notification not send due to YarnRuntimeException",
            "Description": "MRAppMaster.this.stop() throw out YarnRuntimeException as below log shows, it caused job end notification not send.\n{quote}\n2017-05-24 12:14:02,165 WARN [Thread-693] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Graceful stop failed\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException\n        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:531)\n        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:360)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)\n        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)\n        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)\n        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1476)\n        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1090)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:554)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$1.run(MRAppMaster.java:605)\nCaused by: java.nio.channels.ClosedChannelException\n        at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:1528)\n        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:98)\n        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)\n        at java.io.DataOutputStream.write(DataOutputStream.java:107)\n        at org.codehaus.jackson.impl.Utf8Generator._flushBuffer(Utf8Generator.java:1754)\n        at org.codehaus.jackson.impl.Utf8Generator.flush(Utf8Generator.java:1088)\n        at org.apache.avro.io.JsonEncoder.flush(JsonEncoder.java:67)\n        at org.apache.hadoop.mapreduce.jobhistory.EventWriter.write(EventWriter.java:67)\n        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$MetaInfo.writeEvent(JobHistoryEventHandler.java:886)\n        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:520)\n        ... 11 more\n2017-05-24 12:14:02,165 INFO [Thread-693] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Exiting MR AppMaster..GoodBye!\n{quote}"
        }
    },
    {
        "filename": "MAPREDUCE-4451.json",
        "creation_time": "2012-07-17T10:34:13.000+0000",
        "bug_report": {
            "Title": "fairscheduler fail to init job with kerberos authentication configured",
            "Description": "Using FairScheduler in Hadoop 1.0.3 with kerberos authentication configured. Job initialization fails:\n\n{code}\n2012-07-17 15:15:09,220 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:\njava.io.IOException: Call to /192.168.7.80:8020 failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1129)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1097)\n        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)\n        at $Proxy7.getProtocolVersion(Unknown Source)\n        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:411)\n        at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:125)\n        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:329)\n        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:294)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)\n        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1411)\n        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)\n        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1429)\n        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)\n        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)\n        at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:169)\n        at org.apache.hadoop.mapred.JobInProgress.generateAndStoreTokens(JobInProgress.java:3558)\n        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:696)\n        at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:3911)\n        at org.apache.hadoop.mapred.FairScheduler$JobInitializer$InitJob.run(FairScheduler.java:301)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\nCaused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:543)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)\n        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:488)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:590)\n        at org.apache.hadoop.ipc.Client$Connection.access$2100(Client.java:187)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1228)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1072)\n        ... 20 more\nCaused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)\n        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:134)\n        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:385)\n        at org.apache.hadoop.ipc.Client$Connection.access$1200(Client.java:187)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:583)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:580)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:396)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:579)\n        ... 23 more\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\n        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:130)\n        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)\n        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)\n        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:175)\n        ... 32 more\n\n{code}\n\nWhen a job is submitted, fairscheduler calls JobTracker.initJob, which calls JobInProgress.generateAndStoreTokens to write security keys to hdfs. However, the operation is involved in the server side rpc call path, using UGI created by UserGroupInformation.createRemoteUser in rpc server, which have no tgt. This should be done with UGI used by JobTracker."
        }
    },
    {
        "filename": "MAPREDUCE-4144.json",
        "creation_time": "2012-04-12T16:28:30.000+0000",
        "bug_report": {
            "Title": "ResourceManager NPE while handling NODE_UPDATE",
            "Description": "The RM on one of our clusters has exited twice in the past few days because of an NPE while trying to handle a NODE_UPDATE:\n\n{noformat}\n2012-04-12 02:09:01,672 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler\n [ResourceManager Event Processor]java.lang.NullPointerException\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:261)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:223)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:246)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1229)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1078)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1048)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignReservedContainer(LeafQueue.java:859)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:756)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:573)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:622)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:78)\n        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:302)\n        at java.lang.Thread.run(Thread.java:619)\n{noformat}\n\nThis is very similar to the failure reported in MAPREDUCE-3005."
        }
    },
    {
        "filename": "MAPREDUCE-5924.json",
        "creation_time": "2014-06-13T05:02:09.000+0000",
        "bug_report": {
            "Title": "Windows: Sort Job failed due to 'Invalid event: TA_COMMIT_PENDING at COMMIT_PENDING'",
            "Description": "The Sort job over 1GB data failed with below error\n{code}\n2014-06-09 09:15:38,746 INFO [Socket Reader #1 for port 63415] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1402304714683_0002 (auth:SIMPLE)\n2014-06-09 09:15:38,750 INFO [IPC Server handler 13 on 63415] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1402304714683_0002_r_000015_1000\n2014-06-09 09:15:38,751 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1402304714683_0002_r_000015_1000\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_COMMIT_PENDING at COMMIT_PENDING\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1058)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:145)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1271)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1263)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:722)\n2014-06-09 09:15:38,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1402304714683_0002Job Transitioned from RUNNING to ERROR\n\n{code}\n\nThe JobHistory Url prints job state = ERROR"
        }
    },
    {
        "filename": "MAPREDUCE-3649.json",
        "creation_time": "2012-01-09T23:53:06.000+0000",
        "bug_report": {
            "Title": "Job End notification gives an error on calling back.",
            "Description": "When calling job end notification for oozie the AM fails with the following trace:\n\n{noformat}\n2012-01-09 23:45:41,732 WARN [AsyncDispatcher event handler] org.mortbay.log: Job end notification to http://HOST:11000/oozie/v0/callback?id=0000000-120109234442311-oozie-oozi-W@mr-node&status=SUCCEEDED& failed\njava.net.UnknownServiceException: no content-type\n\tat java.net.URLConnection.getContentHandler(URLConnection.java:1192)\n\tat java.net.URLConnection.getContent(URLConnection.java:689)\n\tat org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce(JobEndNotifier.java:95)\n\tat org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notify(JobEndNotifier.java:139)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:388)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:375)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-7077.json",
        "creation_time": "2018-04-11T18:35:34.000+0000",
        "bug_report": {
            "Title": "Pipe mapreduce job fails with Permission denied for jobTokenPassword",
            "Description": "Steps:\r\n\r\nLaunch wordcount example with pipe\r\n{code}\r\n/usr/hdp/current/hadoop-client/bin/hadoop pipes \"-Dhadoop.pipes.java.recordreader=true\" \"-Dhadoop.pipes.java.recordwriter=true\" -input pipeInput -output pipeOutput -program bin/wordcount{code}\r\n\r\nThe application fails with below stacktrace\r\n{code:title=AM}\r\nattempt_1517534613368_0041_r_000000_2 is : 0.0\r\n\r\n2018-02-02 02:40:51,071 ERROR [IPC Server handler 16 on 43391] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1517534613368_0041_r_000000_2 - exited : java.io.FileNotFoundException: /grid/0/hadoop/yarn/local/usercache/hrt_qa/appcache/application_1517534613368_0041/jobTokenPassword (Permission denied)\r\n\r\n at java.io.FileOutputStream.open0(Native Method)\r\n\r\n at java.io.FileOutputStream.open(FileOutputStream.java:270)\r\n\r\n at java.io.FileOutputStream.<init>(FileOutputStream.java:213)\r\n\r\n at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:236)\r\n\r\n at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)\r\n\r\n at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)\r\n\r\n at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)\r\n\r\n at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)\r\n\r\n at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)\r\n\r\n at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)\r\n\r\n at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)\r\n\r\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)\r\n\r\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1149)\r\n\r\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1038)\r\n\r\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1026)\r\n\r\n at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:703)\r\n\r\n at org.apache.hadoop.mapred.pipes.Application.writePasswordToLocalFile(Application.java:173)\r\n\r\n at org.apache.hadoop.mapred.pipes.Application.<init>(Application.java:109)\r\n\r\n at org.apache.hadoop.mapred.pipes.PipesReducer.startApplication(PipesReducer.java:87)\r\n\r\n at org.apache.hadoop.mapred.pipes.PipesReducer.reduce(PipesReducer.java:65)\r\n\r\n at org.apache.hadoop.mapred.pipes.PipesReducer.reduce(PipesReducer.java:38)\r\n\r\n at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:445)\r\n\r\n at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:393)\r\n\r\n at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)\r\n\r\n at java.security.AccessController.doPrivileged(Native Method)\r\n\r\n at javax.security.auth.Subject.doAs(Subject.java:422)\r\n\r\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)\r\n\r\n at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)\r\n{code}\r\n"
        }
    },
    {
        "filename": "MAPREDUCE-4102.json",
        "creation_time": "2012-04-03T19:51:52.000+0000",
        "bug_report": {
            "Title": "job counters not available in Jobhistory webui for killed jobs",
            "Description": "Run a simple wordcount or sleep, and kill the job before it finishes.  Go to the job history web ui and click the \"Counters\" link for that job. It displays \"500 error\".\n\nThe job history log has:\n\nCaused by: com.google.inject.ProvisionException: Guice provision errors:\n\n2012-04-03 19:42:53,148 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /jobhistory/jobcounters/job_1333482028750_0001\njava.lang.reflect.InvocationTargetException\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n    at java.lang.reflect.Method.invoke(Method.java:597)\n...\n..\n...\n\n1) Error injecting constructor, java.lang.NullPointerException\n  at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.<init>(CountersBlock.java:56)\n  while locating org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock\n...\n..\n...\nCaused by: java.lang.NullPointerException    at org.apache.hadoop.mapreduce.counters.AbstractCounters.incrAllCounters(AbstractCounters.java:328)\n    at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters(CountersBlock.java:188)\n    at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.<init>(CountersBlock.java:57)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\n\nThere are task counters available if you drill down into successful tasks though."
        }
    },
    {
        "filename": "MAPREDUCE-6353.json",
        "creation_time": "2015-05-03T14:10:44.000+0000",
        "bug_report": {
            "Title": "Divide by zero error in MR AM when calculating available containers",
            "Description": "When running a sleep job with zero CPU vcores i see the following exception\n\n2015-04-30 06:41:06,954 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. \njava.lang.ArithmeticException: / by zero\nat org.apache.hadoop.mapreduce.v2.app.rm.ResourceCalculatorUtils.computeAvailableContainers(ResourceCalculatorUtils.java:38)\nat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:947)\nat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$200(RMContainerAllocator.java:840)\nat org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:247)\nat org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:282)\nat java.lang.Thread.run(Thread.java:745)"
        }
    },
    {
        "filename": "MAPREDUCE-4913.json",
        "creation_time": "2013-01-05T02:41:54.000+0000",
        "bug_report": {
            "Title": "TestMRAppMaster#testMRAppMasterMissingStaging occasionally exits",
            "Description": "testMRAppMasterMissingStaging will sometimes cause the JVM to exit due to this error from AsyncDispatcher:\n\n{noformat}\n2013-01-05 02:14:54,682 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(137)) - Error in dispatcher thread\njava.lang.Exception: No handler for registered for class org.apache.hadoop.mapreduce.jobhistory.EventType, cannot deliver EventType: AM_STARTED\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:132)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n        at java.lang.Thread.run(Thread.java:662)\n2013-01-05 02:14:54,682 INFO  [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(140)) - Exiting, bbye..\n{noformat}\n\nThis can cause a build to fail since the test process exits without unregistering from surefire which treats it as a build error rather than a test failure."
        }
    },
    {
        "filename": "MAPREDUCE-6492.json",
        "creation_time": "2015-09-28T10:16:44.000+0000",
        "bug_report": {
            "Title": "AsyncDispatcher exit with NPE on TaskAttemptImpl#sendJHStartEventForAssignedFailTask",
            "Description": "For {{TaskAttemptImpl#DeallocateContainerTransition}} {{sendJHStartEventForAssignedFailTask}} is send for TaskAttemptStateInternal.UNASSIGNED also .\n\n\nCausing NPE on {{taskAttempt.container.getNodeHttpAddress()}} \n\n\n{noformat}\n2015-09-28 18:01:48,656 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread\njava.lang.NullPointerException\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.sendJHStartEventForAssignedFailTask(TaskAttemptImpl.java:1494)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.access$2900(TaskAttemptImpl.java:147)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$DeallocateContainerTransition.transition(TaskAttemptImpl.java:1700)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$DeallocateContainerTransition.transition(TaskAttemptImpl.java:1686)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:290)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1190)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:146)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1415)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1407)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)\n\tat java.lang.Thread.run(Thread.java:745)\n2015-09-28 18:01:48,660 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..\n2015-09-28 18:01:48,660 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_e04_1443430524957_0006_01_000059 taskAttempt attempt_1443430524957_0006_m_000000_9\n{noformat}\n\nLog aggregation fail for mapreduce application.\n"
        }
    },
    {
        "filename": "MAPREDUCE-5744.json",
        "creation_time": "2014-02-06T19:05:01.000+0000",
        "bug_report": {
            "Title": "Job hangs because RMContainerAllocator$AssignedRequests.preemptReduce() violates the comparator contract",
            "Description": "We ran into a situation where tasks are not getting assigned because RMContainerAllocator$AssignedRequests.preemptReduce() fails repeatedly with the following exception:\n\n{code}\n2014-02-06 16:43:45,183 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.\njava.lang.IllegalArgumentException: Comparison method violates its general contract!\n     at java.util.TimSort.mergeLo(TimSort.java:747)\n     at java.util.TimSort.mergeAt(TimSort.java:483)\n     at java.util.TimSort.mergeCollapse(TimSort.java:408)\n     at java.util.TimSort.sort(TimSort.java:214)\n     at java.util.TimSort.sort(TimSort.java:173)\n     at java.util.Arrays.sort(Arrays.java:659)\n     at java.util.Collections.sort(Collections.java:217)\n     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$AssignedRequests.preemptReduce(RMContainerAllocator.java:1106)\n     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.preemptReducesIfNeeded(RMContainerAllocator.java:416)\n     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:230)\n     at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:252)\n     at java.lang.Thread.run(Thread.java:744)\n{code}\n\nIt is because the comparator that's defined in this method does not abide by the contract, specifically if p == 0.\n\nComparator.compare(): http://docs.oracle.com/javase/7/docs/api/java/util/Comparator.html#compare(T, T)"
        }
    },
    {
        "filename": "MAPREDUCE-3583.json",
        "creation_time": "2011-12-20T15:07:55.000+0000",
        "bug_report": {
            "Title": "ProcfsBasedProcessTree#constructProcessInfo() may throw NumberFormatException",
            "Description": "HBase PreCommit builds frequently gave us NumberFormatException.\n\nFrom https://builds.apache.org/job/PreCommit-HBASE-Build/553//testReport/org.apache.hadoop.hbase.mapreduce/TestHFileOutputFormat/testMRIncrementalLoad/:\n{code}\n2011-12-20 01:44:01,180 WARN  [main] mapred.JobClient(784): No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).\njava.lang.NumberFormatException: For input string: \"18446743988060683582\"\n\tat java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)\n\tat java.lang.Long.parseLong(Long.java:422)\n\tat java.lang.Long.parseLong(Long.java:468)\n\tat org.apache.hadoop.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree.java:413)\n\tat org.apache.hadoop.util.ProcfsBasedProcessTree.getProcessTree(ProcfsBasedProcessTree.java:148)\n\tat org.apache.hadoop.util.LinuxResourceCalculatorPlugin.getProcResourceValues(LinuxResourceCalculatorPlugin.java:401)\n\tat org.apache.hadoop.mapred.Task.initialize(Task.java:536)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:353)\n\tat org.apache.hadoop.mapred.Child$4.run(Child.java:255)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1083)\n\tat org.apache.hadoop.mapred.Child.main(Child.java:249)\n{code}\nFrom hadoop 0.20.205 source code, looks like ppid was 18446743988060683582, causing NFE:\n{code}\n        // Set (name) (ppid) (pgrpId) (session) (utime) (stime) (vsize) (rss)\n         pinfo.updateProcessInfo(m.group(2), Integer.parseInt(m.group(3)),\n{code}\nYou can find information on the OS at the beginning of https://builds.apache.org/job/PreCommit-HBASE-Build/553/console:\n{code}\nasf011.sp2.ygridcore.net\nLinux asf011.sp2.ygridcore.net 2.6.32-33-server #71-Ubuntu SMP Wed Jul 20 17:42:25 UTC 2011 x86_64 GNU/Linux\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 20\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 16382\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 60000\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 2048\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n60000\nRunning in Jenkins mode\n{code}\n\nFrom Nicolas Sze:\n{noformat}\nIt looks like that the ppid is a 64-bit positive integer but Java long is signed and so only works with 63-bit positive integers.  In your case,\n\n  2^64 > 18446743988060683582 > 2^63.\n\nTherefore, there is a NFE. \n{noformat}\n\nI propose changing allProcessInfo to Map<String, ProcessInfo> so that we don't encounter this problem by avoiding parsing large integer."
        }
    },
    {
        "filename": "MAPREDUCE-2238.json",
        "creation_time": "2011-01-03T22:57:22.000+0000",
        "bug_report": {
            "Title": "Undeletable build directories ",
            "Description": "The MR hudson job is failing, looks like it's due to a test chmod'ing a build directory so the checkout can't clean the build dir.\n\nhttps://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/549/console\n\nBuilding remotely on hadoop7\nhudson.util.IOException2: remote file operation failed: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk at hudson.remoting.Channel@2545938c:hadoop7\n\tat hudson.FilePath.act(FilePath.java:749)\n\tat hudson.FilePath.act(FilePath.java:735)\n\tat hudson.scm.SubversionSCM.checkout(SubversionSCM.java:589)\n\tat hudson.scm.SubversionSCM.checkout(SubversionSCM.java:537)\n\tat hudson.model.AbstractProject.checkout(AbstractProject.java:1116)\n\tat hudson.model.AbstractBuild$AbstractRunner.checkout(AbstractBuild.java:479)\n\tat hudson.model.AbstractBuild$AbstractRunner.run(AbstractBuild.java:411)\n\tat hudson.model.Run.run(Run.java:1324)\n\tat hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:46)\n\tat hudson.model.ResourceController.execute(ResourceController.java:88)\n\tat hudson.model.Executor.run(Executor.java:139)\nCaused by: java.io.IOException: Unable to delete /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/logs/userlogs/job_20101230131139886_0001/attempt_20101230131139886_0001_m_000000_0"
        }
    },
    {
        "filename": "MAPREDUCE-6410.json",
        "creation_time": "2015-06-04T06:34:33.000+0000",
        "bug_report": {
            "Title": "Aggregated Logs Deletion doesnt work after refreshing Log Retention Settings in secure cluster",
            "Description": "{{GSSException}} is thrown everytime log aggregation deletion is attempted after executing bin/mapred hsadmin -refreshLogRetentionSettings in a secure cluster.\n\nThe problem can be reproduced by following steps:\n1. startup historyserver in secure cluster.\n2. Log deletion happens as per expectation. \n3. execute {{mapred hsadmin -refreshLogRetentionSettings}} command to refresh the configuration value.\n4. All the subsequent attempts of log deletion fail with {{GSSException}}\n\nFollowing exception can be found in historyserver's log if log deletion is enabled. \n{noformat}\n2015-06-04 14:14:40,070 | ERROR | Timer-3 | Error reading root log dir this deletion attempt is being aborted | AggregatedLogDeletionService.java:127\njava.io.IOException: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]; Host Details : local host is: \"vm-31/9.91.12.31\"; destination host is: \"vm-33\":25000; \n        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1414)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1363)\n        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n        at com.sun.proxy.$Proxy9.getListing(Unknown Source)\n        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:519)\n        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)\n        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n        at com.sun.proxy.$Proxy10.getListing(Unknown Source)\n        at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1767)\n        at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1750)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:691)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:102)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:753)\n        at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:749)\n        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:749)\n        at org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.run(AggregatedLogDeletionService.java:68)\n        at java.util.TimerThread.mainLoop(Timer.java:555)\n        at java.util.TimerThread.run(Timer.java:505)\nCaused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:677)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1641)\n        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:640)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)\n        at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)\n        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1462)\n        at org.apache.hadoop.ipc.Client.call(Client.java:1381)\n        ... 21 more\nCaused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212)\n        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:411)\n        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:550)\n        at org.apache.hadoop.ipc.Client$Connection.access$1800(Client.java:367)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:716)\n        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:712)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1641)\n        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:711)\n        ... 24 more\nCaused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)\n        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:147)\n        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:121)\n        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:187)\n        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:223)\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212)\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179)\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193)\n        ... 33 more\n{noformat}"
        }
    },
    {
        "filename": "MAPREDUCE-6693.json",
        "creation_time": "2016-05-10T11:30:38.000+0000",
        "bug_report": {
            "Title": "ArrayIndexOutOfBoundsException occurs when the length of the job name is equal to mapreduce.jobhistory.jobname.limit",
            "Description": "Job history entry missing when JOB name is of {{mapreduce.jobhistory.jobname.limit}} character\n\n{noformat}\n2016-05-10 06:51:00,674 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Interrupting Event Handling thread\n2016-05-10 06:51:00,674 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Waiting for Event Handling thread to complete\n2016-05-10 06:51:00,674 ERROR [eventHandlingThread] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[eventHandlingThread,5,main] threw an Exception.\njava.lang.ArrayIndexOutOfBoundsException: 50\n\tat org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.trimURLEncodedString(FileNameIndexUtils.java:326)\n\tat org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.getDoneFileName(FileNameIndexUtils.java:86)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:1147)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:635)\n\tat org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$1.run(JobHistoryEventHandler.java:341)\n\tat java.lang.Thread.run(Thread.java:745)\n2016-05-10 06:51:00,675 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Shutting down timer for Job MetaInfo for job_1462840033869_0009 history file hdfs://hacluster:9820/staging-dir/dsperf/.staging/job_1462840033869_0009/job_1462840033869_0009_1.jhist\n2016-05-10 06:51:00,675 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Shutting down timer Job MetaInfo for job_1462840033869_0009 history file hdfs://hacluster:9820/staging-dir/dsperf/.staging/job_1462840033869_0009/job_1462840033869_0009_1.jhist\n2016-05-10 06:51:00,676 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Closing Writer\n{noformat}\n\nLooks like 50 character check is going wrong"
        }
    },
    {
        "filename": "MAPREDUCE-5912.json",
        "creation_time": "2014-06-04T15:37:03.000+0000",
        "bug_report": {
            "Title": "Task.calculateOutputSize does not handle Windows files after MAPREDUCE-5196",
            "Description": "{code}\n@@ -1098,8 +1120,8 @@ private long calculateOutputSize() throws IOException {\n     if (isMapTask() && conf.getNumReduceTasks() > 0) {\n       try {\n         Path mapOutput =  mapOutputFile.getOutputFile();\n-        FileSystem localFS = FileSystem.getLocal(conf);\n-        return localFS.getFileStatus(mapOutput).getLen();\n+        FileSystem fs = mapOutput.getFileSystem(conf);\n+        return fs.getFileStatus(mapOutput).getLen();\n       } catch (IOException e) {\n         LOG.warn (\"Could not find output size \" , e);\n       }\n{code}\n\ncauses Windows local output files to be routed through HDFS:\n\n{code}\n2014-06-02 00:14:53,891 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.IllegalArgumentException: Pathname /c:/Hadoop/Data/Hadoop/local/usercache/HadoopUser/appcache/application_1401693085139_0001/output/attempt_1401693085139_0001_m_000000_0/file.out from c:/Hadoop/Data/Hadoop/local/usercache/HadoopUser/appcache/application_1401693085139_0001/output/attempt_1401693085139_0001_m_000000_0/file.out is not a valid DFS filename.\n       at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:187)\n       at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:101)\n       at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1024)\n       at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1020)\n       at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n       at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1020)\n       at org.apache.hadoop.mapred.Task.calculateOutputSize(Task.java:1124)\n       at org.apache.hadoop.mapred.Task.sendLastUpdate(Task.java:1102)\n       at org.apache.hadoop.mapred.Task.done(Task.java:1048)\n{code}\n"
        }
    },
    {
        "filename": "MAPREDUCE-5952.json",
        "creation_time": "2014-06-30T23:08:52.000+0000",
        "bug_report": {
            "Title": "LocalContainerLauncher#renameMapOutputForReduce incorrectly assumes a single dir for mapOutIndex",
            "Description": "The javadoc comment for {{renameMapOutputForReduce}} incorrectly refers to a single map output directory, whereas this depends on LOCAL_DIRS.\nmapOutIndex should be set to subMapOutputFile.getOutputIndexFile()\n\n{code}\n2014-06-30 14:48:35,574 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.io.FileNotFoundException: File /Users/gshegalov/workspace/hadoop-common/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapreduce.v2.TestMRJobs/org.apache.hadoop.mapreduce.v2.          TestMRJobs-localDir-nm-2_3/usercache/gshegalov/appcache/application_1404164272885_0001/output/file.out.index does not exist\n  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:517)\n  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:726)\n  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:507)\n  at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337)                      \n  at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289)                          \n  at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:334)    \n  at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:504)\n  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.renameMapOutputForReduce(LocalContainerLauncher.java:471)\n  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:370)\n  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:292)\n  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:178)\n  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:221)\n  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    \n  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)         \n  at java.util.concurrent.FutureTask.run(FutureTask.java:138)                       \n  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n  at java.lang.Thread.run(Thread.java:695)         \n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-3306.json",
        "creation_time": "2011-10-28T16:59:34.000+0000",
        "bug_report": {
            "Title": "Cannot run apps after MAPREDUCE-2989",
            "Description": "Seeing this in NM logs when trying to run jobs.\n{code}\n2011-10-28 21:40:21,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Processing application_1319818154209_0001 of type APPLICATION_INITED\n2011-10-28 21:40:21,264 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..\njava.util.NoSuchElementException\n        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:796)\n        at java.util.HashMap$ValueIterator.next(HashMap.java:822)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:251)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:245)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:385)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:407)\n        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:399)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n        at java.lang.Thread.run(Thread.java:662)\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-6554.json",
        "creation_time": "2015-11-21T07:34:31.000+0000",
        "bug_report": {
            "Title": "MRAppMaster servicestart failing  with NPE in MRAppMaster#parsePreviousJobHistory",
            "Description": "Create scenario so that MR app master gets preempted.\nOn next MRAppMaster launch tried to recover previous job history file {{MRAppMaster#parsePreviousJobHistory}}\n\n\n{noformat}\n2015-11-21 13:52:27,722 INFO [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state STARTED; cause: java.lang.NullPointerException\njava.lang.NullPointerException\n        at java.io.StringReader.<init>(StringReader.java:50)\n        at org.apache.avro.Schema$Parser.parse(Schema.java:917)\n        at org.apache.avro.Schema.parse(Schema.java:966)\n        at org.apache.hadoop.mapreduce.jobhistory.EventReader.<init>(EventReader.java:75)\n        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:139)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.parsePreviousJobHistory(MRAppMaster.java:1256)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.processRecovery(MRAppMaster.java:1225)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1087)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$4.run(MRAppMaster.java:1570)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1673)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1566)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1499)\n2015-11-21 13:52:27,725 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0\n\n{noformat}\n\nEventReader(EventReader stream)\n{noformat}\n this.version = in.readLine();\n...\n    Schema myschema = new SpecificData(Event.class.getClassLoader()).getSchema(Event.class);\n    this.schema = Schema.parse(in.readLine());\n{noformat}\n\n"
        }
    },
    {
        "filename": "MAPREDUCE-4457.json",
        "creation_time": "2012-07-18T21:38:17.000+0000",
        "bug_report": {
            "Title": "mr job invalid transition TA_TOO_MANY_FETCH_FAILURE at FAILED",
            "Description": "we saw a job go into the ERROR state from an invalid state transition.\n\n3,600 INFO [AsyncDispatcher event handler]\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:\nattempt_1342238829791_2501_m_007743_0 TaskAttempt Transitioned from SUCCEEDED\nto FAILED\n2012-07-16 08:49:53,600 INFO [AsyncDispatcher event handler]\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:\nattempt_1342238829791_2501_m_008850_0 TaskAttempt Transitioned from SUCCEEDED\nto FAILED\n2012-07-16 08:49:53,600 INFO [AsyncDispatcher event handler]\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:\nattempt_1342238829791_2501_m_017344_1000 TaskAttempt Transitioned from RUNNING\nto SUCCESS_CONTAINER_CLEANUP\n2012-07-16 08:49:53,601 ERROR [AsyncDispatcher event handler]\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this\nevent at current state for attempt_1342238829791_2501_m_000027_0\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event:\nTA_TOO_MANY_FETCH_FAILURE at FAILED\n    at\norg.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n    at\norg.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n    at\norg.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n    at\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:954)\n    at\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:133)\n    at\norg.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:913)\n    at\norg.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:905)\n    at\norg.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n    at\norg.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.realDispatch(RecoveryService.java:285)\n    at\norg.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:281)\n    at\norg.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n    at java.lang.Thread.run(Thread.java:619)\n2012-07-16 08:49:53,601 INFO [AsyncDispatcher event handler]\norg.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:\nattempt_1342238829791_2501_m_029091_1000 TaskAttempt Transitioned from RUNNING\nto SUCCESS_CONTAINER_CLEANUP\n2012-07-16 08:49:53,601 INFO [IPC Server handler 17 on 47153]\norg.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from\nattempt_1342238829791_2501_r_000461_1000\n\n\nIt looks like we possibly got 2 TA_TOO_MANY_FETCH_FAILURE events. The first one moved it to FAILED and then the second one failed because no valid transition."
        }
    },
    {
        "filename": "MAPREDUCE-2716.json",
        "creation_time": "2011-07-20T21:13:36.000+0000",
        "bug_report": {
            "Title": "MR279: MRReliabilityTest job fails because of missing job-file.",
            "Description": "The ApplicationReport should have the jobFile (e.g. hdfs://localhost:9000/tmp/hadoop-<USER>/mapred/staging/<USER>/.staging/job_201107121640_0001/job.xml)\n\n\nWithout it, jobs such as MRReliabilityTest fail with the following error (caused by the fact that jobFile is hardcoded to \"\" in TypeConverter.java):\ne.g. java.lang.IllegalArgumentException: Can not create a Path from an empty string\n        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:88)\n        at org.apache.hadoop.fs.Path.<init>(Path.java:96)\n        at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:445)\n        at org.apache.hadoop.mapreduce.Cluster.getJobs(Cluster.java:104)\n        at org.apache.hadoop.mapreduce.Cluster.getAllJobs(Cluster.java:218)\n        at org.apache.hadoop.mapred.JobClient.getAllJobs(JobClient.java:757)\n        at org.apache.hadoop.mapred.JobClient.jobsToComplete(JobClient.java:741)\n        at org.apache.hadoop.mapred.ReliabilityTest.runTest(ReliabilityTest.java:219)\n        at org.apache.hadoop.mapred.ReliabilityTest.runSleepJobTest(ReliabilityTest.java:133)\n        at org.apache.hadoop.mapred.ReliabilityTest.run(ReliabilityTest.java:116)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)\n        at org.apache.hadoop.mapred.ReliabilityTest.main(ReliabilityTest.java:504)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)\n        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)\n        at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)\n        at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:597)\n        at org.apache.hadoop.util.RunJar.main(RunJar.java:192)"
        }
    },
    {
        "filename": "MAPREDUCE-6702.json",
        "creation_time": "2016-05-17T22:11:38.000+0000",
        "bug_report": {
            "Title": "TestMiniMRChildTask.testTaskEnv and TestMiniMRChildTask.testTaskOldEnv are failing",
            "Description": "-------------------------------------------------------\n T E S T S\n-------------------------------------------------------\nRunning org.apache.hadoop.mapred.TestMiniMRChildTask\nTests run: 3, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 92.48 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestMiniMRChildTask\ntestTaskEnv(org.apache.hadoop.mapred.TestMiniMRChildTask)  Time elapsed: 21.906 sec  <<< FAILURE!\njava.lang.AssertionError: The environment checker job failed.\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.apache.hadoop.mapred.TestMiniMRChildTask.runTestTaskEnv(TestMiniMRChildTask.java:550)\n\tat org.apache.hadoop.mapred.TestMiniMRChildTask.testTaskEnv(TestMiniMRChildTask.java:472)\n\ntestTaskOldEnv(org.apache.hadoop.mapred.TestMiniMRChildTask)  Time elapsed: 17.452 sec  <<< FAILURE!\njava.lang.AssertionError: The environment checker job failed.\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat org.junit.Assert.assertTrue(Assert.java:41)\n\tat org.apache.hadoop.mapred.TestMiniMRChildTask.runTestTaskEnv(TestMiniMRChildTask.java:550)\n\tat org.apache.hadoop.mapred.TestMiniMRChildTask.testTaskOldEnv(TestMiniMRChildTask.java:496)"
        }
    },
    {
        "filename": "MAPREDUCE-4748.json",
        "creation_time": "2012-10-24T21:53:19.000+0000",
        "bug_report": {
            "Title": "Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED",
            "Description": "We saw this happen when running a large pig script.\n\n{noformat}\n2012-10-23 22:45:24,986 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Can't handle this event at current state for task_1350837501057_21978_m_040453\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:604)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:89)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:914)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:908)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)\n        at java.lang.Thread.run(Thread.java:619)\n{noformat}\n\nSpeculative execution was enabled, and that task did speculate so it looks like this is an error in the state machine either between the task attempts or just within that single task."
        }
    },
    {
        "filename": "MAPREDUCE-3062.json",
        "creation_time": "2011-09-21T17:31:02.000+0000",
        "bug_report": {
            "Title": "YARN NM/RM fail to start",
            "Description": "2011-09-21 10:21:41,932 FATAL resourcemanager.ResourceManager (ResourceManager.java:main(502)) - Error starting ResourceManager\njava.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.admin.address\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)\n\tat org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)\n\tat org.apache.hadoop.yarn.server.resourcemanager.AdminService.init(AdminService.java:88)\n\tat org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.init(ResourceManager.java:191)\n\tat org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:497)\n\nAnother copy and paste issue. Similar to https://issues.apache.org/jira/browse/MAPREDUCE-3042."
        }
    },
    {
        "filename": "MAPREDUCE-5724.json",
        "creation_time": "2014-01-15T00:58:12.000+0000",
        "bug_report": {
            "Title": "JobHistoryServer does not start if HDFS is not running",
            "Description": "Starting JHS without HDFS running fails with the following error:\n\n{code}\nSTARTUP_MSG:   build = git://git.apache.org/hadoop-common.git -r ad74e8850b99e03b0b6435b04f5b3e9995bc3956; compiled by 'tucu' on 2014-01-14T22:40Z\nSTARTUP_MSG:   java = 1.7.0_45\n************************************************************/\n2014-01-14 16:47:40,264 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for [TERM, HUP, INT]\n2014-01-14 16:47:40,883 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n2014-01-14 16:47:41,101 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init\n2014-01-14 16:47:41,710 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:505)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistory.serviceInit(JobHistory.java:94)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:143)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.launchJobHistoryServer(JobHistoryServer.java:207)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:217)\nCaused by: java.net.ConnectException: Call From dontknow.local/172.20.10.4 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1410)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1359)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n\tat com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:185)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)\n\tat com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:671)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1722)\n\tat org.apache.hadoop.fs.Hdfs.getFileStatus(Hdfs.java:124)\n\tat org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1106)\n\tat org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1102)\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n\tat org.apache.hadoop.fs.FileContext.getFileStatus(FileContext.java:1102)\n\tat org.apache.hadoop.fs.FileContext$Util.exists(FileContext.java:1514)\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.mkdir(HistoryFileManager.java:561)\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:502)\n\t... 8 more\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:601)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:696)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2700(Client.java:367)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1458)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1377)\n\t... 28 more\n2014-01-14 16:47:41,713 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.JobHistory failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]\norg.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:505)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistory.serviceInit(JobHistory.java:94)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:143)\n\tat org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.launchJobHistoryServer(JobHistoryServer.java:207)\n\tat org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:217)\nCaused by: java.net.ConnectException: Call From dontknow.local/172.20.10.4 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:526)\n\tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1410)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1359)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n\tat com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:185)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)\n\tat com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:671)\n\tat org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1722)\n\tat org.apache.hadoop.fs.Hdfs.getFileStatus(Hdfs.java:124)\n\tat org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1106)\n\tat org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1102)\n\tat org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)\n\tat org.apache.hadoop.fs.FileContext.getFileStatus(FileContext.java:1102)\n\tat org.apache.hadoop.fs.FileContext$Util.exists(FileContext.java:1514)\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.mkdir(HistoryFileManager.java:561)\n\tat org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:502)\n\t... 8 more\nCaused by: java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)\n\tat org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)\n\tat org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:601)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:696)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2700(Client.java:367)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1458)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1377)\n\t... 28 more\n2014-01-14 16:47:41,714 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Stopping JobHistory\n2014-01-14 16:47:41,714 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]\n{code}\n"
        }
    },
    {
        "filename": "MAPREDUCE-5358.json",
        "creation_time": "2013-06-28T05:40:45.000+0000",
        "bug_report": {
            "Title": "MRAppMaster throws invalid transitions for JobImpl",
            "Description": "{code:xml}\n2013-06-26 11:39:50,128 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at SUCCEEDED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:720)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:119)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:962)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:958)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}\n\n{code:xml}\n2013-06-26 11:39:50,129 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state\norg.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_MAP_TASK_RESCHEDULED at SUCCEEDED\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)\n\tat org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:720)\n\tat org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:119)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:962)\n\tat org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:958)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)\n\tat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)\n\tat java.lang.Thread.run(Thread.java:662)\n{code}"
        }
    },
    {
        "filename": "MAPREDUCE-5837.json",
        "creation_time": "2014-04-15T20:24:58.000+0000",
        "bug_report": {
            "Title": "MRAppMaster fails when checking on uber mode",
            "Description": "When the MRAppMaster determines whether the job should run in the uber mode, it call {{Class.forName()}} to check whether the class is derived from {{ChainMapper}}:\n\n{code}\n try {\n      String mapClassName = conf.get(MRJobConfig.MAP_CLASS_ATTR);\n      if (mapClassName != null) {\n        Class<?> mapClass = Class.forName(mapClassName);\n        if (ChainMapper.class.isAssignableFrom(mapClass))\n          isChainJob = true;\n      }\n    } catch (ClassNotFoundException cnfe) {\n      // don't care; assume it's not derived from ChainMapper\n    }\n{code}\n\nThe problem here is that {{Class.forName()}} can also throw {{NoClassDefError}}. It happens when the additional dependent jar is unavailable to the MRAppMaster. For example, the MRAppMaster complains about a MR job on Scala:\n\n{noformat}\n2014-04-15 11:52:55,877 FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster\njava.lang.NoClassDefFoundError: scala/Function1\n        at java.lang.Class.forName0(Native Method)\n        at java.lang.Class.forName(Class.java:190)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.isChainJob(JobImpl.java:1282)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:1224)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$3700(JobImpl.java:136)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1425)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1363)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:976)\n        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:135)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1263)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1063)\n        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1480)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1606)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1476)\n        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1409)\nCaused by: java.lang.ClassNotFoundException: scala.Function1\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)\n        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n        ... 22 more\n{noformat}\n \nThe proposed fix is to catch {{NoClassDefError}} at the corresponding places."
        }
    },
    {
        "filename": "MAPREDUCE-3058.json",
        "creation_time": "2011-09-21T12:53:39.000+0000",
        "bug_report": {
            "Title": "Sometimes task keeps on running while its Syslog says that it is shutdown",
            "Description": "While running GridMixV3, one of the jobs got stuck for 15 hrs. After clicking on the Job-page, found one of its reduces to be stuck. Looking at syslog of the stuck reducer, found this:\nTask-logs' head:\n\n{code}\n2011-09-19 17:57:22,002 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).\n2011-09-19 17:57:22,002 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started\n{code}\n\nTask-logs' tail:\n{code}\n2011-09-19 18:06:49,818 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as <DATANODE1>\n2011-09-19 18:06:49,818 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-1405370709-<NAMENODE>-1316452621953:blk_-7004355226367468317_79871 in pipeline  <DATANODE2>,  <DATANODE1>: bad datanode  <DATANODE1>\n2011-09-19 18:06:49,818 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtocol: lastAckedSeqno = 26870\n2011-09-19 18:06:49,820 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf sending #454\n2011-09-19 18:06:49,826 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <<NAMENODE> from gridperf got value #454\n2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.ipc.RPC: Call: getAdditionalDatanode 8\n2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.hdfs.DFSClient: Connecting to datanode <DATANODE2>\n2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.hdfs.DFSClient: Send buf size 131071\n2011-09-19 18:06:49,833 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception\njava.io.EOFException: Premature EOF: no length prefix available\n        at org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:158)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:860)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:838)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:929)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:740)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:415)\n2011-09-19 18:06:49,837 WARN org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.EOFException: Premature EOF: no length prefix available\n        at org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:158)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:860)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:838)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:929)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:740)\n        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:415)\n\n2011-09-19 18:06:49,837 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 sending #455\n2011-09-19 18:06:49,839 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 got value #455\n2011-09-19 18:06:49,840 DEBUG org.apache.hadoop.ipc.RPC: Call: statusUpdate 3\n2011-09-19 18:06:49,840 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task\n2011-09-19 18:06:49,840 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf sending #456\n2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf got value #456\n2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.RPC: Call: delete 18\n2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 sending #457\n2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 got value #457\n2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.ipc.RPC: Call: reportDiagnosticInfo 1\n2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: refCount=1\n2011-09-19 18:06:49,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ReduceTask metrics system...\n2011-09-19 18:06:49,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping metrics source UgiMetrics\n2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: class org.apache.hadoop.metrics2.lib.MetricsSourceBuilder$1\n2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=UgiMetrics\n2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping metrics source JvmMetrics\n2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: class org.apache.hadoop.metrics2.source.JvmMetrics\n2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=JvmMetrics\n2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=MetricsSystem,sub=Stats\n2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system stopped.\n2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=MetricsSystem,sub=Control\n2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system shutdown complete.\n{code}\n\nWhich means that tasks is supposed to have stopped within 20 secs, whereas the process itself is stuck for more than 15 hours. From AM log, also found that this task was sending its update regularly. ps -ef | grep java was also showing that process is still alive.\n"
        }
    },
    {
        "filename": "MAPREDUCE-5088.json",
        "creation_time": "2013-03-15T17:55:08.000+0000",
        "bug_report": {
            "Title": "MR Client gets an renewer token exception while Oozie is submitting a job",
            "Description": "After the fix for HADOOP-9299 I'm now getting the following bizzare exception in Oozie while trying to submit a job. This also seems to be KRB related:\n\n{noformat}\n2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-130315123130987-oozie-oozi-W] ACTION[0000001-130315123130987-oozie-oozi-W@Sleep] Error starting action [Sleep]. ErrorType [ERROR], ErrorCode [UninitializedMessageException], Message [UninitializedMessageException: Message missing required fields: renewer]\norg.apache.oozie.action.ActionExecutorException: UninitializedMessageException: Message missing required fields: renewer\n\tat org.apache.oozie.action.ActionExecutor.convertException(ActionExecutor.java:401)\n\tat org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:738)\n\tat org.apache.oozie.action.hadoop.JavaActionExecutor.start(JavaActionExecutor.java:889)\n\tat org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:211)\n\tat org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:59)\n\tat org.apache.oozie.command.XCommand.call(XCommand.java:277)\n\tat org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:326)\n\tat org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:255)\n\tat org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:175)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:662)\nCaused by: com.google.protobuf.UninitializedMessageException: Message missing required fields: renewer\n\tat com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:605)\n\tat org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder.build(SecurityProtos.java:973)\n\tat org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.mergeLocalToProto(GetDelegationTokenRequestPBImpl.java:84)\n\tat org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.getProto(GetDelegationTokenRequestPBImpl.java:67)\n\tat org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getDelegationToken(MRClientProtocolPBClientImpl.java:200)\n\tat org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:194)\n\tat org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:273)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1218)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1215)\n\tat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:581)\n\tat org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:396)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)\n\tat org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:576)\n\tat org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:723)\n\t... 10 more\n2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-13031512313\n{noformat}"
        }
    }
]