[
    {
        "filename": "STORM-2443.json",
        "creation_time": "2017-03-31T08:09:04.000+0000",
        "bug_report": {
            "Title": "Nimbus throws error when changing log level on UI topology page",
            "Description": "Here's stacktrace from Nimbus log:\n\n{code}\n2017-03-30 16:53:26.954 o.a.s.d.n.Nimbus pool-14-thread-56 [WARN] set log config topology exception. (topology id='rolling-1-1490860365')\njava.lang.NullPointerException: null\n        at org.apache.storm.daemon.nimbus.Nimbus.setLogConfig(Nimbus.java:2688) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3295) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$setLogConfig.getResult(Nimbus.java:3280) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_66]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_66]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_66]\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3213.json",
        "creation_time": "2018-09-05T16:16:45.000+0000",
        "bug_report": {
            "Title": "500 Server Error on __acker component page on Storm UI",
            "Description": "\r\n{code:java}\r\norg.apache.storm.thrift.TApplicationException: Internal error processing getComponentPageInfo\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:79)\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1359)\r\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1343)\r\n\tat org.apache.storm.daemon.ui.UIHelpers.getComponentPage(UIHelpers.java:1559)\r\n\tat org.apache.storm.daemon.ui.resources.StormApiResource.getTopologyComponent(StormApiResource.java:438)\r\n{code}\r\n\r\n\r\n\r\n{code:java}\r\n2018-09-05 16:15:24.927 o.a.s.t.ProcessFunction pool-21-thread-55 [ERROR] Internal error processing getComponentPageInfo\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4238) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4577) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4556) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:169) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18) [shaded-deps-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.scheduler.resource.ResourceUtils.getBoltResources(ResourceUtils.java:37) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:4192) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n        ... 10 more\r\n{code}\r\n",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2496.json",
        "creation_time": "2017-04-28T08:17:47.000+0000",
        "bug_report": {
            "Title": "Dependency artifacts should be uploaded to blobstore with READ permission for all",
            "Description": "When we submit topology via specific user with dependency artifacts, submitter uploads artifacts to the blobstore with user which runs the submission.\n\nSince uploaded artifacts are uploaded once and shared globally, other user might need to use uploaded artifact. (This is completely fine for non-secured cluster.) In this case, Supervisor fails to get artifact and crashes in result.\n\n{code}\n2017-04-28 04:56:46.594 o.a.s.l.AsyncLocalizer Async Localizer [WARN] Caught Exception While Downloading (rethrowing)...\norg.apache.storm.generated.AuthorizationException: null\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n2017-04-28 04:56:46.597 o.a.s.d.s.Slot SLOT_6701 [ERROR] Error when processing event\njava.util.concurrent.ExecutionException: AuthorizationException(msg:<user> does not have READ access to dep-org.apache.curator-curator-framework-jar-2.10.0.jar)\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_112]\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_112]\n\tat org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:380) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:275) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:740) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\nCaused by: org.apache.storm.generated.AuthorizationException\n\tat org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:535) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer.access$000(Localizer.java:65) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:505) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:481) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n2017-04-28 04:56:46.597 o.a.s.u.Utils SLOT_6701 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n\tat org.apache.storm.utils.Utils.exitProcess(Utils.java:1774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n\tat org.apache.storm.daemon.supervisor.Slot.run(Slot.java:774) ~[storm-core-1.1.0.2.6.0.3-8.jar:1.1.0.2.6.0.3-8]\n2017-04-28 04:56:46.599 o.a.s.d.s.Supervisor Thread-7 [INFO] Shutting down supervisor 775c158b-0a2d-40be-9e02-a9662d8bc5c4\n{code}\n\nSo we need to upload artifacts with READ permission to all, or at least supervisor should be able to read them at all.",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2879.json",
        "creation_time": "2018-01-03T07:07:49.000+0000",
        "bug_report": {
            "Title": "Supervisor collapse continuously when there is a expired assignment for overdue storm",
            "Description": "For now, when a topology is reassigned or killed for a cluster, supervisor will delete 4 files for an overdue storm:\r\n- storm-code\r\n- storm-ser\r\n- storm-jar\r\n- LocalAssignment\r\n\r\nSlot.java\r\nstatic DynamicState cleanupCurrentContainer(DynamicState dynamicState, StaticState staticState, MachineState nextState) throws Exception {\r\n        assert(dynamicState.container != null);\r\n        assert(dynamicState.currentAssignment != null);\r\n        assert(dynamicState.container.areAllProcessesDead());\r\n        \r\n        dynamicState.container.cleanUp();\r\n        staticState.localizer.releaseSlotFor(dynamicState.currentAssignment, staticState.port);\r\n        DynamicState ret = dynamicState.withCurrentAssignment(null, null);\r\n        if (nextState != null) {\r\n            ret = ret.withState(nextState);\r\n        }\r\n        return ret;\r\n    }\r\n\r\nBut we do not make a transaction to do this, if an exception occurred during deleting storm-code/ser/jar, an overdue local assignment will be left on disk.\r\n\r\nThen when supervisor restart from the exception above, the slots will be initial and container will be recovered from LocalAssignments, the blob store will fetch the files from Nimbus/Master, but will get a KeyNotFoundException, and supervisor collapses again.\r\n\r\nThis will happens continuously and supervisor will never recover until we clean up all the local assignments manually.\r\n\r\nThis is the stack:\r\n2017-12-27 14:15:04.434 o.a.s.l.AsyncLocalizer [INFO] Cleaning up unused topologies in /opt/meituan/storm/data/supervisor/stormdist\r\n2017-12-27 14:15:04.434 o.a.s.d.s.AdvancedFSOps [INFO] Deleting path /opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785\r\n2017-12-27 14:15:04.445 o.a.s.d.s.Slot [INFO] STATE EMPTY msInState: 109 -> WAITING_FOR_BASIC_LOCALIZATION msInState: 1\r\n2017-12-27 14:15:04.471 o.a.s.d.s.Supervisor [INFO] Starting supervisor with id 255d3fed-f3ee-4c7e-8a08-b693c9a6a072 at host gq-data-rt48.gq.sankuai.com.\r\n2017-12-27 14:15:04.502 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.611 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:123) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.718 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormcode.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:124) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.825 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormcode.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:124) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:04.932 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormconf.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:125) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:05.039 o.a.s.u.Utils [ERROR] An exception happened while downloading /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormconf.ser from blob store.\r\norg.apache.storm.generated.KeyNotFoundException: null\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26656) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result$beginBlobDownload_resultStandardScheme.read(Nimbus.java:26624) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$beginBlobDownload_result.read(Nimbus.java:26555) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:86) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.recv_beginBlobDownload(Nimbus.java:864) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.generated.Nimbus$Client.beginBlobDownload(Nimbus.java:851) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.blobstore.NimbusBlobStore.getBlob(NimbusBlobStore.java:357) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorAttempt(Utils.java:598) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisorImpl(Utils.java:582) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.Utils.downloadResourcesAsSupervisor(Utils.java:574) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.downloadBaseBlobs(AsyncLocalizer.java:125) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:148) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBaseBlobsDistributed.call(AsyncLocalizer.java:101) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]\r\n2017-12-27 14:15:05.140 o.a.s.u.Utils [INFO] Could not extract resources from /opt/meituan/storm/data/supervisor/tmp/ca4f8174-59be-40a4-b431-dbc8b697f063/stormjar.jar\r\n2017-12-27 14:15:05.142 o.a.s.d.s.Slot [INFO] STATE WAITING_FOR_BASIC_LOCALIZATION msInState: 697 -> WAITING_FOR_BLOB_LOCALIZATION msInState: 0\r\n2017-12-27 14:15:05.142 o.a.s.l.AsyncLocalizer [WARN] Caught Exception While Downloading (rethrowing)... \r\njava.io.FileNotFoundException: File '/opt/meituan/storm/data/supervisor/stormdist/app_dpsr_realtime_shop_vane_allcates-14-1513685785/stormconf.ser' does not exist\r\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:292) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.shade.org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1815) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfGivenPath(ConfigUtils.java:264) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConfImpl(ConfigUtils.java:376) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.utils.ConfigUtils.readSupervisorStormConf(ConfigUtils.java:370) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:226) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat org.apache.storm.localizer.AsyncLocalizer$DownloadBlobs.call(AsyncLocalizer.java:213) ~[storm-core-1.1.2-mt001.jar:?]\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [?:1.7.0_76]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [?:1.7.0_76]\r\n\tat java.lang.Thread.run(Thread.java:745) [?:1.7.0_76]",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-3012.json",
        "creation_time": "2018-03-27T15:30:32.000+0000",
        "bug_report": {
            "Title": "Nimbus will crash if pacemaker is restarted",
            "Description": "Below is the nimbus.log when I restarted pacemaker. Nimbus crashed because of NPE.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n{code:java}\r\n2018-03-26 21:39:18.404 main o.a.s.z.LeaderElectorImp [INFO] Queued up for leader lock.\r\n2018-03-26 21:39:18.458 main o.a.s.d.m.MetricsUtils [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableRepor\r\nter\r\n2018-03-26 21:39:18.461 main o.a.s.d.m.r.JmxPreparableReporter [INFO] Preparing...\r\n2018-03-26 21:39:18.527 main o.a.s.m.StormMetricsRegistry [INFO] Started statistics report plugin...\r\n2018-03-26 21:39:18.710 main o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:18.738 Refresh-TGT o.a.s.m.n.Login [INFO] TGT refresh thread started.\r\n2018-03-26 21:39:18.739 main o.a.s.z.ClientZookeeper [INFO] Staring ZK Curator\r\n2018-03-26 21:39:18.739 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Starting\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT valid starting at:        Mon Mar 26 21:39:18 UTC 2018\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT expires:                  Tue Mar 27 21:39:18 UTC 2018\r\n2018-03-26 21:39:18.747 Refresh-TGT o.a.s.m.n.Login [INFO] TGT refresh sleeping until: Tue Mar 27 17:39:22 UTC 2018\r\n2018-03-26 21:39:18.756 main o.a.z.ZooKeeper [INFO] Initiating client connection, connectString=openqe74blue-gw.blue.ygrid.yahoo.com:2181 sessionTimeout\r\n=60000 watcher=org.apache.curator.ConnectionState@148c7c4b\r\n2018-03-26 21:39:18.807 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Default schema\r\n2018-03-26 21:39:18.814 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.c.ZooKeeperSaslClient [INFO] Client will use GSSAPI as SASL mec\r\nhanism.\r\n2018-03-26 21:39:18.815 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Opening socket connection to server openqe74b\r\nlue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-03-26 21:39:18.816 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Socket connection established to openqe74blue\r\n-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, initiating session\r\n2018-03-26 21:39:18.817 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Session establishment complete on server open\r\nqe74blue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, sessionid = 0x1624f6d49dd0cdd, negotiated timeout = 40000\r\n2018-03-26 21:39:18.818 main-EventThread o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\r\n2018-03-26 21:39:18.839 Curator-Framework-0 o.a.c.f.i.CuratorFrameworkImpl [INFO] backgroundOperationsLoop exiting\r\n2018-03-26 21:39:18.841 main o.a.z.ZooKeeper [INFO] Session: 0x1624f6d49dd0cdd closed\r\n2018-03-26 21:39:18.842 main-EventThread o.a.z.ClientCnxn [INFO] EventThread shut down\r\n2018-03-26 21:39:18.844 main o.a.s.z.ClientZookeeper [INFO] Staring ZK Curator\r\n2018-03-26 21:39:18.844 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Starting\r\n2018-03-26 21:39:18.875 main o.a.z.ZooKeeper [INFO] Initiating client connection, connectString=openqe74blue-gw.blue.ygrid.yahoo.com:2181/storm_ystormQE\r\n_CI sessionTimeout=60000 watcher=org.apache.curator.ConnectionState@211febf3\r\n2018-03-26 21:39:18.908 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.c.ZooKeeperSaslClient [INFO] Client will use GSSAPI as SASL mec\r\nhanism.\r\n2018-03-26 21:39:18.909 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Opening socket connection to server openqe74b\r\nlue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-03-26 21:39:18.910 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Socket connection established to openqe74blue\r\n-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, initiating session\r\n2018-03-26 21:39:18.911 main-SendThread(openqe74blue-gw.blue.ygrid.yahoo.com:2181) o.a.z.ClientCnxn [INFO] Session establishment complete on server open\r\nqe74blue-gw.blue.ygrid.yahoo.com/10.215.68.156:2181, sessionid = 0x1624f6d49dd0cde, negotiated timeout = 40000\r\n2018-03-26 21:39:18.920 main o.a.c.f.i.CuratorFrameworkImpl [INFO] Default schema\r\n2018-03-26 21:39:18.923 main-EventThread o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\r\n2018-03-26 21:39:18.986 main o.a.s.d.n.Nimbus [INFO] Starting nimbus server for storm version '2.0.0.y'\r\n2018-03-26 21:39:19.931 main-EventThread o.a.s.z.Zookeeper [INFO] active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []\r\n2018-03-26 21:39:19.932 main-EventThread o.a.s.z.Zookeeper [INFO] active-topology-dependencies [] local-blobs [] diff-topology-dependencies []\r\n2018-03-26 21:39:19.932 main-EventThread o.a.s.z.Zookeeper [INFO] Accepting leadership, all active topologies and corresponding dependencies found local\r\nly.\r\n2018-03-26 21:39:20.636 timer o.a.s.d.n.Nimbus [INFO] Scheduling took 1381 ms for 0 topologies\r\n2018-03-26 21:39:20.901 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: open\r\nqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:20.901 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 101ms (NOT MAX)\r\n2018-03-26 21:39:21.003 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: open\r\nqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.003 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 102ms (NOT MAX)\r\n2018-03-26 21:39:21.106 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.106 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 106ms (NOT MAX)\r\n2018-03-26 21:39:21.214 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.214 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 115ms (NOT MAX)\r\n2018-03-26 21:39:21.331 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.331 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 129ms (NOT MAX)\r\n2018-03-26 21:39:21.462 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.462 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 162ms (NOT MAX)\r\n2018-03-26 21:39:21.626 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.626 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 176ms (NOT MAX)\r\n2018-03-26 21:39:21.807 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:21.807 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 319ms (NOT MAX)\r\n2018-03-26 21:39:21.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:22.128 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:22.128 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 603ms (NOT MAX)\r\n2018-03-26 21:39:22.733 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:22.733 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 868ms (NOT MAX)\r\n2018-03-26 21:39:22.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:23.603 client-boss-1 o.a.s.p.PacemakerClientHandler [WARN] Connection to pacemaker failed. Trying to reconnect Connection refused: openqe74blue-n1.blue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:23.603 client-boss-1 o.a.s.u.StormBoundedExponentialBackoffRetry [WARN] WILL SLEEP FOR 1494ms (NOT MAX)\r\n2018-03-26 21:39:23.888 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:24.889 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b\r\nlue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:25.107 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.116 client-worker-4 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.121 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@116ce525\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:37614 to openqe74blue-n2.blue.ygrid.yahoo.com/10.215.76.243:6699\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:24.889 timer o.a.s.p.PacemakerClient [ERROR] error attempting to write to a channel {}\r\norg.apache.storm.pacemaker.PacemakerConnectionException: Timed out waiting for channel ready.\r\n        at org.apache.storm.pacemaker.PacemakerClient.waitUntilReady(PacemakerClient.java:213) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:182) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClient.send(PacemakerClient.java:197) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:65) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:193) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:25.100 client-worker-4 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:36922 to openqe74blue-n1.b\r\nlue.ygrid.yahoo.com/10.215.76.240:6699\r\n2018-03-26 21:39:25.107 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.116 client-worker-4 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.121 client-worker-4 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@116ce525\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslClientHandler [INFO] Connection established from /10.215.76.240:37614 to openqe74blue-n2.b\r\nlue.ygrid.yahoo.com/10.215.76.243:6699\r\n2018-03-26 21:39:25.753 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Creating Kerberos Client.\r\n2018-03-26 21:39:25.763 client-worker-1 o.a.s.m.n.Login [INFO] successfully logged in.\r\n2018-03-26 21:39:25.765 client-worker-1 o.a.s.m.n.KerberosSaslNettyClient [INFO] Got Client: com.sun.security.sasl.gsskerb.GssKrb5Client@493cfe64\r\n2018-03-26 21:39:26.596 timer o.a.s.d.n.Nimbus [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2508) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:195) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:408) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:765) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2148) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$36(Nimbus.java:2506) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-03-26 21:39:26.596 timer o.a.s.u.Utils [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$23(Nimbus.java:1154) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:106) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-03-26 21:39:26.600 Thread-16 o.a.s.u.Utils [INFO] Halting after 5 seconds\r\n2018-03-26 21:39:26.606 Thread-15 o.a.s.d.n.Nimbus [INFO] Shutting down master\r\n2018-03-26 21:39:31.600 Thread-16 o.a.s.u.Utils [WARN] Forcing Halt...\r\n{code}\r\n\u00a0\r\n\r\n\u00a0\r\n\r\nThis is because when [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/pacemaker/PacemakerClient.java#L195-L198]\u00a0happens,\r\n\r\n\u00a0\r\n{code:java}\r\nHBMessage ret = messages[next];\r\nif(ret == null) {\r\n// This can happen if we lost the connection and subsequently reconnected or timed out.\r\nsend(m);\r\n}\r\nmessages[next] = null;\r\nLOG.debug(\"Got Response: {}\", ret);\r\nreturn ret;\r\n{code}\r\nit returns null result. And the null result is inserted into [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/pacemaker/PacemakerClientPool.java#L65-L66]\r\n{code:java}\r\nfor(String s : servers) {\r\nHBMessage response = getClientForServer(s).send(m);\r\nresponses.add(response);\r\n}\r\n{code}\r\nwhich leads to [https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/cluster/PaceMakerStateStorage.java#L195]\r\n\r\n\u00a0\r\n{code:java}\r\nfor(HBMessage response : responses) {\r\nif (response.get_type() != HBServerMessageType.GET_ALL_NODES_FOR_PATH_RESPONSE) {\r\nLOG.error(\"get_worker_hb_children: Invalid Response Type\");\r\ncontinue;\r\n}\r\nif(response.get_data().get_nodes().get_pulseIds() != null) {\r\nretSet.addAll(response.get_data().get_nodes().get_pulseIds());\r\n}\r\n}\r\n{code}\r\n\u00a0\r\n\r\nand this is where NPE\u00a0happens\u00a0",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3073.json",
        "creation_time": "2018-05-15T11:12:21.000+0000",
        "bug_report": {
            "Title": "In some cases workers may crash because pendingEmits is full",
            "Description": "Saw this while running the https://github.com/apache/storm/blob/master/examples/storm-loadgen/src/main/java/org/apache/storm/loadgen/ThroughputVsLatency.java topology.\r\n\r\n{code}\r\n2018-05-15 11:35:28.365 o.a.s.u.Utils Thread-16-spout-executor[8, 8] [ERROR] Async loop died!\r\njava.lang.RuntimeException: java.lang.IllegalStateException: Queue full\r\n\tat org.apache.storm.executor.Executor.accept(Executor.java:282) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consumeImpl(JCQueue.java:133) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:110) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.JCQueue.consume(JCQueue.java:101) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:168) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$2.call(SpoutExecutor.java:157) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.Utils$2.run(Utils.java:349) [storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\r\nCaused by: java.lang.IllegalStateException: Queue full\r\n\tat java.util.AbstractQueue.add(AbstractQueue.java:98) ~[?:1.8.0_144]\r\n\tat org.apache.storm.daemon.worker.WorkerTransfer.tryTransferRemote(WorkerTransfer.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.worker.WorkerState.tryTransferRemote(WorkerState.java:516) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.ExecutorTransfer.tryTransfer(ExecutorTransfer.java:66) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.sendSpoutMsg(SpoutOutputCollectorImpl.java:140) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutOutputCollectorImpl.emit(SpoutOutputCollectorImpl.java:70) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.spout.SpoutOutputCollector.emit(SpoutOutputCollector.java:42) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.loadgen.LoadSpout.fail(LoadSpout.java:135) ~[stormjar.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor.failSpoutMsg(SpoutExecutor.java:360) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:120) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor$1.expire(SpoutExecutor.java:113) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.utils.RotatingMap.rotate(RotatingMap.java:63) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.spout.SpoutExecutor.tupleActionFn(SpoutExecutor.java:295) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.executor.Executor.accept(Executor.java:278) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\t... 7 more\r\n{code}\r\n\r\nThe executor's pendingEmits queue is full, and the executor then tries to add another tuple. It looks to me like we're preventing the queue from filling by emptying it between calls to nextTuple at https://github.com/apache/storm/blob/master/storm-client/src/jvm/org/apache/storm/executor/spout/SpoutExecutor.java#L184.\r\n\r\nThe TVL topology reemits failed tuples directly from the fail method, which can be triggered by tick tuples. If the pendingEmits queue is already close to full when this happens, we might hit the error above. I think it can also happen if nextTuple emits too many tuples in a call, or if too many metrics ticks happen between pendingEmit flushes, since metrics ticks also trigger emits.",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-1672.json",
        "creation_time": "2016-03-31T19:24:18.000+0000",
        "bug_report": {
            "Title": "Stats not get class cast exception",
            "Description": "Component page in UI\n{code}\n2016-03-31 14:21:44.576 o.a.s.t.s.AbstractNonblockingServer$FrameBuffer [ERROR] Unexpected throwable while invoking!\njava.lang.ClassCastException: java.lang.Long cannot be cast to java.util.Map\n        at org.apache.storm.stats.StatsUtil.filterSysStreams(StatsUtil.java:1696)\n        at org.apache.storm.stats.StatsUtil.aggPreMergeCompPageBolt(StatsUtil.java:240)\n        at org.apache.storm.stats.StatsUtil.aggCompExecStats(StatsUtil.java:1130)\n        at org.apache.storm.stats.StatsUtil.aggregateCompStats(StatsUtil.java:1108)\n        at org.apache.storm.stats.StatsUtil.aggCompExecsStats(StatsUtil.java:1236)\n        at org.apache.storm.daemon.nimbus$fn__3490$exec_fn__789__auto__$reify__3519.getComponentPageInfo(nimbus.clj:2130)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3826)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:3810)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:158)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:744)\n{code}",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-1520.json",
        "creation_time": "2016-02-03T02:48:58.000+0000",
        "bug_report": {
            "Title": "Nimbus Clojure/Zookeeper issue (\"stateChanged\" method not found)",
            "Description": "Placeholder until I can gather more information for reproducing the issue.\n\nThe following appears in nimbus.log after deploying/undeploying topologies:\n\n{code}\n2016-02-02 21:34:04.308 o.a.s.s.o.a.c.f.l.ListenerContainer [ERROR] Listener (org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660@22587507) threw an exception\njava.lang.IllegalArgumentException: No matching method found: stateChanged for class org.apache.storm.cluster$mk_storm_cluster_state$reify$reify__6413\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:53)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.cluster_state.zookeeper_state_factory$_mkState$reify$reify__12660.stateChanged(zookeeper_state_factory.clj:145)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:259)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:255)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)\n\tat org.apache.storm.shade.com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)\n\tat org.apache.storm.shade.org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:84)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:253)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:43)\n\tat org.apache.storm.shade.org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:111)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\n\n-Basic functionality does not seem to be affected.-\n\nNimbus becomes unresponsive and needs to be manually restarted.\n",
            "Priority": "Blocker"
        }
    },
    {
        "filename": "STORM-1977.json",
        "creation_time": "2016-07-17T09:07:06.000+0000",
        "bug_report": {
            "Title": "Leader Nimbus crashes with getClusterInfo when it doesn't have one or more replicated topology codes",
            "Description": "While investigating STORM-1976, I found that there're cases for nimbus to not having topology codes. \nBefore BlobStore, only nimbuses which is having all topology codes can gain leadership, otherwise they give up leadership immediately. While introducing BlobStore, this logic is removed.\n\nI don't know it's intended or not, but it incurs one of nimbus to gain leadership which doesn't have replicated topology code, and the nimbus will be crashed when getClusterInfo is requested.\n\nEasiest way to reproduce is:\n\n1. comment cleanup-corrupt-topologies! from nimbus.clj (It's a quick workaround for resolving STORM-1976), and patch Storm cluster\n2. Launch Nimbus 1 (leader)\n3. Run topology\n4. Kill Nimbus 1\n5. Launch Nimbus 2 from different node\n6. Nimbus 2 gains leadership \n7. getClusterInfo is requested to Nimbus 2, and Nimbus 2 gets crashed\n\nLog:\n\n{code}\n2016-07-17 08:47:48.378 o.a.s.b.FileBlobStoreImpl [INFO] Creating new blob store based in /grid/0/hadoop/storm/blobs\n...\n2016-07-17 08:47:48.619 o.a.s.zookeeper [INFO] Queued up for leader lock.\n2016-07-17 08:47:48.651 o.a.s.zookeeper [INFO] <node1> gained leadership\n...\n2016-07-17 08:47:48.833 o.a.s.d.nimbus [INFO] Starting nimbus server for storm version '1.1.1-SNAPSHOT'\n2016-07-17 08:47:49.295 o.a.s.t.ProcessFunction [ERROR] Internal error processing getClusterInfo\nKeyNotFoundException(msg:production-topology-2-1468745167-stormcode.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:268)\n...\n        at org.apache.storm.daemon.nimbus$get_blob_replication_count.invoke(nimbus.clj:498)\n        at org.apache.storm.daemon.nimbus$get_cluster_info$iter__9520__9524$fn__9525.invoke(nimbus.clj:1427)\n...\n        at org.apache.storm.daemon.nimbus$get_cluster_info.invoke(nimbus.clj:1401)\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9612.getClusterInfo(nimbus.clj:1838)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3724)\n        at org.apache.storm.generated.Nimbus$Processor$getClusterInfo.getResult(Nimbus.java:3708)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n...\n2016-07-17 08:47:49.397 o.a.s.b.BlobStoreUtils [ERROR] Could not download blob with keyproduction-topology-2-1468745167-stormconf.ser\n2016-07-17 08:47:49.400 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with keyproduction-topology-2-1468745167-stormconf.ser\n2016-07-17 08:47:49.402 o.a.s.d.nimbus [ERROR] Error when processing event\nKeyNotFoundException(msg:production-topology-2-1468745167-stormconf.ser)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:149)\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:239)\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:271)\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:300)\n...\n       at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n        at org.apache.storm.daemon.nimbus$read_storm_conf_as_nimbus.invoke(nimbus.clj:548)\n        at org.apache.storm.daemon.nimbus$read_topology_details.invoke(nimbus.clj:555)\n        at org.apache.storm.daemon.nimbus$mk_assignments$iter__9205__9209$fn__9210.invoke(nimbus.clj:912)\n...\n        at org.apache.storm.daemon.nimbus$mk_assignments.doInvoke(nimbus.clj:911)\n        at clojure.lang.RestFn.invoke(RestFn.java:410)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781$fn__9782.invoke(nimbus.clj:2216)\n        at org.apache.storm.daemon.nimbus$fn__9769$exec_fn__1363__auto____9770$fn__9781.invoke(nimbus.clj:2215)\n        at org.apache.storm.timer$schedule_recurring$this__1732.invoke(timer.clj:105)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:50)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n...\n2016-07-17 08:47:49.408 o.a.s.util [ERROR] Halting process: (\"Error when processing an event\")\njava.lang.RuntimeException: (\"Error when processing an event\")\n        at org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n        at clojure.lang.RestFn.invoke(RestFn.java:423)\n        at org.apache.storm.daemon.nimbus$nimbus_data$fn__8727.invoke(nimbus.clj:205)\n        at org.apache.storm.timer$mk_timer$fn__1715$fn__1716.invoke(timer.clj:71)\n        at org.apache.storm.timer$mk_timer$fn__1715.invoke(timer.clj:42)\n        at clojure.lang.AFn.run(AFn.java:22)\n        at java.lang.Thread.run(Thread.java:745)\n2016-07-17 08:47:49.410 o.a.s.d.nimbus [INFO] Shutting down master\n{code}\n",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2988.json",
        "creation_time": "2018-03-07T14:55:22.000+0000",
        "bug_report": {
            "Title": "\"Error on initialization of server mk-worker\" when using org.apache.storm.metrics2.reporters.JmxStormReporter on worker",
            "Description": "As per documentation, I configured metrics v2 in my storm.yaml using the following configuration:\r\n\u00a0\r\n{code:yaml}\r\nstorm.metrics.reporters:\r\n\r\n  - class: \"org.apache.storm.metrics2.reporters.JmxStormReporter\"\r\n    daemons:\r\n        - \"supervisor\"\r\n        - \"nimbus\"\r\n        - \"worker\"\r\n    report.period: 10\r\n    report.period.units: \"SECONDS\"\r\n{code}\r\n\r\nWhen I start nimbus and supervisors everything works properly, I can see metrics reported to JMX, and logs (for nimbus in this example) report:\r\n\r\n{code}\r\n2018-03-07 15:35:22.201 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter\r\n2018-03-07 15:35:22.203 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\r\n2018-03-07 15:35:22.221 o.a.s.d.common main [INFO] Started statistics report plugin...\r\n{code}\r\n\r\nWhen I submit a topology, workers cannot initialize and report this error\r\n\r\n{code:java}\r\n2018-03-07 15:39:19.136 o.a.s.d.worker main [INFO] Launching worker for stp_topology-1-1520433551 on [... cut ...]\r\n2018-03-07 15:39:19.169 o.a.s.m.StormMetricRegistry main [INFO] Starting metrics reporters...\r\n2018-03-07 15:39:19.172 o.a.s.m.StormMetricRegistry main [INFO] Attempting to instantiate reporter class: org.apache.storm.metrics2.reporters.JmxStormReporter\r\n2018-03-07 15:39:19.175 o.a.s.m.r.JmxStormReporter main [INFO] Preparing...\r\n2018-03-07 15:39:19.182 o.a.s.d.worker main [ERROR] Error on initialization of server mk-worker\r\njava.lang.IllegalArgumentException: Don't know how to convert {\"class\" \"org.apache.storm.metrics2.reporters.JmxStormReporter\", \"daemons\" [\"supervisor\" \"nimbus\" \"worker\"], \"report.period\" 10, \"report.period.units\" \"SECONDS\"} + to String\r\n\tat org.apache.storm.utils.Utils.getString(Utils.java:848) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain(JmxStormReporter.java:70) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.reporters.JmxStormReporter.prepare(JmxStormReporter.java:51) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.StormMetricRegistry.startReporter(StormMetricRegistry.java:119) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.metrics2.StormMetricRegistry.start(StormMetricRegistry.java:102) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat org.apache.storm.daemon.worker$fn__5545$exec_fn__1369__auto____5546.invoke(worker.clj:611) ~[storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:178) ~[clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) ~[clojure-1.7.0.jar:?]\r\n\tat clojure.core$apply.invoke(core.clj:630) ~[clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\r\n2018-03-07 15:39:19.195 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")\r\njava.lang.RuntimeException: (\"Error on initialization\")\r\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$fn__5545$mk_worker__5636.doInvoke(worker.clj:598) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:512) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker$_main.invoke(worker.clj:787) [storm-core-1.2.1.jar:1.2.1]\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165) [clojure-1.7.0.jar:?]\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.7.0.jar:?]\r\n\tat org.apache.storm.daemon.worker.main(Unknown Source) [storm-core-1.2.1.jar:1.2.1]\r\n{code}\r\n\r\nLooking at org.apache.storm.metrics2.reporters.JmxStormReporter.getMetricsJMXDomain() I found that it passes \"reporterConf\" map to Utils.getString() instead of a string:\r\n{code:java}\r\n    public static String getMetricsJMXDomain(Map reporterConf) {\r\n        return Utils.getString(reporterConf, JMX_DOMAIN);\r\n}\r\n{code}\r\n\r\nThe \"prepare\" method in org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter used by nimbus and supervisor correctly passes a string to Utils.getString():\r\n\r\n{code:java}\r\npublic void prepare(MetricRegistry metricsRegistry, Map stormConf) {\r\n        LOG.info(\"Preparing...\");\r\n        JmxReporter.Builder builder = JmxReporter.forRegistry(metricsRegistry);\r\n        String domain = Utils.getString(stormConf.get(Config.STORM_DAEMON_METRICS_REPORTER_PLUGIN_DOMAIN), null);\r\n        if (domain != null) {\r\n            builder.inDomain(domain);\r\n}\r\n[...]\r\n{code}\r\n\r\nIs this a bug or am I missing something in configuration?\r\n\r\nRegards,\r\nFederico Chiacchiaretta",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2321.json",
        "creation_time": "2017-01-24T04:18:07.000+0000",
        "bug_report": {
            "Title": "Nimbus did not come up after restart",
            "Description": "The nimbus was restarted during HA testing. After the restart the nimbus failed to come up. \n{code}\n2017-01-18 04:57:58.231 o.a.s.s.o.a.c.f.s.ConnectionStateManager [INFO] State change: CONNECTED\n2017-01-18 04:57:58.247 o.a.s.b.BlobStoreUtils [ERROR] Could not update the blob with keyKillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n2017-01-18 04:57:58.273 o.a.s.b.KeySequenceNumber [ERROR] Exception {}\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /blobstore/KillLeaderThenSubmitNewTopology1-1-1484715309-stormjar.jar\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:200)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:149)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58.274 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl [INFO] backgroundOperationsLoop exiting\n2017-01-18 04:57:58.296 o.a.s.m.n.Login [INFO] successfully logged in.\n2017-01-18 04:57:58.309 o.a.s.s.o.a.z.ZooKeeper [INFO] Session: 0x359afc1eaa2009b closed\n2017-01-18 04:57:58.309 o.a.s.s.o.a.z.ClientCnxn [INFO] EventThread shut down\n2017-01-18 04:57:58.310 o.a.s.t.s.TThreadPoolServer [ERROR] Error occurred during processing of message.\njava.util.NoSuchElementException\n\tat java.util.TreeMap.key(TreeMap.java:1327)\n\tat java.util.TreeMap.lastKey(TreeMap.java:297)\n\tat java.util.TreeSet.last(TreeSet.java:401)\n\tat org.apache.storm.blobstore.KeySequenceNumber.getKeySequenceNumber(KeySequenceNumber.java:206)\n\tat org.apache.storm.daemon.nimbus$get_version_for_key.invoke(nimbus.clj:456)\n\tat org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9548.createStateInZookeeper(nimbus.clj:2056)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3755)\n\tat org.apache.storm.generated.Nimbus$Processor$createStateInZookeeper.getResult(Nimbus.java:3740)\n\tat org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n\tat org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n\tat org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144)\n\tat org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58.311 o.a.s.d.nimbus [ERROR] Error when processing event\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:92)\n\tat org.apache.storm.daemon.nimbus$fn__9373.invoke(nimbus.clj:1452)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:233)\n\tat org.apache.storm.daemon.nimbus$fn__9770$exec_fn__3656__auto____9771$fn__9786.invoke(nimbus.clj:2452)\n\tat org.apache.storm.timer$schedule_recurring$this__2188.invoke(timer.clj:105)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:50)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:114)\n\tat org.apache.storm.blobstore.BlobSynchronizer.syncBlobs(BlobSynchronizer.java:76)\n\t... 8 more\nCaused by: java.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:252)\n\tat org.apache.storm.blobstore.BlobSynchronizer.updateKeySetForBlobStore(BlobSynchronizer.java:111)\n\t... 9 more\nCaused by: java.lang.RuntimeException: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:349)\n\tat org.apache.storm.blobstore.BlobStoreUtils.createStateInZookeeper(BlobStoreUtils.java:217)\n\tat org.apache.storm.blobstore.BlobStoreUtils.updateKeyForBlobStore(BlobStoreUtils.java:249)\n\t... 10 more\nCaused by: org.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:376)\n\tat org.apache.storm.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:453)\n\tat org.apache.storm.thrift.transport.TSaslTransport.read(TSaslTransport.java:435)\n\tat org.apache.storm.thrift.transport.TSaslClientTransport.read(TSaslClientTransport.java:37)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_createStateInZookeeper(Nimbus.java:1000)\n\tat org.apache.storm.generated.Nimbus$Client.createStateInZookeeper(Nimbus.java:987)\n\tat org.apache.storm.blobstore.NimbusBlobStore.createStateInZookeeper(NimbusBlobStore.java:346)\n\t... 12 more\n2017-01-18 04:57:58.314 o.a.s.util [ERROR] Halting process: (\"Error when processing an event\")\njava.lang.RuntimeException: (\"Error when processing an event\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$nimbus_data$fn__8579.invoke(nimbus.clj:212)\n\tat org.apache.storm.timer$mk_timer$fn__2171$fn__2172.invoke(timer.clj:71)\n\tat org.apache.storm.timer$mk_timer$fn__2171.invoke(timer.clj:42)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.lang.Thread.run(Thread.java:745)\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,317 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,318 FATAL Ignoring log event after log4j was shut down\n2017-01-18 04:57:58,318 FATAL Ignoring log event after log4j was shut down\n{code}",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-3013.json",
        "creation_time": "2018-03-28T04:47:28.000+0000",
        "bug_report": {
            "Title": "Deactivated topology restarts if data flows into Kafka",
            "Description": "Hi, I have deactivated the storm topology & then if I produce any records into Kafka, Storm throws an exception. Exception follows,\r\n{code:java}\r\n2018-03-28 09:50:23.804 o.a.s.d.executor Thread-83-kafkaLogs-executor[130 130] [INFO] Deactivating spout kafkaLogs:(130)\r\n2018-03-28 09:51:01.289 o.a.s.util Thread-17-kafkaLogs-executor[139 139] [ERROR] Async loop died!\r\njava.lang.RuntimeException: java.lang.IllegalStateException: This consumer has already been closed.\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:522) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatch(DisruptorQueue.java:477) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.disruptor$consume_batch.invoke(disruptor.clj:70) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$fn__4975$fn__4990$fn__5021.invoke(executor.clj:634) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.util$async_loop$fn__557.invoke(util.clj:484) [storm-core-1.2.1.jar:1.2.1]\r\nat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\r\nat java.lang.Thread.run(Thread.java:745) [?:1.8.0_45]\r\nCaused by: java.lang.IllegalStateException: This consumer has already been closed.\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:1787) ~[stormjar.jar:?]\r\nat org.apache.kafka.clients.consumer.KafkaConsumer.beginningOffsets(KafkaConsumer.java:1622) ~[stormjar.jar:?]\r\nat org.apache.storm.kafka.spout.metrics.KafkaOffsetMetric.getValueAndReset(KafkaOffsetMetric.java:79) ~[stormjar.jar:?]\r\nat org.apache.storm.daemon.executor$metrics_tick$fn__4899.invoke(executor.clj:345) ~[storm-core-1.2.1.jar:1.2.1]\r\nat clojure.core$map$fn__4553.invoke(core.clj:2622) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.RT.seq(RT.java:507) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$seq__4128.invoke(core.clj:137) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$filter$fn__4580.invoke(core.clj:2679) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.sval(LazySeq.java:40) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.LazySeq.seq(LazySeq.java:49) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.Cons.next(Cons.java:39) ~[clojure-1.7.0.jar:?]\r\nat clojure.lang.RT.next(RT.java:674) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$next__4112.invoke(core.clj:64) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6523.invoke(protocols.clj:170) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6478$G__6473__6487.invoke(protocols.clj:19) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$seq_reduce.invoke(protocols.clj:31) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6506.invoke(protocols.clj:101) ~[clojure-1.7.0.jar:?]\r\nat clojure.core.protocols$fn__6452$G__6447__6465.invoke(protocols.clj:13) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$reduce.invoke(core.clj:6519) ~[clojure-1.7.0.jar:?]\r\nat clojure.core$into.invoke(core.clj:6600) ~[clojure-1.7.0.jar:?]\r\nat org.apache.storm.daemon.executor$metrics_tick.invoke(executor.clj:349) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$fn__4975$tuple_action_fn__4981.invoke(executor.clj:522) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.daemon.executor$mk_task_receiver$fn__4964.invoke(executor.clj:471) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.disruptor$clojure_handler$reify__4475.onEvent(disruptor.clj:41) ~[storm-core-1.2.1.jar:1.2.1]\r\nat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) ~[storm-core-1.2.1.jar:1.2.1]\r\n... 7 more\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3117.json",
        "creation_time": "2018-06-20T21:37:56.000+0000",
        "bug_report": {
            "Title": "Deleting blobs for running topologies hoses Nimbus",
            "Description": "The following test pseudo-code causes issues:\r\n{code:java}\r\ncluster.submitTopology(cluster.getTopologiesJarFile(), topoName, config, topology);\r\ncluster.waitTopologyUp(topoName);\r\ncluster.deleteAllBlobs();\r\n{code}\r\nThis causes nimbus to get stuck and restart:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-06-20 15:48:14.273 o.a.s.d.n.Nimbus pool-27-thread-694 [INFO] Received topology submission for wc-topology-test (storm-0.10.2.y.251 JDK-1.8.0_131) \r\n2018-06-20 15:48:14.629 o.a.s.d.n.Nimbus pool-27-thread-694 [INFO] Activating wc-topology-test: wc-topology-test-1-1529509694\r\n2018-06-20 15:48:14.724 o.a.s.d.n.Nimbus pool-27-thread-703 [INFO] TRANSITION: wc-topology-test-1-1529509694 KILL null true\r\n2018-06-20 15:48:14.812 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormconf.ser\r\n2018-06-20 15:48:14.830 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormcode.ser\r\n2018-06-20 15:48:14.863 o.a.s.d.n.Nimbus pool-27-thread-704 [INFO] Deleted blob for key wc-topology-test-1-1529509694-stormjar.jar\r\n2018-06-20 15:48:18.449 o.a.s.s.r.s.p.DefaultSchedulingPriorityStrategy timer [INFO] SIM Scheduling wc-topology-test-1-1529509694 with score of 0.3125\r\n2018-06-20 15:48:18.492 o.a.s.s.Cluster timer [INFO] STATUS - wc-topology-test-1-1529509694 Running - Fully Scheduled by DefaultResourceAwareStrategy\r\n2018-06-20 15:48:18.527 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id wc-topology-test-1-1529509694:\r\n\r\n2018-06-20 15:48:18.979 o.a.s.d.n.Nimbus pool-27-thread-722 [WARN] get blob meta exception.\r\norg.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormjar.jar\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n\r\n2018-06-20 15:48:22.884 o.a.s.d.n.Nimbus timer [INFO] Renewing Creds For wc-topology-test-1-1529509694 with org.apache.storm.security.auth.kerberos.AutoTGT@4482469c owned by hadoopqa@DEV.YGRID.YAHOO.COM\r\n\r\n\r\n2018-06-20 15:48:37.947 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: KeyNotFoundException(msg:wc-topology-test-1-1529509694-stormcode.ser)\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2822) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: org.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormcode.ser\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:420) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1517) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getClusterInfoImpl(Nimbus.java:2675) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.sendClusterMetricsToExecutors(Nimbus.java:2686) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$48(Nimbus.java:2819) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-06-20 15:48:37.948 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:468) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:488) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-06-20 15:48:37.950 o.a.s.d.n.Nimbus Thread-11 [INFO] Shutting down master\r\n2018-06-20 15:48:37.950 o.a.s.u.Utils Thread-12 [INFO] Halting after 10 seconds\r\n\r\n2018-06-20 15:48:46.672 o.a.s.d.n.Nimbus pool-27-thread-798 [WARN] get blob meta exception.\r\norg.apache.storm.utils.WrappedKeyNotFoundException: wc-topology-test-1-1529509694-stormconf.ser\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:256) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlobMeta(LocalFsBlobStore.java:286) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.getBlobMeta(Nimbus.java:3483) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:4011) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$getBlobMeta.getResult(Nimbus.java:3990) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-06-20 15:48:47.950 o.a.s.u.Utils Thread-12 [WARN] Forcing Halt...\r\n\r\n{code}\r\nNimbus then continually restarts:\r\n{code:java}\r\n2018-06-20 15:48:54.635 o.a.s.u.Utils main [ERROR] Received error in main thread.. terminating server...\r\njava.lang.Error: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\r\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:603) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:582) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.utils.Utils$5.uncaughtException(Utils.java:931) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1057) [?:1.8.0_131]\r\n        at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1052) [?:1.8.0_131]\r\n        at java.lang.Thread.dispatchUncaughtException(Thread.java:1959) [?:1.8.0_131]\r\nCaused by: java.lang.IllegalStateException: Could not find credentials for topology wc-topology-test-1-1529509694 at path /storms. Don't know how to fix this automatically. Please add needed ACLs, or delete the path.\r\n        at org.apache.storm.zookeeper.AclEnforcement.getTopoAcl(AclEnforcement.java:194) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithTopoChildren(AclEnforcement.java:250) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyParentWithReadOnlyTopoChildren(AclEnforcement.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.AclEnforcement.verifyAcls(AclEnforcement.java:136) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1155) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1162) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2993.json",
        "creation_time": "2018-03-12T19:04:16.000+0000",
        "bug_report": {
            "Title": "Storm HDFS bolt throws ClosedChannelException when Time rotation policy is used",
            "Description": "Storm connector throws below error in the worker logs.\r\n\r\n\u00a0\r\n\r\n2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-3 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-3-0-1520878438104.txt to /tmp/dest2/my-bolt-3-0-15 20878438104.txt 2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-0 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-6-0-1520878438104.txt to /tmp/dest2/my-bolt-6-0-15 20878438104.txt 2018-03-12 18:14:58.123 o.a.s.h.c.r.MoveFileAction Timer-1 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-5-0-1520878438104.txt to /tmp/dest2/my-bolt-5-0-15 20878438104.txt 2018-03-12 18:14:58.124 o.a.s.h.c.r.MoveFileAction Timer-2 [INFO] Moving file hdfs://ctr-e138-1518143905142-85179-01-000004.hwx.site:8020/tmp/foo/my-bolt-4-0-1520878438104.txt to /tmp/dest2/my-bolt-4-0-15 20878438104.txt 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-2 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-0 [INFO] File rotation took 29 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-3 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Timer-1 [INFO] File rotation took 28 ms. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-12-my-bolt-executor[6 6] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-8-my-bolt-executor[3 3] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.h.b.AbstractHdfsBolt Thread-16-my-bolt-executor[5 5] [INFO] Tuple failed to write, forcing a flush of existing data. 2018-03-12 18:14:58.132 o.a.s.d.executor Thread-8-my-bolt-executor[3 3] [ERROR] java.nio.channels.ClosedChannelException: null at org.apache.hadoop.hdfs.ExceptionLastSeen.throwException4Close(ExceptionLastSeen.java:73) ~[stormjar.jar:?] at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:153) ~[stormjar.jar:?] at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:105) ~[stormjar.jar:?] at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:57) ~[stormjar.jar:?] at java.io.DataOutputStream.write(DataOutputStream.java:107) ~[?:1.8.0_161] at java.io.FilterOutputStream.write(FilterOutputStream.java:97) ~[?:1.8.0_161] at org.apache.storm.hdfs.common.HDFSWriter.doWrite(HDFSWriter.java:48) ~[stormjar.jar:?] at org.apache.storm.hdfs.common.AbstractHDFSWriter.write(AbstractHDFSWriter.java:40) ~[stormjar.jar:?] at org.apache.storm.hdfs.bolt.AbstractHdfsBolt.execute(AbstractHdfsBolt.java:158) [stormjar.jar:?] at org.apache.storm.daemon.executor$fn__10189$tuple_action_fn__10191.invoke(executor.clj:745) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.daemon.executor$mk_task_receiver$fn__10108.invoke(executor.clj:473) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.disruptor$clojure_handler$reify__4115.onEvent(disruptor.clj:41) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:509) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:487) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:74) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.daemon.executor$fn__10189$fn__10202$fn__10257.invoke(executor.clj:868) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at org.apache.storm.util$async_loop$fn__1221.invoke(util.clj:484) [storm-core-1.2.1.3.0.0.0-1013.jar:1.2.1.3.0.0.0-1013] at clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161] 2018-03-12 18:14:58.133 o.a.s.d.executor Thread-16-my-bolt-executor[5 5]\u00a0\r\n\r\n\u00a0\r\n----\r\n\u00a0\r\n\r\nApparently the Timed rotation policy does not synchronize properly so its possible that the HDFS bolt code can\u00a0attempt to write to a closed writer.\r\n\r\n\u00a0",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-1540.json",
        "creation_time": "2016-02-11T22:55:05.000+0000",
        "bug_report": {
            "Title": "Topology Debug/Sampling Breaks Trident Topologies",
            "Description": "Steps to reproduce:\n\n1. Deploy a Trident topology.\n2. Turn on debug/sampling.\n\nWorkers will crash with the following error:\n\n2016-02-11 14:13:23.617 o.a.s.util [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:448) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:414) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$consume_loop_STAR_$fn__7651.invoke(disruptor.clj:83) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.util$async_loop$fn__554.invoke(util.clj:484) [storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat clojure.lang.AFn.run(AFn.java:22) [clojure-1.7.0.jar:?]\n\tat java.lang.Thread.run(Thread.java:745) [?:1.8.0_72]\nCaused by: java.lang.RuntimeException: java.io.NotSerializableException: org.apache.storm.trident.tuple.ConsList\n\tat org.apache.storm.serialization.SerializableSerializer.write(SerializableSerializer.java:41) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:75) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.serializers.CollectionSerializer.write(CollectionSerializer.java:18) ~[kryo-2.21.jar:?]\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:486) ~[kryo-2.21.jar:?]\n\tat org.apache.storm.serialization.KryoValuesSerializer.serializeInto(KryoValuesSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.serialization.KryoTupleSerializer.serialize(KryoTupleSerializer.java:44) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.worker$mk_transfer_fn$transfer_fn__8346.invoke(worker.clj:186) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.daemon.executor$start_batch_transfer__GT_worker_handler_BANG_$fn__8037.invoke(executor.clj:309) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.disruptor$clojure_handler$reify__7634.onEvent(disruptor.clj:40) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\tat org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:435) ~[storm-core-1.0.0-SNAPSHOT.jar:1.0.0-SNAPSHOT]\n\t... 6 more\n",
            "Priority": "Blocker"
        }
    },
    {
        "filename": "STORM-2275.json",
        "creation_time": "2017-01-04T23:21:06.000+0000",
        "bug_report": {
            "Title": "Nimbus crashed during state transition of topology",
            "Description": "I am copying last few lines of the nimbus logs including stack trace.\n{code}\n2017-01-04 22:18:10.106 pool-15-thread-47 o.a.s.d.n.Nimbus [INFO] Activating DemoTest: DemoTest-21-1483568289\n2017-01-04 22:18:11.646 timer o.a.s.s.EvenScheduler [INFO] Available slots: [f0ea57ab-86d6-401f-9429-52f479b1d69f:6704, f0ea57ab-86d6-401f-9429-52f479b1d69f:6705, f0ea57ab-86d6-401f-9429-52f479b1d69f:670\\\n6, f0ea57ab-86d6-401f-9429-52f479b1d69f:6707, f0ea57ab-86d6-401f-9429-52f479b1d69f:6708, f0ea57ab-86d6-401f-9429-52f479b1d69f:6709, f0ea57ab-86d6-401f-9429-52f479b1d69f:6700, f0ea57ab-86d6-401f-9429-52f4\\\n79b1d69f:6701, f0ea57ab-86d6-401f-9429-52f479b1d69f:6702, f0ea57ab-86d6-401f-9429-52f479b1d69f:6703]\n2017-01-04 22:18:11.648 timer o.a.s.d.n.Nimbus [INFO] Setting new assignment for topology id DemoTest-21-1483568289: Assignment(master_code_dir:storm-local, node_host:{f0ea57ab-86d6-401f-9429-52f479b1d69\\\nf=node1}, executor_node_port:{[10, 10]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [14, 14]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [16, 16]=NodeInfo(node:\\\nf0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [12, 12]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [8, 8]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [6,\\\n 6]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [20, 20]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [4, 4]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f,\\\n port:[6700]), [2, 2]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [18, 18]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [11, 11]=NodeInfo(node:f0ea57ab-86d6-401\\\nf-9429-52f479b1d69f, port:[6701]), [15, 15]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [7, 7]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [9, 9]=NodeInfo(node\\\n:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [21, 21]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [5, 5]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6701]), [3\\\n, 3]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702]), [19, 19]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [17, 17]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d6\\\n9f, port:[6701]), [1, 1]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700]), [13, 13]=NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700])}, executor_start_time_secs:{[12, 12]=1\\\n483568291, [6, 6]=1483568291, [18, 18]=1483568291, [2, 2]=1483568291, [8, 8]=1483568291, [14, 14]=1483568291, [16, 16]=1483568291, [20, 20]=1483568291, [4, 4]=1483568291, [10, 10]=1483568291, [9, 9]=1483\\\n568291, [3, 3]=1483568291, [15, 15]=1483568291, [21, 21]=1483568291, [5, 5]=1483568291, [11, 11]=1483568291, [13, 13]=1483568291, [17, 17]=1483568291, [19, 19]=1483568291, [1, 1]=1483568291, [7, 7]=14835\\\n68291}, worker_resources:{NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6702])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f,\\\n port:[6701])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0), NodeInfo(node:f0ea57ab-86d6-401f-9429-52f479b1d69f, port:[6700])=WorkerResources(mem_on_heap:0.0, mem_off_heap:0.0, cpu:0.0)})\n2017-01-04 22:18:11.660 timer o.a.s.d.n.Nimbus [INFO] Cleaning up DemoTest-20-1483567429\n2017-01-04 22:18:11.668 timer o.a.s.d.n.Nimbus [INFO] Removing dependency jars from blobs - []\n2017-01-04 22:18:12.420 pool-15-thread-51 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormjar.jar\n2017-01-04 22:18:12.990 pool-15-thread-38 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormcode.ser\n2017-01-04 22:18:12.995 pool-15-thread-59 o.a.s.d.n.Nimbus [INFO] Created download session for DemoTest-21-1483568289-stormconf.ser\n2017-01-04 22:18:20.303 timer o.a.s.d.n.Nimbus [INFO] TRANSITION: DemoTest-20-1483567429 REMOVE null false\n2017-01-04 22:18:20.304 timer o.a.s.d.n.Nimbus [ERROR] Error while processing event\njava.lang.RuntimeException: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1174)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:83)\nCaused by: java.lang.NullPointerException\n        at org.apache.storm.daemon.nimbus.Nimbus.transition(Nimbus.java:1215)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$delayEvent$16(Nimbus.java:1172)\n        ... 1 more\n2017-01-04 22:18:20.304 timer o.a.s.u.Utils [ERROR] Halting process: Error while processing event\njava.lang.RuntimeException: Halting process: Error while processing event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1792)\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$15(Nimbus.java:1107)\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:104)\n2017-01-04 22:18:20.315 Thread-9 o.a.s.d.n.Nimbus [INFO] Shutting down master\n{code}\n\nThe problem is that we are assuming that the base will be non-null which is incorrect leading to NPE.",
            "Priority": "Blocker"
        }
    },
    {
        "filename": "STORM-2873.json",
        "creation_time": "2017-12-29T18:44:56.000+0000",
        "bug_report": {
            "Title": "Backpressure implentation delete ephemeral too frequently",
            "Description": "The backpressure implementation deletes the znode when not relevant but that hits zookeeper issue of too frequent deletion and creation or same path for ephemeral znode. Below is exception we get when zk hits this issue:\r\n\r\n{code}\r\n017-09-18 15:00:34.980 b.s.util WorkerBackpressureThread [WARN] Expecting exception of class: class org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException, but exception chain only contains: (#<NoAuthException org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721>)\r\n2017-09-18 15:00:34.980 b.s.d.worker WorkerBackpressureThread [ERROR] workerBackpressure update failed when connecting to ZK ... will retry\r\njava.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\r\n\tat backtype.storm.util$wrap_in_runtime.invoke(util.clj:52) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:110) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:464) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.zookeeper$delete_recursive.invoke(zookeeper.clj:189) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.cluster_state.zookeeper_state_factory$_mkState$reify__4207.delete_node(zookeeper_state_factory.clj:117) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat org.apache.storm.pacemaker.pacemaker_state_factory$_mkState$reify__4254.delete_node(pacemaker_state_factory.clj:174) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor859.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.cluster$mk_storm_cluster_state$reify__3873.worker_backpressure_BANG_(cluster.clj:421) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat sun.reflect.GeneratedMethodAccessor857.invoke(Unknown Source) ~[?:?]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]\r\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.6.0.jar:?]\r\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.6.0.jar:?]\r\n\tat backtype.storm.daemon.worker$mk_backpressure_handler$fn__7117.invoke(worker.clj:161) [storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.disruptor$worker_backpressure_handler$reify__6432.onEvent(disruptor.clj:57) [storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.utils.WorkerBackpressureThread.run(WorkerBackpressureThread.java:64) [storm-core-0.10.2.y.jar:0.10.2.y]\r\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /backpressure/TestTopology--170916-005358-117-1505523256/d11af335-6e03-48b6-801e-7369acfe9ffd-127.0.0.1-6721\r\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:113) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\tat backtype.storm.zookeeper$delete_node.doInvoke(zookeeper.clj:107) ~[storm-core-0.10.2.y.jar:0.10.2.y]\r\n\t... 23 more\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2279.json",
        "creation_time": "2017-01-05T20:59:11.000+0000",
        "bug_report": {
            "Title": "Unable to open bolt page of storm ui",
            "Description": "With latest storm code, I am unable to open ui and see bolt information. I am using the vagrant setup. On the ui page that open, I see the following error.\n{code}\nInternal Server Error\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getComponentPageInfo(Nimbus.java:1369)\n\tat org.apache.storm.generated.Nimbus$Client.getComponentPageInfo(Nimbus.java:1353)\n\tat org.apache.storm.ui.core$component_page.invoke(core.clj:1026)\n\tat org.apache.storm.ui.core$fn__4308.invoke(core.clj:1214)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__789.invoke(core.clj:100)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__777.invoke(core.clj:46)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__770.invoke(core.clj:31)\n\tat org.apache.storm.shade.compojure.core$routing$fn__795.invoke(core.clj:113)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:113)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__799.invoke(core.clj:118)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__3573.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__3102.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__2152.invoke(helpers.clj:54)\n\tat org.apache.storm.ui.core$catch_errors$fn__4474.invoke(core.clj:1460)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__1844.invoke(keyword_params.clj:35)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__1887.invoke(nested_params.clj:84)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__1816.invoke(params.clj:64)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__1924.invoke(multipart_params.clj:118)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__2139.invoke(flash.clj:35)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__2125.invoke(session.clj:98)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__1674.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__1678.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)\n{code}\nUrl: http://node1:8080/component.html?id=SlidingTimeCorrectness-winSec1slideSec1VerificationBolt&topology_id=SlidingWindowTestw1s1-2-1483646178\n\nThere is a stacktrace corresponding to this in nimbus.log showing IndexOutOfBound error:\n{code}\n2017-01-05 19:57:26.934 pool-15-thread-41 o.a.s.d.n.Nimbus [WARN] getComponentPageInfo exception. (topo id='SlidingWindowTestw1s1-2-1483646178')\njava.lang.ArrayIndexOutOfBoundsException: -2\n        at java.util.ArrayList.elementData(ArrayList.java:418)\n        at java.util.ArrayList.get(ArrayList.java:431)\n        at org.apache.storm.daemon.nimbus.Nimbus.getComponentPageInfo(Nimbus.java:3606)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4097)\n        at org.apache.storm.generated.Nimbus$Processor$getComponentPageInfo.getResult(Nimbus.java:4081)\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39)\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\n        at org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:160)\n        at org.apache.storm.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518)\n        at org.apache.storm.thrift.server.Invocation.run(Invocation.java:18)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n{code}\n\nThe problem is that we expect the index to be positive, but since it is a mod of hashcode it can be negative.\n{code}\n                int taskIndex = TupleUtils.listHashCode(Arrays.asList(componentId)) %\n                        tasks.size();\n                int taskId = tasks.get(taskIndex);\n{code}\nhttps://github.com/apache/storm/blob/2b82fc8b5328fd4fbd680998c6051d9496c102d7/storm-core/src/jvm/org/apache/storm/daemon/nimbus/Nimbus.java#L3605\n",
            "Priority": "Blocker"
        }
    },
    {
        "filename": "STORM-3079.json",
        "creation_time": "2018-05-17T19:29:10.000+0000",
        "bug_report": {
            "Title": "improve getMessage support for ThriftExceptions",
            "Description": "I've seen error callstacks similar to this and been confused as to the null message.\u00a0 The generated thrift code does not support getMessage().\u00a0 We should try and improve the log messages.\r\n\r\n\u00a0\r\n2018-05-16 21:15:04.596 o.a.s.d.n.Nimbus timer [INFO] Exception {}\r\norg.apache.storm.generated.KeyNotFoundException: null        at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:258) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:393) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:670) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2333) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2387) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2674) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3096.json",
        "creation_time": "2018-06-05T18:39:44.000+0000",
        "bug_report": {
            "Title": "blobstores deleted before topologies can be submitted",
            "Description": "STORM-3053 attempted to fix the race condition where a nimbus timer causes doCleanup() to delete the blobs during topology submission.\u00a0 After the fix went in, we still see the error occurring.\u00a0 I tracked the problem down to\u00a0idsOfTopologiesWithPrivateWorkerKeys() at [https://github.com/apache/storm/blob/master/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L893.]\u00a0\r\n\r\n\u00a0\r\n\r\nThe previous change to wait to delete topologies is useful, but should be moved after all the topologies are discovered.\r\n\r\n\u00a0\r\n{code:java}\r\n\r\n 018-06-03 11:53:42.581 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] Received topology submission for topology-testHardCoreFaultTolerance-4 (storm-0.10.2.y.248 JDK-1.8.0_131) with conf {topology.users=[hadoopqa@DEV.YGRID.YAHOO.COM, hadoopqa], topology.acker.executors=0, storm.zookeeper.superACL=sasl:gstorm, topology.workers=3, topology.submitter.principal=hadoopqa@DEV.YGRID.YAHOO.COM, topology.debug=true, topology.disable.loadaware.messaging=true, storm.zookeeper.topology.auth.payload=#########################################, topology.name=topology-testHardCoreFaultTolerance-4, storm.zookeeper.topology.auth.scheme=digest, topology.kryo.register={}, nimbus.task.timeout.secs=200, storm.id=topology-testHardCoreFaultTolerance-4-18-1528026822, topology.kryo.decorators=[], topology.eventlogger.executors=0, topology.submitter.user=hadoopqa, topology.max.task.parallelism=null}\r\n 2018-06-03 11:53:42.591 o.a.s.d.n.Nimbus timer [INFO] Cleaning up topology-testHardCoreFaultTolerance-4-18-1528026822\r\n 2018-06-03 11:53:42.597 o.a.s.d.n.Nimbus pool-37-thread-1014 [INFO] uploadedJar /home/y/var/storm/nimbus/inbox/stormjar-3c73de98-ced7-4fd0-86d9-8fba3e5100f1.jar\r\n 2018-06-03 11:53:42.601 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.621 o.a.s.d.n.Nimbus timer [INFO] Exception {}\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlob(LocalFsBlobStore.java:394) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.BlobStore.readBlobTo(BlobStore.java:310) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.BlobStore.readBlob(BlobStore.java:339) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.TopoCache.readTopology(TopoCache.java:67) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.readStormTopologyAsNimbus(Nimbus.java:680) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.rmDependencyJarsInTopology(Nimbus.java:2389) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2443) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2730) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.StormTimer$1.run(StormTimer.java:111) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n 2018-06-03 11:53:42.871 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormconf.ser/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.881 o.a.s.c.StormClusterStateImpl pool-37-thread-1014 [INFO] set-path: /blobstore/topology-testHardCoreFaultTolerance-4-18-1528026822-stormcode.ser/openqe82blue-n1.blue.ygrid.yahoo.com:50560-1\r\n 2018-06-03 11:53:42.886 o.a.s.d.n.Nimbus pool-37-thread-1023 [INFO] Created download session dd7fa916-e489-47a5-beea-ac3eba6ed905 for topology-testHardCoreFaultTolerance-0-14-1528026818-stormjar.jar\r\n 2018-06-03 11:53:42.888 o.a.s.d.n.Nimbus pool-37-thread-1014 [WARN] Topology submission exception. (topology name='topology-testHardCoreFaultTolerance-4')\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\r\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n 2018-06-03 11:53:42.888 o.a.t.ProcessFunction pool-37-thread-1014 [ERROR] Internal error processing submitTopologyWithOpts\r\n org.apache.storm.utils.WrappedKeyNotFoundException: topology-testHardCoreFaultTolerance-4-18-1528026822-stormjar.jar\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getStoredBlobMeta(LocalFsBlobStore.java:259) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.blobstore.LocalFsBlobStore.getBlobReplication(LocalFsBlobStore.java:423) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.getBlobReplicationCount(Nimbus.java:1499) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.waitForDesiredCodeReplication(Nimbus.java:1509) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2982) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [libthrift-0.11.0.jar:0.11.0]\r\n at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [libthrift-0.11.0.jar:0.11.0]\r\n at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-1642.json",
        "creation_time": "2016-03-21T07:34:06.000+0000",
        "bug_report": {
            "Title": "NullPointerException when deserialize",
            "Description": "Hi:\nI've encountered the following NPE when storm tries to deserialize. I did not use OutputCollector concurrently in my code.  The only object we are passing between bolts are a thrift object, and we have written a serializer for it. I've attached the code of serializer and please help to check whether there are any potential bugs there.\n\n2016-03-04 17:17:43.583 b.s.util [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n2016-03-04 17:17:43.584 b.s.d.executor [ERROR]\njava.lang.RuntimeException: java.lang.NullPointerException\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:135) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:106) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:80) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$fn__5694$fn__5707$fn__5758.invoke(executor.clj:819) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:479) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]\nCaused by: java.lang.NullPointerException\n        at com.esotericsoftware.kryo.io.Input.setBuffer(Input.java:57) ~[kryo-2.21.jar:?]\n        at backtype.storm.serialization.KryoTupleDeserializer.deserialize(KryoTupleDeserializer.java:47) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__5615.invoke(executor.clj:433) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.disruptor$clojure_handler$reify__5189.onEvent(disruptor.clj:58) ~[storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:132) ~[storm-core-0.10.0.jar:0.10.0]\n        ... 6 more\n2016-03-04 17:17:43.648 b.s.util [ERROR] Halting process: (\"Worker died\")\njava.lang.RuntimeException: (\"Worker died\")\n        at backtype.storm.util$exit_process_BANG_.doInvoke(util.clj:336) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.RestFn.invoke(RestFn.java:423) [clojure-1.6.0.jar:?]\n        at backtype.storm.daemon.worker$fn__7188$fn__7189.invoke(worker.clj:536) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.daemon.executor$mk_executor_data$fn__5523$fn__5524.invoke(executor.clj:261) [storm-core-0.10.0.jar:0.10.0]\n        at backtype.storm.util$async_loop$fn__545.invoke(util.clj:489) [storm-core-0.10.0.jar:0.10.0]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_60]",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2700.json",
        "creation_time": "2017-08-21T14:09:50.000+0000",
        "bug_report": {
            "Title": "Blobstore shouldn't check ACL when Blobstore Acl validation disabled",
            "Description": "When \n{code:java}\nstorm.blobstore.acl.validation.enabled: false\n{code}\nis set, blobstore still checks ACL.\n\n\n{code:java}\n2017-08-21 13:56:19.800 o.a.s.d.s.Slot SLOT_6702 [ERROR] Error when processing event\njava.util.concurrent.ExecutionException: AuthorizationException(msg:ethan does not have READ access to key1)\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[?:1.8.0_131]\n        at java.util.concurrent.FutureTask.get(FutureTask.java:206) ~[?:1.8.0_131]\n        at org.apache.storm.localizer.LocalDownloadedResource$NoCancelFuture.get(LocalDownloadedResource.java:63) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.handleWaitingForBlobLocalization(Slot.java:410) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.stateMachineStep(Slot.java:305) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:789) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\nCaused by: org.apache.storm.generated.AuthorizationException\n        at org.apache.storm.localizer.Localizer.downloadBlob(Localizer.java:527) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer.access$000(Localizer.java:68) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:497) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.localizer.Localizer$DownloadBlob.call(Localizer.java:473) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\n2017-08-21 13:56:19.800 o.a.s.u.Utils SLOT_6702 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:437) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n        at org.apache.storm.daemon.supervisor.Slot.run(Slot.java:823) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n2017-08-21 13:56:19.802 o.a.s.d.s.Supervisor Thread-6 [INFO] Shutting down supervisor b350cfb4-b333-4ea5-965e-b0698aaea80f-10.88.214.182\n2017-08-21 13:56:19.803 o.a.s.e.EventManagerImp Thread-5 [INFO] Event manager interrupted\n{code}\n\n\nReproduce:\n\n1. Create a blobstore with permission set to one user (e.g mapredqa).\n{code:java}\nsudo -u mapredqa storm blobstore create --file test-blobstore.txt --acl u:mapredqa:rwa key1\n{code}\n\n2. Submit a topology with topology.blobstore.map config as someone else (e.g. ethan).\n{code:java}\nsudo -u ethan storm jar /tmp/storm-starter-2.0.0-SNAPSHOT.jar org.apache.storm.starter.WordCountTopology wc -c topology.blobstore.map='{\"key1\":{\"localname\":\"test-blobstore.txt\", \"uncompress\":false}}'\n{code}\n",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-1663.json",
        "creation_time": "2016-03-29T06:07:27.000+0000",
        "bug_report": {
            "Title": "Clicking on an active topology from storm ui home page and then refreshing the page throws exception",
            "Description": "The exception thrown is:\n\norg.apache.storm.thrift.transport.TTransportException\n\tat org.apache.storm.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:129)\n\tat org.apache.storm.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)\n\tat org.apache.storm.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.storm.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:77)\n\tat org.apache.storm.generated.Nimbus$Client.recv_getTopologyPageInfo(Nimbus.java:1243)\n\tat org.apache.storm.generated.Nimbus$Client.getTopologyPageInfo(Nimbus.java:1228)\n\tat org.apache.storm.ui.core$topology_page.invoke(core.clj:638)\n\tat org.apache.storm.ui.core$fn__3662.invoke(core.clj:987)\n\tat org.apache.storm.shade.compojure.core$make_route$fn__302.invoke(core.clj:93)\n\tat org.apache.storm.shade.compojure.core$if_route$fn__290.invoke(core.clj:39)\n\tat org.apache.storm.shade.compojure.core$if_method$fn__283.invoke(core.clj:24)\n\tat org.apache.storm.shade.compojure.core$routing$fn__308.invoke(core.clj:106)\n\tat clojure.core$some.invoke(core.clj:2570)\n\tat org.apache.storm.shade.compojure.core$routing.doInvoke(core.clj:106)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:139)\n\tat clojure.core$apply.invoke(core.clj:632)\n\tat org.apache.storm.shade.compojure.core$routes$fn__312.invoke(core.clj:111)\n\tat org.apache.storm.shade.ring.middleware.json$wrap_json_params$fn__1204.invoke(json.clj:56)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.reload$wrap_reload$fn__724.invoke(reload.clj:22)\n\tat org.apache.storm.ui.helpers$requests_middleware$fn__3091.invoke(helpers.clj:50)\n\tat org.apache.storm.ui.core$catch_errors$fn__3837.invoke(core.clj:1250)\n\tat org.apache.storm.shade.ring.middleware.keyword_params$wrap_keyword_params$fn__2852.invoke(keyword_params.clj:27)\n\tat org.apache.storm.shade.ring.middleware.nested_params$wrap_nested_params$fn__2892.invoke(nested_params.clj:65)\n\tat org.apache.storm.shade.ring.middleware.params$wrap_params$fn__2823.invoke(params.clj:55)\n\tat org.apache.storm.shade.ring.middleware.multipart_params$wrap_multipart_params$fn__765.invoke(multipart_params.clj:103)\n\tat org.apache.storm.shade.ring.middleware.flash$wrap_flash$fn__3075.invoke(flash.clj:14)\n\tat org.apache.storm.shade.ring.middleware.session$wrap_session$fn__3063.invoke(session.clj:43)\n\tat org.apache.storm.shade.ring.middleware.cookies$wrap_cookies$fn__2991.invoke(cookies.clj:160)\n\tat org.apache.storm.shade.ring.util.servlet$make_service_method$fn__2729.invoke(servlet.clj:127)\n\tat org.apache.storm.shade.ring.util.servlet$servlet$fn__2733.invoke(servlet.clj:136)\n\tat org.apache.storm.shade.ring.util.servlet.proxy$javax.servlet.http.HttpServlet$ff19274a.service(Unknown Source)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:654)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1320)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.handle(AccessLoggingFilter.java:47)\n\tat org.apache.storm.logging.filters.AccessLoggingFilter.doFilter(AccessLoggingFilter.java:39)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.handle(CrossOriginFilter.java:247)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlets.CrossOriginFilter.doFilter(CrossOriginFilter.java:210)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1291)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:443)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1044)\n\tat org.apache.storm.shade.org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:372)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:978)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.Server.handle(Server.java:369)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:486)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:933)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:995)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.apache.storm.shade.org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.apache.storm.shade.org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:668)\n\tat org.apache.storm.shade.org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.apache.storm.shade.org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:745)",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2518.json",
        "creation_time": "2017-05-17T06:26:37.000+0000",
        "bug_report": {
            "Title": "NPE during uploading dependency artifacts with secured cluster",
            "Description": "While adding ACL to USER from uploading artifacts, \"name\" field is actually optional for thrift specification, but Nimbus reads the value without checking null while fixing ACL.\n\n{code}\n2017-05-16 14:57:02.527 o.a.s.t.s.TThreadPoolServer pool-45-thread-136 [ERROR] Error occurred during processing of message.\njava.lang.NullPointerException: null\n        at org.apache.storm.blobstore.BlobStoreAclHandler.fixACLsForUser(BlobStoreAclHandler.java:382) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableACLs(BlobStoreAclHandler.java:357) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.BlobStoreAclHandler.normalizeSettableBlobMeta(BlobStoreAclHandler.java:306) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.blobstore.LocalFsBlobStore.createBlob(LocalFsBlobStore.java:103) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_112]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_112]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]\n        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]\n        at clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93) ~[clojure-1.7.0.jar:?]\n        at clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28) ~[clojure-1.7.0.jar:?]\n        at org.apache.storm.daemon.nimbus$mk_reified_nimbus$reify__9064.beginCreateBlob(nimbus.clj:2047) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3430) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.generated.Nimbus$Processor$beginCreateBlob.getResult(Nimbus.java:3414) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.security.auth.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:144) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[storm-core-1.1.0.2.6.0.2-SNAPSHOT.jar:1.1.0.2.6.0.2-SNAPSHOT]\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]\n{code}\n\nUploading artifacts fails and topology submission also fails.",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3124.json",
        "creation_time": "2018-06-27T13:28:01.000+0000",
        "bug_report": {
            "Title": "Failures talking to Pacemaker",
            "Description": "{code:java}\r\n2018-06-25 20:21:05.220 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 7 more attempts.\r\n2018-06-25 20:21:06.220 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:06.220 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 6 more attempts.\r\n2018-06-25 20:21:07.220 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:07.221 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 5 more attempts.\r\n2018-06-25 20:21:08.221 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:08.221 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 4 more attempts.\r\n2018-06-25 20:21:09.222 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:09.222 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 3 more attempts.\r\n2018-06-25 20:21:10.222 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:10.222 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 2 more attempts.\r\n2018-06-25 20:21:11.223 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:11.223 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 1 more attempts.\r\n2018-06-25 20:21:12.223 o.a.s.p.PacemakerClient timer [ERROR] error attempting to write to a channel Timed out waiting for channel ready..\r\n2018-06-25 20:21:12.223 o.a.s.p.PacemakerClient timer [ERROR] Not getting response or getting null response. Making 0 more attempts.\r\n2018-06-25 20:21:13.224 o.a.s.p.PacemakerClientPool timer [WARN] Failed to connect to the pacemaker server openqe74blue-n2.blue.ygrid.yahoo.com\r\n2018-06-25 20:21:13.229 o.a.s.d.n.Nimbus pool-37-thread-481 [INFO] uploadedJar /home/y/var/storm/nimbus/inbox/stormjar-c5893ba3-21c6-4397-84e2-54aab8e091a9.jar\r\n2018-06-25 20:21:13.225 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2773) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:110) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:226) [storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.RuntimeException: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:214) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\nCaused by: org.apache.storm.pacemaker.PacemakerConnectionException: Failed to connect to any Pacemaker.\r\n        at org.apache.storm.pacemaker.PacemakerClientPool.sendAll(PacemakerClientPool.java:71) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.get_worker_hb_children(PaceMakerStateStorage.java:199) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.heartbeatStorms(StormClusterStateImpl.java:482) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.topoIdsToClean(Nimbus.java:897) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.doCleanup(Nimbus.java:2469) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2771) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-06-25 20:21:13.231 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:470) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:490) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:253) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-06-25 20:21:13.232 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master\r\n2018-06-25 20:21:13.232 o.a.s.u.Utils Thread-13 [INFO] Halting after 10 seconds\r\n\r\n\r\n2018-06-25 20:21:13.677 o.a.s.d.n.Nimbus pool-37-thread-481 [INFO] desired replication count 1 achieved, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1\r\n2018-06-25 20:21:13.678 o.a.s.d.n.Nimbus pool-37-thread-481 [WARN] Topology submission exception. (topology name='run')\r\njava.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-06-25 20:21:13.680 o.a.s.t.ProcessFunction pool-37-thread-481 [ERROR] Internal error processing submitTopologyWithOpts\r\njava.lang.RuntimeException: java.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3049) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3511) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3490) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3024) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 9 more\r\n\r\n{code}\r\nWe're having sporadic failures talking to Pacemaker.\u00a0 This callstack shows us unable to launch topologies.",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2095.json",
        "creation_time": "2016-09-14T16:00:30.000+0000",
        "bug_report": {
            "Title": "Nimbus dies and never recovers due to java.nio.file.DirectoryNotEmptyException",
            "Description": "To Recreate:\n--------------------------------------\n1) Create a blobstore key for a large file (1 or 2 GB). Size of the file does not matter if nimbus can be killed while the blob is being created.\n2) while the blob is being created, restart nimbus (this is easiest way to regenerate, there can be various reasons due to which a blob couldn't be successfully created in nimbus)\n3) When nimbus tries to start on restart, it will keep dying due to DirectoryNotEmptyException and never come up.\n\nExpected Behavior\n--------------------------------------\nPartial blobstore key is deleted cleanly and doesn't affect nimbus.\n\nThe actual, incorrect behavior.\n--------------------------------------\n2016-09-14 15:07:48.518 o.a.s.zookeeper [INFO] Queued up for leader lock.\n2016-09-14 15:07:48.576 o.a.s.zookeeper [INFO] xxx gained leadership\n2016-09-14 15:07:48.581 o.a.s.d.nimbus [ERROR] Error on initialization of server service-handler\njava.lang.RuntimeException: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:229)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat clojure.lang.Reflector.invokeMatchingMethod(Reflector.java:93)\n\tat clojure.lang.Reflector.invokeInstanceMethod(Reflector.java:28)\n\tat org.apache.storm.daemon.nimbus$setup_blobstore.invoke(nimbus.clj:1196)\n\tat org.apache.storm.daemon.nimbus$fn__7064$exec_fn__2461__auto____7065.invoke(nimbus.clj:1416)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat clojure.core$apply.invoke(core.clj:630)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\nCaused by: java.nio.file.DirectoryNotEmptyException: /opt/storm/storm-local/blobs/955/some_big_file\n\tat sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n\tat sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)\n\tat java.nio.file.Files.deleteIfExists(Files.java:1165)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.delete(FileBlobStoreImpl.java:239)\n\tat org.apache.storm.blobstore.FileBlobStoreImpl.deleteKey(FileBlobStoreImpl.java:178)\n\tat org.apache.storm.blobstore.LocalFsBlobStore.deleteBlob(LocalFsBlobStore.java:226)\n\t... 19 more\n2016-09-14 15:07:48.588 o.a.s.util [ERROR] Halting process: (\"Error on initialization\")\njava.lang.RuntimeException: (\"Error on initialization\")\n\tat org.apache.storm.util$exit_process_BANG_.doInvoke(util.clj:341)\n\tat clojure.lang.RestFn.invoke(RestFn.java:423)\n\tat org.apache.storm.daemon.nimbus$fn__7064$service_handler__7308.doInvoke(nimbus.clj:1358)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat org.apache.storm.daemon.nimbus$launch_server_BANG_.invoke(nimbus.clj:2206)\n\tat org.apache.storm.daemon.nimbus$_launch.invoke(nimbus.clj:2239)\n\tat org.apache.storm.daemon.nimbus$_main.invoke(nimbus.clj:2262)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat org.apache.storm.daemon.nimbus.main(Unknown Source)\n\n\n[root]# ls -l  /opt/storm/storm-local/blobs/955/some_big_file\ntotal 591060\n-rw-r--r-- 1 storm storm 605241344 Sep 14 15:07 1473865562841.tmp",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2847.json",
        "creation_time": "2017-12-07T16:51:01.000+0000",
        "bug_report": {
            "Title": "Exception thrown after rebalance IllegalArgumentException",
            "Description": "After rebalance the storm-kafka-client spout attempts to check the current position of partitions that are no longer assigned to the current spout. This occurs in a topology with multiple spout instances.\r\n\r\njava.lang.IllegalArgumentException: You can only check the position for partitions assigned to this consumer. at org.apache.kafka.clients.consumer.KafkaConsumer.position(KafkaConsumer.java:1262) at org.apache.storm.kafka.spout.KafkaSpout.commitOffsetsForAckedTuples(KafkaSpout.java:473)",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-1114.json",
        "creation_time": "2015-10-15T15:41:36.000+0000",
        "bug_report": {
            "Title": "Racing condition in trident zookeeper zk-node create/delete",
            "Description": "In production for some trident topology, we met the bug that some workers are trying to create a zk-node that is already existent or delete a zk node that has already been deleted. This causes the worker process to die.\n \nWe dissect the problem and figure out that there exists racing condition in trident TransactionalState's zk-node create and delete codes.\n\nfailure stack trace in worker.log:\n{noformat}\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ignoreStoredMetadata\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:119) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CreateBuilderImpl$3.forPath(CreateBuilderImpl.java:193) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.forPath(TransactionalState.java:83) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.createNode(TransactionalState.java:100) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.setData(TransactionalState.java:115) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 9 more\n2015-10-14 18:10:43.786 b.s.util [ERROR] Halting process: (\"Worker died\")\n{noformat}\n\n\n{noformat}\nCaused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /rainbowHdfsPath\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:239) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl$5.call(DeleteBuilderImpl.java:234) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.pathInForeground(DeleteBuilderImpl.java:230) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:215) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.storm.shade.org.apache.curator.framework.imps.DeleteBuilderImpl.forPath(DeleteBuilderImpl.java:42) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at storm.trident.topology.state.TransactionalState.delete(TransactionalState.java:126) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        ... 12 more\n2015-10-14 18:10:28.799 b.s.util [ERROR] Halting process: (\"Worker died\")\njava.lang.RuntimeException: (\"Worker died\")\n{noformat}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2811.json",
        "creation_time": "2017-11-12T08:37:10.000+0000",
        "bug_report": {
            "Title": "Nimbus may throw NPE if the same topology is killed multiple times, and the integration test kills the same topology multiple times",
            "Description": "{quote}\r\n2017-11-12 08:45:50.353 o.a.s.d.n.Nimbus pool-14-thread-47 [WARN] Kill topology exception. (topology name='SlidingWindowTest-window20-slide10')\r\njava.lang.NullPointerException: null\r\n\tat org.apache.storm.cluster.IStormClusterState.getTopoId(IStormClusterState.java:171) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.nimbus.Nimbus.tryReadTopoConfFromName(Nimbus.java:1970) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.daemon.nimbus.Nimbus.killTopologyWithOpts(Nimbus.java:2760) ~[storm-server-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3226) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.storm.generated.Nimbus$Processor$killTopologyWithOpts.getResult(Nimbus.java:3210) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.storm.security.auth.SimpleTransportPlugin$SimpleWrapProcessor.process(SimpleTransportPlugin.java:167) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n\tat org.apache.thrift.server.AbstractNonblockingServer$FrameBuffer.invoke(AbstractNonblockingServer.java:518) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat org.apache.thrift.server.Invocation.run(Invocation.java:18) ~[libthrift-0.10.0.jar:0.10.0]\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_144]\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_144]\r\n\tat java.lang.Thread.run(Thread.java:748) [?:1.8.0_144]\r\n{quote}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2903.json",
        "creation_time": "2018-01-19T17:10:01.000+0000",
        "bug_report": {
            "Title": "Fix possible NullPointerException in AbstractAutoCreds",
            "Description": "Observed below exception while testing Hive token mechanism.\r\n\r\n\u00a0 \u00a0 ```\r\n\u00a0 \u00a0 Caused by: java.lang.NullPointerException\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.common.AbstractAutoCreds.addTokensToUGI(AbstractAutoCreds.java:219) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.common.AbstractAutoCreds.populateSubject(AbstractAutoCreds.java:118) ~[storm-autocreds-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.security.auth.AuthUtils.populateSubject(AuthUtils.java:228) ~[storm-core-1.2.0.3.1.0.0-526.jar:1.2.0.3.1.0.0-526]\r\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ... 10 more\r\n\u00a0 \u00a0 2018-01-19 16:23:26.157 o.a.s.util main [ERROR] Halting process: (\"Error on initialization\")\r\n\u00a0 \u00a0 ```",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3168.json",
        "creation_time": "2018-08-01T19:31:42.000+0000",
        "bug_report": {
            "Title": "AsyncLocalizer cleanup appears to crash",
            "Description": "I was investigating these blobstore download messages which keep repeating for hours in the supervisor (and nimbus logs).\u00a0 I turned on debug logging, and was expecting a cleanup debug message every 30 seconds ([https://github.com/apache/storm/blob/master/storm-server/src/main/java/org/apache/storm/localizer/AsyncLocalizer.java#L606).]\u00a0 It did not log.\u00a0 I restarted the supervisor, and it started logging again.\u00a0 It appears to have crashed with some error.\u00a0\u00a0\r\n\r\nWe should make sure the cleanup runs continuously and logs any failures to investigate.\r\n\r\n\u00a0\r\n{code:java}\r\n2018-07-30 23:25:35.691 o.a.s.l.AsyncLocalizer AsyncLocalizer Executor - 2 [ERROR] Could not update blob, will retry again later\r\n\r\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Could not download...\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.updateBlobs(AsyncLocalizer.java:303) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n\r\nCaused by: java.lang.RuntimeException: Could not download...\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:268) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 ... 3 more\r\n\r\nCaused by: org.apache.storm.generated.KeyNotFoundException\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25853) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result$getBlobMeta_resultStandardScheme.read(Nimbus.java:25821) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$getBlobMeta_result.read(Nimbus.java:25752) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$Client.recv_getBlobMeta(Nimbus.java:798) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.generated.Nimbus$Client.getBlobMeta(Nimbus.java:785) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.blobstore.NimbusBlobStore.getBlobMeta(NimbusBlobStore.java:85) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.LocallyCachedTopologyBlob.getRemoteVersion(LocallyCachedTopologyBlob.java:122) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at org.apache.storm.localizer.AsyncLocalizer.lambda$downloadOrUpdate$69(AsyncLocalizer.java:252) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[?:1.8.0_131]\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 ... 3 more\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2986.json",
        "creation_time": "2018-03-05T21:41:24.000+0000",
        "bug_report": {
            "Title": "NPE from LogCleaner",
            "Description": "So I set\r\n{code:java}\r\nlogviewer.cleanup.interval.secs: 10\r\n{code}\r\nto start LogCleaner thread. But from logviewer.log:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-03-05 21:31:17.629 o.a.s.v.ConfigValidation main [WARN] storm.messaging.netty.max_retries is a deprecated config please see class org.apache.storm.Config.STORM_MESSAGING_NETTY_MAX_RETRIES for more information.\r\n2018-03-05 21:31:17.650 o.a.s.d.l.LogviewerServer main [INFO] Starting Logviewer HTTP servers...\r\n2018-03-05 21:31:17.684 o.e.j.u.log main [INFO] Logging initialized @2455ms to org.eclipse.jetty.util.log.Slf4jLog\r\n2018-03-05 21:31:17.877 o.a.s.d.l.u.LogCleaner main [INFO] configured max total size of worker logs: 2 MB, max total size of worker logs per directory: 1 MB\r\n2018-03-05 21:31:18.017 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter\r\n2018-03-05 21:31:18.022 o.a.s.d.l.u.LogCleaner logviewer-cleanup [ERROR] Exception while cleaning up old log.\r\njava.lang.NullPointerException: null\r\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\n2018-03-05 21:31:18.024 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\r\n2018-03-05 21:31:18.031 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...\r\n2018-03-05 21:31:18.031 o.a.s.d.l.LogviewerServer main [INFO] Starting Logviewer...\r\n2018-03-05 21:31:18.041 o.e.j.s.Server main [INFO] jetty-9.4.7.v20170914\r\n2018-03-05 21:31:18.215 o.a.h.s.a.s.KerberosAuthenticationHandler main [INFO] Login using keytab /keytabs/HTTP.keytab, for principal HTTP/persistmist.corp.ne1.yahoo.com\r\n2018-03-05 21:31:20.832 o.h.v.i.u.Version main [INFO] HV000001: Hibernate Validator 5.3.4.Final\r\n2018-03-05 21:31:21.215 o.e.j.s.h.ContextHandler main [INFO] Started o.e.j.s.ServletContextHandler@65bb9029{/,file:///tmp/apache-storm-2.0.0-SNAPSHOT/public/,AVAILABLE}\r\n2018-03-05 21:31:21.287 o.e.j.s.AbstractConnector main [INFO] Started ServerConnector@30506c0d{HTTP/1.1,[http/1.1]}{0.0.0.0:8000}\r\n2018-03-05 21:31:21.288 o.e.j.s.Server main [INFO] Started @6060ms\r\n2018-03-05 21:31:28.038 o.a.s.d.l.u.LogCleaner logviewer-cleanup [ERROR] Exception while cleaning up old log.\r\njava.lang.NullPointerException: null\r\nat java.util.Arrays.stream(Arrays.java:5004) ~[?:1.8.0_131]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.selectDirsForCleanup(LogCleaner.java:217) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.daemon.logviewer.utils.LogCleaner.run(LogCleaner.java:135) ~[storm-webapp-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$1.run(StormTimer.java:207) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\r\nat org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:81) ~[storm-client-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]{code}\r\n\u00a0\r\n\r\nIt's because there is no workers-artifacts directory at the very beginning before submitting any topologies.\u00a0 Users\u00a0can fix it by\u00a0manually creating the directory. But it's better to have it solve fixed.\u00a0",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2197.json",
        "creation_time": "2016-11-10T03:57:30.000+0000",
        "bug_report": {
            "Title": "NimbusClient connectins leak due to leakage in ThriftClient.",
            "Description": "Nimbus client connections are not closed when there are errors while connecting to nimbus. Created TSocket in ThriftClient should have been closed in case of errors.\n\n2016-11-03 08:09:37.766 b.s.s.a.k.KerberosSaslTransportPlugin [ERROR] Client failed to open SaslClientTransport to interact with a server during session initiation: org.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\norg.apache.thrift7.transport.TTransportException: Peer indicated failure: GSS initiate failed\n\tat org.apache.thrift7.transport.TSaslTransport.receiveSaslMessage(TSaslTransport.java:199) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:277) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) ~[storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:145) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:141) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.7.0_60]\n\tat javax.security.auth.Subject.doAs(Subject.java:415) [?:1.7.0_60]\n\tat backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:140) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:48) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:103) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.security.auth.ThriftClient.<init>(ThriftClient.java:72) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.<init>(NimbusClient.java:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.utils.NimbusClient.getConfiguredClientAs(NimbusClient.java:82) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$nimbus_summary.invoke(core.clj:584) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat backtype.storm.ui.core$fn__10334.invoke(core.clj:1009) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$make_route$fn__7476.invoke(core.clj:93) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_route$fn__7464.invoke(core.clj:39) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$if_method$fn__7457.invoke(core.clj:24) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat compojure.core$routing$fn__7482.invoke(core.clj:106) [storm-core-2.4.2-debug-patch.jar:0.10.0-SNAPSHOT]\n\tat clojure.core$some.invoke(core.clj:2515) [clojure-1.6.0.jar:?]",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-1596.json",
        "creation_time": "2016-03-02T23:42:56.000+0000",
        "bug_report": {
            "Title": "Multiple Subject sharing Kerberos TGT - causes services to fail",
            "Description": "With multiple threads accessing same {{Subject}}, it can cause {{ServiceTicket}} in use be by one thread be destroyed by another thread.\n\nRunning BasicDRPCTopology with high parallelism in secure cluster would reproduce the issue.\n\nHere is sample log from such a scenarios:\n{code}\n2016-01-20 15:52:26.904 o.a.t.t.TSaslTransport [ERROR] SASL negotiation failure\njavax.security.sasl.SaslException: GSS initiate failed\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211) ~[?:1.8.0_40]\n        at org.apache.thrift7.transport.TSaslClientTransport.handleSaslStartMessage(TSaslClientTransport.java:94) ~[storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslTransport.open(TSaslTransport.java:271) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at org.apache.thrift7.transport.TSaslClientTransport.open(TSaslClientTransport.java:37) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:195) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin$1.run(KerberosSaslTransportPlugin.java:191) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_40]\n        at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_40]\n        at backtype.storm.security.auth.kerberos.KerberosSaslTransportPlugin.connect(KerberosSaslTransportPlugin.java:190) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.TBackoffConnect.doConnectWithRetry(TBackoffConnect.java:54) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.security.auth.ThriftClient.reconnect(ThriftClient.java:109) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.DRPCInvocationsClient.reconnectClient(DRPCInvocationsClient.java:57) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.reconnectClient(ReturnResults.java:113) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.drpc.ReturnResults.execute(ReturnResults.java:103) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$tuple_action_fn__6379.invoke(executor.clj:689) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$mk_task_receiver$fn__6301.invoke(executor.clj:448) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$clojure_handler$reify__6018.onEvent(disruptor.clj:40) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:437) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.utils.DisruptorQueue.consumeBatchWhenAvailable(DisruptorQueue.java:416) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.disruptor$consume_batch_when_available.invoke(disruptor.clj:73) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.daemon.executor$fn__6377$fn__6390$fn__6441.invoke(executor.clj:801) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at backtype.storm.util$async_loop$fn__742.invoke(util.clj:482) [storm-core-0.10.1.y.jar:0.10.1.y]\n        at clojure.lang.AFn.run(AFn.java:22) [clojure-1.6.0.jar:?]\n        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_40]\nCaused by: org.ietf.jgss.GSSException: No valid credentials provided (Mechanism level: The ticket isn't for us (35) - BAD TGS SERVER NAME)\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:770) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.KrbException: The ticket isn't for us (35) - BAD TGS SERVER NAME\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\nCaused by: sun.security.krb5.Asn1Exception: Identifier doesn't match expected value (906)\n        at sun.security.krb5.internal.KDCRep.init(KDCRep.java:140) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.init(TGSRep.java:65) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:259) ~[?:1.8.0_40]\n        at sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:270) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:302) ~[?:1.8.0_40]\n        at sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:120) ~[?:1.8.0_40]\n        at sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:458) ~[?:1.8.0_40]\n        at sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:693) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:248) ~[?:1.8.0_40]\n        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179) ~[?:1.8.0_40]\n        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192) ~[?:1.8.0_40]\n        ... 23 more\n\n\n{code}",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2142.json",
        "creation_time": "2016-10-10T04:42:01.000+0000",
        "bug_report": {
            "Title": "ReportErrorAndDie runs suicide function only when InterruptedException or InterruptedIOException is thrown",
            "Description": "When EvaluationFilter / EvaluationFunction throws Exception, async loop for the executor is died but others will continue to work.\n\n{code}\n2016-10-08 14:12:29.597 o.a.s.u.Utils Thread-23-b-0-LOGICALFILTER_6-LOGICALPROJECT_7-executor[5 5] [ERROR] Async loop died!\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n        at org.apache.storm.utils.DisruptorQueue.consumeBatchToCursor(DisruptorQueue.java:468) ~[storm-core-2.0.0-SNAPSHOT.jar:2.0.0-SNAPSHOT]\n...\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_66]\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_66]\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_66]\n        at java.lang.reflect.Method.invoke(Method.java:497) ~[?:1.8.0_66]\n        at org.codehaus.janino.ScriptEvaluator.evaluate(ScriptEvaluator.java:982) ~[dep-janino-2.7.6-dcb5bd18-a5dd-4976-a967-0108dcf46df0.jar.1475903522000:2.7.6]\n...\nCaused by: java.lang.RuntimeException: Cannot convert null to int\n        at org.apache.calcite.runtime.SqlFunctions.cannotConvert(SqlFunctions.java:1023) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at org.apache.calcite.runtime.SqlFunctions.toInt(SqlFunctions.java:1134) ~[dep-calcite-core-1.9.0-e7846de7-7024-4041-89e4-67dd5edf31e8.jar.1475903521000:1.9.0]\n        at SC.eval0(Unknown Source) ~[?:?]\n{code}\n\nWhile looking into detail, I found that ReportErrorAndDie implementation seems odd - completely opposite behavior compared to 1.x :report-error-and-die.\nWhen InterruptedException or InterruptedIOException is thrown, it should just leave a log and shouldn't run suicide function. For others it should run suicide function.",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-2400.json",
        "creation_time": "2017-03-08T04:32:34.000+0000",
        "bug_report": {
            "Title": "Intermittent failure in nimbus because of errors from LeaderLatch#getLeader()",
            "Description": "This issue is reported to Curator with CURATOR-358. \n\norg.apache.curator.framework.recipes.leader.LeaderLatch#getLeader() throws KeeperException with Code#NONODE intermittently as mentioned in the stack trace below. It may be possible participant's ephemeral ZK node is removed because its connection/session is closed.\n\nYou can see the below code at https://github.com/apache/curator/blob/master/curator-recipes/src/main/java/org/apache/curator/framework/recipes/leader/LeaderLatch.java#L451\n\n{code}\npublic Participant getLeader() throws Exception\n{ \n  Collection<String> participantNodes = LockInternals.getParticipantNodes(client, latchPath, LOCK_NAME, sorter); \n  return LeaderSelector.getLeader(client, participantNodes); \n}\n{code}\n\nI guess it hits a race condition where a participant node is retrieved but when it invokes LeaderSelector#getLeader() it would have been removed because of session timeout and it throws KeeperException with NoNode code. It does not retry as the RetryLoop retries only for connection/session timeouts. But in this case, NoNode should have been retried. I could not find any APIs on CuratorClient to configure the kind of KeeperException codes to be retried. It may be good to have a way to take what kind of errors should be retried in org.apache.curator.framework.CuratorFrameworkFactory.Builder APIs.\nIntermittent Exception found with the stack trace:\n\n{noformat}\n2016-11-15 06:09:33.954 o.a.s.d.nimbus [ERROR] Error when processing event\norg.apache.storm.shade.org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /storm/leader-lock/_c_97c09eed-5bba-4ac8-a05f-abdc4e8e95cf-latch-0000000002\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\nat org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:304)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:293)\nat org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:108)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:290)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:281)\nat org.apache.storm.shade.org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:42)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.participantForPath(LeaderSelector.java:375)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderSelector.getLeader(LeaderSelector.java:346)\nat org.apache.storm.shade.org.apache.curator.framework.recipes.leader.LeaderLatch.getLeader(LeaderLatch.java:454)\n{noformat}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3084.json",
        "creation_time": "2018-05-24T20:45:32.000+0000",
        "bug_report": {
            "Title": "2.x NPE on Nimbus startup",
            "Description": "{code:java}\r\n2018-05-24 09:27:05.636 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.0.0.y' 2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event java.lang.RuntimeException: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y] Caused by: java.lang.NullPointerException at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y] ... 2 more 2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event java.lang.RuntimeException: Halting process: Error while processing event at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y] at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y] at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y] 2018-05-24 09:27:06.032 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master 2018-05-24 09:27:06.032 o.a.s.u.Utils Thread-13 [INFO] Halting after 5 seconds\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-3118.json",
        "creation_time": "2018-06-21T13:46:08.000+0000",
        "bug_report": {
            "Title": "Netty incompatibilities with Pacemaker",
            "Description": "Nimbus has issues with Pacemaker:\r\n{code:java}\r\n2018-06-21 08:55:17.762 o.a.s.p.PacemakerClientHandler client-worker-2 [ERROR] Exception occurred in Pacemaker.\r\norg.apache.storm.shade.io.netty.handler.codec.EncoderException: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\r\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:106) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:738) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:801) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:814) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:794) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1066) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:305) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.messaging.netty.KerberosSaslClientHandler.channelActive(KerberosSaslClientHandler.java:65) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.ChannelInboundHandlerAdapter.channelActive(ChannelInboundHandlerAdapter.java:64) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.fireChannelActive(AbstractChannelHandlerContext.java:192) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline$HeadContext.channelActive(DefaultChannelPipeline.java:1422) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:213) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.AbstractChannelHandlerContext.invokeChannelActive(AbstractChannelHandlerContext.java:199) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.DefaultChannelPipeline.fireChannelActive(DefaultChannelPipeline.java:941) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.fulfillConnectPromise(AbstractNioChannel.java:311) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:341) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:635) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:582) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:499) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:461) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.IndexOutOfBoundsException: writerIndex(713) + minWritableBytes(2) exceeds maxCapacity(713): UnpooledHeapByteBuf(ridx: 0, widx: 713, cap: 713/713)\r\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.ensureWritable0(AbstractByteBuf.java:276) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.buffer.AbstractByteBuf.writeShort(AbstractByteBuf.java:966) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.messaging.netty.SaslMessageToken.write(SaslMessageToken.java:104) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encodeNettySerializable(ThriftEncoder.java:44) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.pacemaker.codec.ThriftEncoder.encode(ThriftEncoder.java:77) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:88) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        ... 26 more\r\n{code}\r\nPrevents topology submission:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-06-21 09:10:46.343 o.a.s.d.n.Nimbus pool-37-thread-250 [WARN] Topology submission exception. (topology name='testStormKafkaNewApi')\r\njava.lang.IllegalStateException: instance must be started before calling this method\r\n        at org.apache.storm.shade.org.apache.curator.shaded.com.google.common.base.Preconditions.checkState(Preconditions.java:444) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:432) ~[shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.ZKStateStorage.mkdirs(ZKStateStorage.java:114) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.PaceMakerStateStorage.mkdirs(PaceMakerStateStorage.java:69) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.cluster.StormClusterStateImpl.setupHeatbeats(StormClusterStateImpl.java:435) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:3009) [storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3508) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3487) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.ProcessFunction.process(ProcessFunction.java:38) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.TBaseProcessor.process(TBaseProcessor.java:39) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) [storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:291) [shaded-deps-2.0.0.y.jar:2.0.0.y]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n{code}",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2158.json",
        "creation_time": "2016-10-20T12:56:58.000+0000",
        "bug_report": {
            "Title": "OutOfMemoryError in Nimbus' SimpleTransportPlugin",
            "Description": "{{OutOfMemoryError}} is thrown by Nimbus' {{SimpleTransportPlugin}} if malformed Thrift request is posted:\n{code}\necho \"Hello\" | nc localhost 6627\n{code}\n\nIn nimbus.log:\n{noformat}\n2016-10-20 12:54:09.978 b.s.d.nimbus [INFO] Starting Nimbus server...\n2016-10-20 12:54:42.926 o.a.t.s.THsHaServer [ERROR] run() exiting due to uncaught error\njava.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57) ~[?:1.8.0_92-internal]\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335) ~[?:1.8.0_92-internal]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$FrameBuffer.read(AbstractNonblockingServer.java:371) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.AbstractNonblockingServer$AbstractSelectThread.handleRead(AbstractNonblockingServer.java:203) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.select(TNonblockingServer.java:207) ~[storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n\tat org.apache.thrift7.server.TNonblockingServer$SelectAcceptThread.run(TNonblockingServer.java:158) [storm-core-0.10.3-SNAPSHOT.jar:0.10.3-SNAPSHOT]\n2016-10-20 12:54:42.942 b.s.d.nimbus [INFO] Shutting down master\n2016-10-20 12:54:43.003 b.s.d.nimbus [INFO] Shut down master\n{noformat}\n\nThe problem is caused by the lack of specification of the {{maxReadBufferBytes}} of {{THsHaServer}}'s arguments.",
            "Priority": "Major"
        }
    },
    {
        "filename": "STORM-2682.json",
        "creation_time": "2017-08-07T15:20:27.000+0000",
        "bug_report": {
            "Title": "Supervisor crashes with NullPointerException",
            "Description": "When supervisor is started, it dies after about 30s like so:\n\n{code:java}\n...\n2017-08-07 17:12:04.606 o.a.s.d.s.Slot main [WARN] SLOT 192.168.10.21:6701 Starting in state EMPTY - assignment null\n2017-08-07 17:12:04.607 o.a.s.d.s.Slot main [WARN] SLOT 192.168.10.21:6702 Starting in state EMPTY - assignment null\n2017-08-07 17:12:04.607 o.a.s.l.AsyncLocalizer main [INFO] Cleaning up unused topologies in /home/storm/data/supervisor/stormdist\n2017-08-07 17:12:04.617 o.a.s.d.s.Supervisor main [INFO] Starting supervisor with id 65a0f977-474c-4938-a4f5-bc99939e96ff at host 192.168.10.\n21.\n2017-08-07 17:12:04.619 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPrep\narableReporter\n2017-08-07 17:12:04.620 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...\n2017-08-07 17:12:04.624 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...\n2017-08-07 17:12:34.620 o.a.s.e.EventManagerImp Thread-4 [ERROR] {} Error when processing event\njava.lang.NullPointerException: null\n        at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:936) ~[?:1.8.0_121]\n        at org.apache.storm.localizer.Localizer.updateBlobs(Localizer.java:332) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.updateBlobsForTopology(UpdateBlobs.java:99) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.daemon.supervisor.timer.UpdateBlobs.run(UpdateBlobs.java:72) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:54) ~[storm-core-1.0.4.jar:1.0.4]\n2017-08-07 17:12:34.620 o.a.s.u.Utils Thread-4 [ERROR] Halting process: Error when processing an event\njava.lang.RuntimeException: Halting process: Error when processing an event\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:1750) ~[storm-core-1.0.4.jar:1.0.4]\n        at org.apache.storm.event.EventManagerImp$1.run(EventManagerImp.java:63) ~[storm-core-1.0.4.jar:1.0.4]\n2017-08-07 17:12:34.631 o.a.s.d.s.Supervisor Thread-5 [INFO] Shutting down supervisor 65a0f977-474c-4938-a4f5-bc99939e96ff\n{code}",
            "Priority": "Critical"
        }
    },
    {
        "filename": "STORM-3103.json",
        "creation_time": "2018-06-13T18:23:11.000+0000",
        "bug_report": {
            "Title": "nimbus stuck shutting down causing leadership issues on startup",
            "Description": "When debugging an Nimbus NPE that caused restarts, I noticed that a forced halt occurred:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-05-24 09:27:05.569 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Opening socket connection to server openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181. Will attempt to SASL-authenticate using Login Context section 'Client'\r\n2018-05-24 09:27:05.570 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Socket connection established to openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181, initiating session\r\n2018-05-24 09:27:05.571 o.a.z.ClientCnxn main-SendThread(openqe82blue-gw.blue.ygrid.yahoo.com:2181) [INFO] Session establishment complete on server openqe82blue-gw.blue.ygrid.yahoo.com/10.215.77.115:2181, sessionid = 0x1624a86300f7f6b, negotiated timeout = 40000\r\n2018-05-24 09:27:05.571 o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED\r\n2018-05-24 09:27:05.636 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.0.0.y'\r\n2018-05-24 09:27:06.012 o.a.s.d.n.Nimbus timer [ERROR] Error while processing event\r\njava.lang.RuntimeException: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2685) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$1.run(StormTimer.java:111) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:227) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\nCaused by: java.lang.NullPointerException\r\n        at org.apache.storm.daemon.nimbus.Nimbus.readAllSupervisorDetails(Nimbus.java:1814) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.computeNewSchedulerAssignments(Nimbus.java:1906) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2057) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.mkAssignments(Nimbus.java:2003) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$launchServer$37(Nimbus.java:2681) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 2 more\r\n2018-05-24 09:27:06.023 o.a.s.u.Utils timer [ERROR] Halting process: Error while processing event\r\njava.lang.RuntimeException: Halting process: Error while processing event\r\n        at org.apache.storm.utils.Utils.exitProcess(Utils.java:469) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.lambda$new$17(Nimbus.java:484) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.StormTimer$StormTimerTask.run(StormTimer.java:252) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n2018-05-24 09:27:06.032 o.a.s.d.n.Nimbus Thread-12 [INFO] Shutting down master\r\n2018-05-24 09:27:06.032 o.a.s.u.Utils Thread-13 [INFO] Halting after 5 seconds\r\n{code}\r\nAt times this would cause leadership confusion:\r\n\r\n\u00a0\r\n{code:java}\r\n2018-05-24 09:27:21.762 o.a.s.z.LeaderElectorImp main [INFO] Queued up for leader lock.\r\n2018-05-24 09:27:22.604 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping assignments\r\n2018-05-24 09:27:22.604 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping cleanup\r\n2018-05-24 09:27:22.633 o.a.s.d.n.Nimbus timer [INFO] not a leader, skipping credential renewal.\r\n\r\n2018-05-24 09:27:40.771 o.a.s.d.n.Nimbus pool-37-thread-63 [WARN] Topology submission exception. (topology name='topology-testOverSubscribe-1')\r\njava.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\n2018-05-24 09:27:40.771 o.a.s.b.BlobStoreUtils Timer-1 [ERROR] Could not download the blob with key: topology-testOverCapacityScheduling-2-1519992333-stormcode.ser\r\n2018-05-24 09:27:40.771 o.a.t.s.TThreadPoolServer pool-37-thread-63 [ERROR] Error occurred during processing of message.\r\njava.lang.RuntimeException: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2961) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3454) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.generated.Nimbus$Processor$submitTopologyWithOpts.getResult(Nimbus.java:3438) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at org.apache.storm.security.auth.sasl.SaslTransportPlugin$TUGIWrapProcessor.process(SaslTransportPlugin.java:147) ~[storm-client-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[libthrift-0.9.3.jar:0.9.3]\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_131]\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_131]\r\n        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_131]\r\nCaused by: java.lang.RuntimeException: not a leader, current leader is NimbusInfo{host='openqe82blue-n1.blue.ygrid.yahoo.com', port=50560, isLeader=true}\r\n        at org.apache.storm.daemon.nimbus.Nimbus.assertIsLeader(Nimbus.java:1311) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        at org.apache.storm.daemon.nimbus.Nimbus.submitTopologyWithOpts(Nimbus.java:2807) ~[storm-server-2.0.0.y.jar:2.0.0.y]\r\n        ... 9 more\r\n{code}\r\nWe should endeavor to shutdown cleanly.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0",
            "Priority": "Major"
        }
    }
]